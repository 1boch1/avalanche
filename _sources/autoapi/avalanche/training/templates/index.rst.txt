:mod:`avalanche.training.templates`
===================================

.. py:module:: avalanche.training.templates


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   deep_learning_strategy/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.training.templates.DeepLearningStrategy
   avalanche.training.templates.MTDeepLearningStrategy



.. py:class:: DeepLearningStrategy(train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = 1, device=None, evaluation_protocol: Optional[EvalProtocol] = None, plugins: Optional[Sequence[StrategySkeleton]] = None)

   Bases: :class:`avalanche.training.skeletons.StrategyTemplate`

   Defines a general Deep Learning strategy.

   This class is usually used as the father class of most strategy
   implementations, although users should consider using
   :class:`MTDeepLearningStrategy`, which also adds automatic multi head
   management for multi-task scenarios.

   This class (or :class:`MTDeepLearningStrategy`) takes care of most
   under-the-hood management. Most users should create an inherited class and
   implement its "training_epoch" and "testing_epoch" methods.
   Optionally, also overriding "adapt_train_dataset" and "adapt_test_dataset"
   may allow the users to adapt (pad, augment, etc.) the training and test
   datasets.

   This class introduces the main parts usually found in a Deep Learning based
   Continual Learning strategy, such as a training loop based on epochs,
   a model adaptation flow group (filled, for instance, by
   :class:`MTDeepLearningStrategy`) and a lot of default callbacks that the
   user can override, such as:

   -   before/after_training
   -   before/after_training_epoch
   -   before/after_testing
   -   before/after_step_testing
   -   before/after_testing_epoch

   And also exposes some useful callback methods that have to be called by
   implementing classes, such as:

   -   before/after_training_iteration
   -   before/after_forward
   -   before/after_backward
   -   before/after_update
   -   before/after_test_iteration
   -   before/after_test_forward

   Creates a new instance of DeepLearningStrategy.

   This constructor accepts common parameters used to control the minibatch
   size, the number of training epochs and the device used for training.
   It also accepts and instance of :class:`EvalProtocol` which will be used
   to compute the required metrics.

   :param train_mb_size: The size of the training minibatch size. This
       value is used when creating the training data loader. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The size of the test minibatch size. This
       value is used when creating the testing data loader. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param evaluation_protocol: The evaluation protocol used to compute
       the relevant metrics. Defaults to None.
   :param plugins: Additional plugin other to be added to the Strategy.
   Keep in mind that the EvaluationPlugin is always added by default,
   do not add it again here. Defaults to None.

   .. method:: training_epoch(self)

      Runs a training epoch.

      This is the method most users should override, along with
      "testing_epoch".

      :return: Strategy specific.


   .. method:: testing_epoch(self)

      Runs a testing epoch.

      This is the method most users should override, along with
      "training_epoch".

      :return: Strategy specific.


   .. method:: adapt_train_dataset(self)

      Adapts the training set.

      This method can be safely overridden by users. Defaults to no-op.

      The user should adapt the existing "train_dataset" (that can be
      retrieved in the global namespace). Operations may involve padding,
      merging of replay patterns, ... If the result is an object different
      from the original "train_dataset", the corresponding namespace value
      must be set accordingly using the "update_namespace" method.

      :return: Strategy specific.


   .. method:: adapt_test_dataset(self)

      Adapts the test set.

      This method can be safely overridden by users. Defaults to no-op.

      The user should adapt the existing "test_dataset" (that can be
      retrieved in the global namespace). If the result is an object different
      from the original "test_dataset", the corresponding namespace value
      must be set accordingly using the "update_namespace" method.

      :return: Strategy specific.


   .. method:: set_initial_epoch(self)

      Initial utility that sets the initial epoch namespace value to 0.

      Most users shouldn't override this method.


   .. method:: before_training(self)

      A callback that gets invoked before training.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: after_training(self)

      A callback that gets invoked after training.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: before_training_epoch(self)

      A callback that gets invoked before each training epoch.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: after_training_epoch(self)

      A callback that gets invoked after each training epoch.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: next_training_epoch(self, epoch=0, train_epochs=1)

      Checks if another epoch has to be run and sets the epoch namespace
      value accordingly.

      This method simply checks for the train_epochs parameter for the number
      of training epochs to run.

      This is the last part of the TrainingLoop group, which means that
      returning "False" stops the training loop.

      Most users shouldn't override this method.

      :param epoch: The current epoch.
      :param train_epochs: The number of training epoch to run. This is
      usually taken from the class field with the same name.

      :return: True if other epochs are to be run, False otherwise.


   .. method:: has_training_epochs_left(self, epoch=0, train_epochs=1)

      Checks if there are training epochs left.

      This method simply checks for the train_epochs parameter for the number
      of training epochs to run.

      This method doesn't set any namespace values.

      Most users shouldn't override this method.

      :param epoch: The current epoch.
      :param train_epochs: The number of training epoch to run. This is
      usually taken from the class field with the same name.
      :return: True if other epochs are to be run, False otherwise.


   .. method:: before_training_iteration(self)

      A callback that gets invoked before each training iteration.

      This callback is not automatically called by the
      :class:`DeepLearningStrategy`, where it's declared. In fact,
      implementing strategies subclasses should explicitly call this method
      before running each training iteration.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: after_training_iteration(self)

      A callback that gets invoked after each training iteration.

      This callback is not automatically called by the
      :class:`DeepLearningStrategy`, where it's declared. In fact,
      implementing strategies subclasses should explicitly call this method
      after running each training iteration.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: before_forward(self)

      A callback that gets invoked before running the forward pass on the
      model(s?).

      This callback is not automatically called by the
      :class:`DeepLearningStrategy`, where it's declared. In fact,
      implementing strategies subclasses should explicitly call this method
      before running each forward pass.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: after_forward(self)

      A callback that gets invoked after running the forward pass on the
      model(s?).

      This callback is not automatically called by the
      :class:`DeepLearningStrategy`, where it's declared. In fact,
      implementing strategies subclasses should explicitly call this method
      after running each forward pass.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: before_backward(self)

      A callback that gets invoked before running the backward pass on the
      model(s?).

      This callback is not automatically called by the
      :class:`DeepLearningStrategy`, where it's declared. In fact,
      implementing strategies subclasses should explicitly call this method
      before running each backward pass.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: after_backward(self)

      A callback that gets invoked after running the backward pass on the
      model(s?).

      This callback is not automatically called by the
      :class:`DeepLearningStrategy`, where it's declared. In fact,
      implementing strategies subclasses should explicitly call this method
      after running each backward pass.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: before_update(self)

      A callback that gets invoked before running the update pass on the
      model(s?).

      This callback is not automatically called by the
      :class:`DeepLearningStrategy`, where it's declared. In fact,
      implementing strategies subclasses should explicitly call this method
      before running each update pass.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: after_update(self)

      A callback that gets invoked after running the update pass on the
      model(s?).

      This callback is not automatically called by the
      :class:`DeepLearningStrategy`, where it's declared. In fact,
      implementing strategies subclasses should explicitly call this method
      after running each update pass.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: before_testing(self)

      A callback that gets invoked before testing.

      Beware that another callback method exists, "before_step_testing",
      which gets invoked before testing on each single test set. On the
      contrary, this method gets invoked once at the very beginning of the
      testing flow.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: after_testing(self)

      A callback that gets invoked after testing.

      Beware that another callback method exists, "after_step_testing",
      which gets invoked after testing on each single test set. On the
      contrary, this method gets invoked once at the very end of the
      testing flow.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: before_step_testing(self)

      A callback that gets invoked before testing on a single test set.

      Beware that another callback method exists, "before_testing",
      which gets invoked once at the very beginning of the test flow. On the
      contrary, this method gets invoked before testing on each test set.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: after_step_testing(self)

      A callback that gets invoked after testing on a single test set.

      Beware that another callback method exists, "after_testing",
      which gets invoked once at the very end of the test flow. On the
      contrary, this method gets invoked after testing on each test set.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: before_testing_epoch(self)

      A callback that gets invoked before running a test epoch.

      Consider that, when testing, only one epoch for each test set is
      executed. The main difference between this callback and
      "before_step_testing" is that, when "before_step_testing" is called,
      the model is not already adapted for the current test set. Also,
      the "make_test_dataset", "adapt_test_dataset", "make_test_dataloader"
      are called after "before_step_testing" and before this callback.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: after_testing_epoch(self)

      A callback that gets invoked after running a test epoch.

      Consider that, when testing, only one epoch for each test set is
      executed.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: before_test_iteration(self)

      A callback that gets invoked before running an iteration on a
      test set.

      This callback is not automatically called by the
      :class:`DeepLearningStrategy`, where it's declared. In fact,
      implementing strategies subclasses should explicitly call this method
      before running each test iteration.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: after_test_iteration(self)

      A callback that gets invoked after running an iteration on a
      test set.

      This callback is not automatically called by the
      :class:`DeepLearningStrategy`, where it's declared. In fact,
      implementing strategies subclasses should explicitly call this method
      after running each test iteration.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: before_test_forward(self)

      A callback that gets invoked before running the forward pass on the
      model(s) during testing.

      This callback is not automatically called by the
      :class:`DeepLearningStrategy`, where it's declared. In fact,
      implementing strategies subclasses should explicitly call this method
      before running each forward pass.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: after_test_forward(self)

      A callback that gets invoked after running the forward pass on the
      model(s) during testing.

      This callback is not automatically called by the
      :class:`DeepLearningStrategy`, where it's declared. In fact,
      implementing strategies subclasses should explicitly call this method
      after running each forward pass.

      Can be safely overridden by users. Consider calling the super method
      when overriding.

      :return: Strategy specific.


   .. method:: train(self, step_info: TStepInfo, **kwargs)

      Executes an incremental training step on the training data.

      This methods takes a "step_info" as a parameter. The "step_info"
      instance can be used to extract data relevant to the current training
      step, like the training dataset, the current task/batch id, any
      previous or future training or testing test, etc.

      :param step_info: The step info instance.
      :param kwargs: A list of strategy parameters.
      :return: The result of the evaluation protocol (if any).


   .. method:: test(self, step_info: TStepInfo, test_part: DatasetPart, **kwargs)

      Executes a testing procedure step on the testing data.

      This methods takes a "step_info" as a parameter. The "step_info"
      instance can be used to extract data relevant to the current testing
      step, like the test datasets, the current task/batch id, any
      previous or future training or testing test, etc.

      Beware that a dataset part flag must be passed as the second parameter
      (as a value of :class:`DatasetPart`). This flag controls whenever the
      user wants to test on all tasks/batches ("COMPLETE"), only on already
      encountered tasks/batches ("CUMULATIVE"), only on previous ones ("OLD"),
      on the current task/batch only ("CURRENT") or even on future
      tasks/batches ("FUTURE").

      The testing procedure must loop through the different test sets
      to obtain the relevant metrics.

      :param step_info: The step info instance.
      :param kwargs: A list of strategy parameters.
      :return: The result of the evaluation protocol (if any).



.. py:class:: MTDeepLearningStrategy(model: Module, classifier_field: str = 'classifier', keep_initial_layer=False, train_mb_size=1, train_epochs=1, test_mb_size=None, evaluation_protocol=None, device=None, plugins=None)

   Bases: :class:`avalanche.training.templates.deep_learning_strategy.DeepLearningStrategy`

   Defines a common skeleton for Deep Learning strategies supporting
   Multi Task scenarios. This base class can be used as the foundation for
   strategies supporting Single-Incremental-Task (a.k.a. task-free) scenarios
   as well (in which case, it only handles the dynamic head expansion part).

   This class adds several elements to the training and testing flows.
   In particular, the default implementation keeps an internal set of layers,
   one for each task.

   By default, a Linear (fully connected) layer is created
   with as many output units as the number of classes in that task. This
   behaviour can be changed by overriding the "create_task_layer" method.

   By default, weights are initialized using the Linear class default
   initialization. This behaviour can be changed by overriding the
   "initialize_new_task_layer" method.

   When dealing with a Single-Incremental-Task scenario, the final layer may
   get dynamically expanded. By default, the initialization provided by the
   Linear class is used and then weights of already existing classes are copied
   (that  is, without adapting the weights of new classes). The user can
   control how the new weights are initialized by overriding
   "initialize_dynamically_expanded_head".

   In each training/testing step the strategy changes the model final layer
   with the task-specific one. Those behaviours can be changed
   by overriding the appropriate methods in order to achieve more complex
   Multi Task management.

   Creates a new MTDeepLearningStrategy instance.

   This constructor is usually invoked by implementing subclasses.

   This class expects a single model to adapt. More complex setups, where
   multiple models are used, must be implemented separately (this
   implementation may still serve as a good starting point). The second
   parameter specifies the name of the model field which will get changed
   when adapting for a different task. The third parameter control whenever
   the existing head should be kept for task 0 or it should be discarded.

   The remaining parameters are passed as constructor arguments for the
   superclass :class:`DeepLearningStrategy`.

   :param model: The model.
   :param classifier_field: The name of the model field to adapt.
   :param keep_initial_layer: If True, the model head found in the original
       model will be used for task 0. Defaults to False, which means that
       the head for task 0 will be created from scratch and the existing
       head will be discarded. Beware that when keeping the original layer
       the weight initialization will not take place. That is, the layer
       will initially be kept as-is.
   :param train_mb_size: The size of the training minibatch size. This
       value is used when creating the training data loader. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The size of the test minibatch size. This
       value is used when creating the testing data loader. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param evaluation_protocol: The evaluation protocol used to compute
       the relevant metrics. Defaults to None.
   :param plugins: Plugins to be added.

   .. method:: set_task_layer(self, model: Module, classifier_field: str, step_info: IStepInfo, step_id: Optional[int] = None)

      Sets the correct task layer.

      This method is used by both training and testing flows. This is
      particularly useful when testing on the complete test set, which usually
      includes not already seen tasks.

      By default a Linear layer is created for each task. More info can be
      found at class level documentation.

      :param model: The model to adapt.
      :param classifier_field: The name of the layer (model class field) to
          change.
      :param step_info: The step info object.
      :param step_id: The relevant step id. If None, the current training step
          id is used.
      :return: None


   .. method:: create_task_layer(self, model: Module, classifier_field: str, n_output_units: int, previous_task_layer=None)

      Creates a new task layer.

      By default, this method will create a new :class:`Linear` layer with
      n_output_units" output units. If  "previous_task_layer" is None,
      the name of the classifier field is used to retrieve the amount of
      input features.

      This method will also be used to create a new layer when expanding
      an existing task head.

      This method can be overridden by the user so that a layer different
      from :class:`Linear` can be created.

      :param model: The model for which the layer will be created.
      :param classifier_field: The name of the classifier field.
      :param n_output_units: The number of output units.
      :param previous_task_layer: If not None, the previously created layer
           for the same task.
      :return: The new layer.


   .. method:: initialize_new_task_layer(self, new_layer: Module)

      Initializes a new task layer.

      This method should initialize the input layer. This usually is just a
      weight initialization procedure, but more complex operations can be
      done as well.

      The input layer can be either a new layer created for a previously
      unseen task or a layer created to expand an existing task layer. In the
      latter case, the user can define a specific weight initialization
      procedure for the expanded part of the head by overriding the
      "initialize_dynamically_expanded_head" method.

      By default, if no custom implementation is provided, no specific
      initialization is done, which means that the default initialization
      provided by the :class:`Linear` class is used.

      :param new_layer: The new layer to adapt.
      :return: None


   .. method:: initialize_dynamically_expanded_head(self, prev_task_layer, new_task_layer)

      Initializes head weights for enw classes.

      This function is called by "adapt_task_layer" only.

      Defaults to no-op, which uses the initialization provided
      by "initialize_new_task_layer" (already called by "adapt_task_layer").

      This method should initialize the weights for new classes. However,
      if the strategy dictates it, this may be the perfect place to adapt
      weights of previous classes, too.

      :param prev_task_layer: New previous, not expanded, task layer.
      :param new_task_layer: The new task layer, with weights from already
          existing classes already set.
      :return:


   .. method:: adapt_task_layer(self, prev_task_layer, new_task_layer)

      Adapts the task layer by copying previous weights to the new layer and
      by calling "initialize_dynamically_expanded_head".

      This method is called by "expand_task_layer" only if a new task layer
      was created as the result of encountering a new class for that task.

      :param prev_task_layer: The previous task later.
      :param new_task_layer: The new task layer.
      :return: None.


   .. method:: expand_task_layer(self, model: Module, classifier_field: str, min_n_output_units: int, task_layer)

      Expands an existing task layer.

      This method checks if the layer for a task should be expanded to
      accommodate for "min_n_output_units" output units. If the task layer
      already contains a sufficient amount of output units, no operations are
      done and "task_layer" will be returned as-is.

      If an expansion is needed, "create_task_layer" will be used to create
      a new layer and then "adapt_task_layer" will be called to copy the
      weights of already seen classes and to initialize the weights
      for the expanded part of the layer.

      :param model: The model.
      :param classifier_field: The name of the field to adapt.
      :param min_n_output_units: The number of required output units.
      :param task_layer: The previous task layer.

      :return: The new layer for the task.


   .. method:: adapt_model_for_task(self, model: Module, classifier_field: str, task_layer)

      Sets the model classifier field for the given task layer
      By default, just sets the model property with the name given by
      the "classifier_field" parameter

      :param model: The model to adapt.
      :param classifier_field: The name of the classifier field.
      :param task_layer: The layer to set.



