:mod:`avalanche.training.strategies.joint_training`
===================================================

.. py:module:: avalanche.training.strategies.joint_training


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.training.strategies.joint_training.JointTraining



.. py:class:: JointTraining(model: Module, optimizer: Optimizer, criterion, train_mb_size: int = 1, train_epochs: int = 1, eval_mb_size: int = 1, device='cpu', plugins: Optional[Sequence['StrategyPlugin']] = None, evaluator=default_logger)

   Bases: :class:`avalanche.training.strategies.BaseStrategy`

   JointTraining performs joint training (also called offline training) on
   the entire stream of data. This means that it is not a continual
   learning strategy but it can be used as an "offline" upper bound for
   them.

   .. warnings also::
       Currently :py:class:`JointTraining` adapts its own dataset.
       Please check that the plugins you are using do not implement
       :py:meth:`adapt_trainin_dataset`. Otherwise, they are incompatible
       with :py:class:`JointTraining`.

   :param model: PyTorch model.
   :param optimizer: PyTorch optimizer.
   :param criterion: loss function.
   :param train_mb_size: mini-batch size for training.
   :param train_epochs: number of training epochs.
   :param eval_mb_size: mini-batch size for eval.
   :param device: PyTorch device to run the model.
   :param plugins: (optional) list of StrategyPlugins.
   :param evaluator: (optional) instance of EvaluationPlugin for logging
       and metric computations. None to remove logging.

   .. method:: train(self, experiences: Union[Experience, Sequence[Experience]], **kwargs)

      Training loop. if experiences is a single element trains on it.
      If it is a sequence, trains the model on each experience in order.
      Joint training uses the entire stream and it is not a proper CL
      strategy.

      :param experiences: single IExperience or sequence.



