:mod:`avalanche.training.strategies`
====================================

.. py:module:: avalanche.training.strategies


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   base_strategy/index.rst
   joint_training/index.rst
   strategies/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.training.strategies.BaseStrategy
   avalanche.training.strategies.JointTraining
   avalanche.training.strategies.Naive
   avalanche.training.strategies.CWRStar
   avalanche.training.strategies.Replay
   avalanche.training.strategies.GDumb
   avalanche.training.strategies.Cumulative



.. py:class:: BaseStrategy(model: Module, optimizer: Optimizer, criterion, evaluation_protocol: Optional[EvalProtocol] = None, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = 1, device='cpu', plugins: Optional[Sequence[StrategyPlugin]] = None)

   BaseStrategy is the super class of all continual learning strategies.
   It implements a basic training loop and callback system that can be
   customized by child strategies. Additionally, it supports plugins,
   a mechanism to augment existing strategies with additional
   behavior (e.g. a memory buffer for replay).

   :param model: PyTorch model.
   :param optimizer: PyTorch optimizer.
   :param criterion: loss function.
   :param evaluation_protocol: evaluation plugin.
   :param train_mb_size: mini-batch size for training.
   :param train_epochs: number of training epochs.
   :param test_mb_size: mini-batch size for test.
   :param device: PyTorch device to run the model.
   :param plugins: (optional) list of StrategyPlugins.

   .. method:: update_optimizer(self, old_params, new_params, reset_state=True)

      Update the optimizer by substituting old_params with new_params.

      :param old_params: List of old trainable parameters.
      :param new_params: List of new trainable parameters.
      :param reset_state: Wheter to reset the optimizer's state.
          Defaults to True.
      :return:


   .. method:: add_new_params_to_optimizer(self, new_params)

      Add new parameters to the trainable parameters.

      :param new_params: list of trainable parameters


   .. method:: train(self, step_infos: Union[IStepInfo, Sequence[IStepInfo]], **kwargs)

      Training loop. if step_infos is a single element trains on it.
      If it is a sequence, trains the model on each step in order.
      This is different from joint training on the entire stream.

      :param step_infos: single IStepInfo or sequence.
      :return:


   .. method:: train_step(self, step_info: IStepInfo, **kwargs)

      Training loop over a single IStepInfo object.

      :param step_info: CL step information.
      :param kwargs: custom arguments.
      :return: train results from the evalution plugin.


   .. method:: test(self, step_list: Union[IStepInfo, Sequence[IStepInfo]], **kwargs)

      Test the current model on a series of steps, as defined by test_part.

      :param step_info: CL step information.
      :param test_part: determines which steps to test on.
      :param kwargs: custom arguments.
      :return: evaluation plugin test results.


   .. method:: before_training_step(self, **kwargs)

      Called  after the dataset and data loader creation and
      before the training loop.


   .. method:: make_train_dataloader(self, num_workers=0, shuffle=True, **kwargs)

      Called after the dataset instantiation. Initialize the data loader.
      :param num_workers: number of thread workers for the data laoding.
      :param shuffle: True if the data should be shuffled, False otherwise.


   .. method:: make_test_dataloader(self, num_workers=0, **kwargs)

      Initialize the test data loader.
      :param num_workers:
      :param kwargs:
      :return:


   .. method:: adapt_train_dataset(self, **kwargs)

      Called after the dataset initialization and before the
      dataloader initialization. Allows to customize the dataset.
      :param kwargs:
      :return:


   .. method:: before_training_epoch(self, **kwargs)

      Called at the beginning of a new training epoch.
      :param kwargs:
      :return:


   .. method:: training_epoch(self, **kwargs)

      Training epoch.
      :param kwargs:
      :return:


   .. method:: before_training_iteration(self, **kwargs)


   .. method:: before_forward(self, **kwargs)


   .. method:: after_forward(self, **kwargs)


   .. method:: before_backward(self, **kwargs)


   .. method:: after_backward(self, **kwargs)


   .. method:: after_training_iteration(self, **kwargs)


   .. method:: before_update(self, **kwargs)


   .. method:: after_update(self, **kwargs)


   .. method:: after_training_epoch(self, **kwargs)


   .. method:: after_training_step(self, **kwargs)


   .. method:: before_test(self, **kwargs)


   .. method:: before_test_step(self, **kwargs)


   .. method:: adapt_test_dataset(self, **kwargs)


   .. method:: test_epoch(self, **kwargs)


   .. method:: after_test_step(self, **kwargs)


   .. method:: after_test(self, **kwargs)


   .. method:: before_test_iteration(self, **kwargs)


   .. method:: before_test_forward(self, **kwargs)


   .. method:: after_test_forward(self, **kwargs)


   .. method:: after_test_iteration(self, **kwargs)



.. py:class:: JointTraining(model: Module, optimizer: Optimizer, criterion, evaluation_protocol: Optional[EvalProtocol] = None, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = 1, device='cpu', plugins: Optional[Sequence[StrategyPlugin]] = None)

   Bases: :class:`avalanche.training.strategies.BaseStrategy`

   JointStrategy is a super class for all the joint training strategies.
   This means that it is not a continual learning strategy but it can be
   used as an "offline" upper bound for them. This strategy takes in
   input an entire stream and learn from it one shot. It supports unique
   tasks (i.e. streams with a unique task label) or multiple tasks.

   :param model: PyTorch model.
   :param optimizer: PyTorch optimizer.
   :param criterion: loss function.
   :param evaluation_protocol: evaluation plugin.
   :param train_mb_size: mini-batch size for training.
   :param train_epochs: number of training epochs.
   :param test_mb_size: mini-batch size for test.
   :param device: PyTorch device to run the model.
   :param plugins: (optional) list of StrategyPlugins.

   .. method:: train(self, step_infos: Sequence[IStepInfo], **kwargs)

      Training loop. if step_infos is a single element trains on it.
      If it is a sequence, trains the model on each step in order.
      This is different from joint training on the entire stream.

      :param step_infos: single IStepInfo or sequence.
      :return:



.. py:class:: Naive(model: Module, optimizer: Optimizer, criterion, evaluation_protocol: Optional[EvalProtocol] = None, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = None, device=None, plugins: Optional[Sequence[StrategyPlugin]] = None)

   Bases: :class:`avalanche.training.strategies.base_strategy.BaseStrategy`

   The simplest (and least effective) Continual Learning strategy. Naive just
   incrementally fine tunes a single model without employing any method
   to contrast the catastrophic forgetting of previous knowledge.

   Naive is easy to set up and its results are commonly used to show the worst
   performing baseline.

   Creates an instance of the Naive strategy.

   :param model: The model.
   :param optimizer: The optimizer to use.
   :param criterion: The loss criterion to use.
   :param evaluation_protocol: The evaluation plugin.
   :param train_mb_size: The train minibatch size. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The test minibatch size. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param plugins: Plugins to be added. Defaults to None.


.. py:class:: CWRStar(model: Module, optimizer: Optimizer, criterion, second_last_layer_name, num_classes=50, evaluation_protocol: Optional[EvalProtocol] = None, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = None, device=None, plugins: Optional[List[StrategyPlugin]] = None)

   Bases: :class:`avalanche.training.strategies.base_strategy.BaseStrategy`

   CWR* Strategy.

   :param model: The model.
   :param optimizer: The optimizer to use.
   :param criterion: The loss criterion to use.
   :param second_last_layer_name: name of the second to last layer
           (layer just before the classifier).
   :param num_classes: total number of classes.
   :param evaluation_protocol: The evaluation plugin.
   :param train_mb_size: The train minibatch size. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The test minibatch size. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param plugins: Plugins to be added. Defaults to None.


.. py:class:: Replay(model: Module, optimizer: Optimizer, criterion, mem_size: int = 200, evaluation_protocol: Optional[EvalProtocol] = None, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = None, device=None, plugins: Optional[List[StrategyPlugin]] = None)

   Bases: :class:`avalanche.training.strategies.base_strategy.BaseStrategy`

   Experience replay strategy. See ReplayPlugin for more details.

   :param model: The model.
   :param optimizer: The optimizer to use.
   :param criterion: The loss criterion to use.
   :param mem_size: replay buffer size.
   :param evaluation_protocol: The evaluation plugin.
   :param train_mb_size: The train minibatch size. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The test minibatch size. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param plugins: Plugins to be added. Defaults to None.


.. py:class:: GDumb(model: Module, optimizer: Optimizer, criterion, mem_size: int = 200, evaluation_protocol: Optional[EvalProtocol] = None, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = None, device=None, plugins: Optional[List[StrategyPlugin]] = None)

   Bases: :class:`avalanche.training.strategies.base_strategy.BaseStrategy`

   GDumb strategy. See GDumbPlugin for more details.

   :param model: The model.
   :param optimizer: The optimizer to use.
   :param criterion: The loss criterion to use.
   :param mem_size: replay buffer size.
   :param evaluation_protocol: The evaluation plugin.
   :param train_mb_size: The train minibatch size. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The test minibatch size. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param plugins: Plugins to be added. Defaults to None.


.. py:class:: Cumulative(model: Module, optimizer: Optimizer, criterion, evaluation_protocol: Optional[EvalProtocol] = None, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = None, device=None, plugins: Optional[List[StrategyPlugin]] = None)

   Bases: :class:`avalanche.training.strategies.base_strategy.BaseStrategy`

   Cumulative strategy. At each step,
       train model with data from all previous steps and current step.

   :param model: The model.
   :param optimizer: The optimizer to use.
   :param criterion: The loss criterion to use.
   :param evaluation_protocol: The evaluation plugin.
   :param train_mb_size: The train minibatch size. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The test minibatch size. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param plugins: Plugins to be added. Defaults to None.

   .. method:: adapt_train_dataset(self, **kwargs)

      Called after the dataset initialization and before the
      dataloader initialization. Allows to customize the dataset.
      :param kwargs:
      :return:



