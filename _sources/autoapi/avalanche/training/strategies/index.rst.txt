:mod:`avalanche.training.strategies`
====================================

.. py:module:: avalanche.training.strategies


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   cl_naive/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.training.strategies.Naive



.. py:class:: Naive(model: Module, classifier_field: str, optimizer: Optimizer, criterion: Module, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = None, device=None, evaluation_protocol: Optional[EvalProtocol] = None, plugins: Optional[Sequence[StrategySkeleton]] = None)

   Bases: :class:`avalanche.training.template.deep_learning_strategy.MTDeepLearningStrategy`

   The simplest (and least effective) Continual Learning strategy. Naive just
   incrementally fine tunes a single model without employing any method
   to contrast the catastrophic forgetting of previous knowledge.

   Naive is easy to set up and its results are commonly used to show the worst
   performing baseline.

   Creates an instance of the Naive strategy.

   :param model: The model.
   :param classifier_field: The name of the classifier field. Used when
       managing heads in Multi-Task scenarios.
   :param optimizer: The optimizer to use.
   :param criterion: The loss criterion to use.
   :param train_mb_size: The train minibatch size. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The test minibatch size. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param evaluation_protocol: The evaluation protocol. Defaults to None.
   :param plugins: Plugins to be added. Defaults to None.

   .. method:: training_epoch(self, model: Module, train_data_loader, optimizer: Optimizer, criterion: Module, device=None)


   .. method:: testing_epoch(self, model: Module, test_data_loader, criterion: Module, device=None)



