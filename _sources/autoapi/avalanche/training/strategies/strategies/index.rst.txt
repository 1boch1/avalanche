:mod:`avalanche.training.strategies.strategies`
===============================================

.. py:module:: avalanche.training.strategies.strategies


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.training.strategies.strategies.Naive
   avalanche.training.strategies.strategies.CWRStar
   avalanche.training.strategies.strategies.Replay
   avalanche.training.strategies.strategies.GDumb
   avalanche.training.strategies.strategies.Cumulative
   avalanche.training.strategies.strategies.LwF
   avalanche.training.strategies.strategies.AGEM
   avalanche.training.strategies.strategies.GEM



.. py:class:: Naive(model: Module, optimizer: Optimizer, criterion, evaluation_protocol: Optional[EvalProtocol] = None, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = None, device=None, plugins: Optional[Sequence[StrategyPlugin]] = None)

   Bases: :class:`avalanche.training.strategies.base_strategy.BaseStrategy`

   The simplest (and least effective) Continual Learning strategy. Naive just
   incrementally fine tunes a single model without employing any method
   to contrast the catastrophic forgetting of previous knowledge.

   Naive is easy to set up and its results are commonly used to show the worst
   performing baseline.

   Creates an instance of the Naive strategy.

   :param model: The model.
   :param optimizer: The optimizer to use.
   :param criterion: The loss criterion to use.
   :param evaluation_protocol: The evaluation plugin.
   :param train_mb_size: The train minibatch size. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The test minibatch size. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param plugins: Plugins to be added. Defaults to None.


.. py:class:: CWRStar(model: Module, optimizer: Optimizer, criterion, second_last_layer_name, num_classes=50, evaluation_protocol: Optional[EvalProtocol] = None, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = None, device=None, plugins: Optional[List[StrategyPlugin]] = None)

   Bases: :class:`avalanche.training.strategies.base_strategy.BaseStrategy`

   CWR* Strategy.

   :param model: The model.
   :param optimizer: The optimizer to use.
   :param criterion: The loss criterion to use.
   :param second_last_layer_name: name of the second to last layer
           (layer just before the classifier).
   :param num_classes: total number of classes.
   :param evaluation_protocol: The evaluation plugin.
   :param train_mb_size: The train minibatch size. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The test minibatch size. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param plugins: Plugins to be added. Defaults to None.


.. py:class:: Replay(model: Module, optimizer: Optimizer, criterion, mem_size: int = 200, evaluation_protocol: Optional[EvalProtocol] = None, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = None, device=None, plugins: Optional[List[StrategyPlugin]] = None)

   Bases: :class:`avalanche.training.strategies.base_strategy.BaseStrategy`

   Experience replay strategy. See ReplayPlugin for more details.

   :param model: The model.
   :param optimizer: The optimizer to use.
   :param criterion: The loss criterion to use.
   :param mem_size: replay buffer size.
   :param evaluation_protocol: The evaluation plugin.
   :param train_mb_size: The train minibatch size. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The test minibatch size. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param plugins: Plugins to be added. Defaults to None.


.. py:class:: GDumb(model: Module, optimizer: Optimizer, criterion, mem_size: int = 200, evaluation_protocol: Optional[EvalProtocol] = None, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = None, device=None, plugins: Optional[List[StrategyPlugin]] = None)

   Bases: :class:`avalanche.training.strategies.base_strategy.BaseStrategy`

   GDumb strategy. See GDumbPlugin for more details.

   :param model: The model.
   :param optimizer: The optimizer to use.
   :param criterion: The loss criterion to use.
   :param mem_size: replay buffer size.
   :param evaluation_protocol: The evaluation plugin.
   :param train_mb_size: The train minibatch size. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The test minibatch size. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param plugins: Plugins to be added. Defaults to None.


.. py:class:: Cumulative(model: Module, optimizer: Optimizer, criterion, evaluation_protocol: Optional[EvalProtocol] = None, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = None, device=None, plugins: Optional[List[StrategyPlugin]] = None)

   Bases: :class:`avalanche.training.strategies.base_strategy.BaseStrategy`

   Cumulative strategy. At each step,
       train model with data from all previous steps and current step.

   :param model: The model.
   :param optimizer: The optimizer to use.
   :param criterion: The loss criterion to use.
   :param evaluation_protocol: The evaluation plugin.
   :param train_mb_size: The train minibatch size. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The test minibatch size. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param plugins: Plugins to be added. Defaults to None.

   .. method:: adapt_train_dataset(self, **kwargs)

      Called after the dataset initialization and before the
      dataloader initialization. Allows to customize the dataset.
      :param kwargs:
      :return:



.. py:class:: LwF(model: Module, optimizer: Optimizer, criterion, alpha: Union[float, Sequence[float]], temperature: float, evaluation_protocol: Optional[EvalProtocol] = None, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = None, device=None, plugins: Optional[List[StrategyPlugin]] = None)

   Bases: :class:`avalanche.training.strategies.base_strategy.BaseStrategy`

   Learning without Forgetting strategy. 
       See LwF plugin for details.

   :param model: The model.
   :param optimizer: The optimizer to use.
   :param criterion: The loss criterion to use.
   :param alpha: distillation hyperparameter. It can be either a float
           number or a list containing alpha for each step.
   :param temperature: softmax temperature for distillation
   :param evaluation_protocol: The evaluation plugin.
   :param train_mb_size: The train minibatch size. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The test minibatch size. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param plugins: Plugins to be added. Defaults to None.


.. py:class:: AGEM(model: Module, optimizer: Optimizer, criterion, patterns_per_step: int, sample_size: int = 64, evaluation_protocol: Optional[EvalProtocol] = None, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = None, device=None, plugins: Optional[List[StrategyPlugin]] = None)

   Bases: :class:`avalanche.training.strategies.base_strategy.BaseStrategy`

   Average Gradient Episodic Memory (A-GEM) strategy. 
       See AGEM plugin for details.

   :param model: The model.
   :param optimizer: The optimizer to use.
   :param criterion: The loss criterion to use.
   :param patterns_per_step: number of patterns per step in the memory
   :param sample_size: number of patterns in memory sample when computing
       reference gradient.        
   :param evaluation_protocol: The evaluation plugin.
   :param train_mb_size: The train minibatch size. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The test minibatch size. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param plugins: Plugins to be added. Defaults to None.


.. py:class:: GEM(model: Module, optimizer: Optimizer, criterion, patterns_per_step: int, memory_strength: float = 0.5, evaluation_protocol: Optional[EvalProtocol] = None, train_mb_size: int = 1, train_epochs: int = 1, test_mb_size: int = None, device=None, plugins: Optional[List[StrategyPlugin]] = None)

   Bases: :class:`avalanche.training.strategies.base_strategy.BaseStrategy`

   Gradient Episodic Memory (GEM) strategy. 
       See GEM plugin for details.

   :param model: The model.
   :param optimizer: The optimizer to use.
   :param criterion: The loss criterion to use.
   :param patterns_per_step: number of patterns per step in the memory
   :param memory_strength: offset to add to the projection direction
       in order to favour backward transfer (gamma in original paper).
   :param evaluation_protocol: The evaluation plugin.
   :param train_mb_size: The train minibatch size. Defaults to 1.
   :param train_epochs: The number of training epochs. Defaults to 1.
   :param test_mb_size: The test minibatch size. Defaults to 1.
   :param device: The device to use. Defaults to None (cpu).
   :param plugins: Plugins to be added. Defaults to None.


