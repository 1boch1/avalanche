:mod:`avalanche.training.utils`
===============================

.. py:module:: avalanche.training.utils


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   transform_dataset/index.rst
   utils/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.training.utils.IDataset
   avalanche.training.utils.IDatasetWithTargets
   avalanche.training.utils.DatasetWithTargets
   avalanche.training.utils.TransformationDataset
   avalanche.training.utils.TransformationSubset
   avalanche.training.utils.ConcatDatasetWithTargets
   avalanche.training.utils.TransformationTensorDataset



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.training.utils.get_accuracy
   avalanche.training.utils.train_net
   avalanche.training.utils.preprocess_imgs
   avalanche.training.utils.maybe_cuda
   avalanche.training.utils.change_lr
   avalanche.training.utils.set_classifier
   avalanche.training.utils.reset_classifier
   avalanche.training.utils.shuffle_in_unison
   avalanche.training.utils.softmax
   avalanche.training.utils.count_lines
   avalanche.training.utils.pad_data
   avalanche.training.utils.compute_one_hot
   avalanche.training.utils.imagenet_batch_preproc
   avalanche.training.utils.load_all_dataset
   avalanche.training.utils.concat_datasets_sequentially


.. function:: get_accuracy(model, criterion, batch_size, test_x, test_y, test_it, device=None, mask=None)

   Test accuracy given net and data. 


.. function:: train_net(optimizer, model, criterion, batch_size, train_x, train_y, train_it, device=None, mask=None)

   Train net from memory using pytorch 


.. function:: preprocess_imgs(img_batch, scale=True, norm=True, channel_first=True)

   Here we get a batch of PIL imgs and we return them normalized as for
   the pytorch pre-trained models. 


.. function:: maybe_cuda(what, use_cuda=True, **kw)

   Moves `what` to CUDA and returns it, if `use_cuda` and it's available.
       


.. function:: change_lr(optimizer, lr)

   Change the learning rate of the optimizer


.. function:: set_classifier(model, weigth, bias, clas=None)

   Change weights and biases of the last layer in the network. 


.. function:: reset_classifier(model, val=0, std=None)

   Set weights and biases of the last layer in the network to zero. 


.. function:: shuffle_in_unison(dataset, seed=None, in_place=False)

   Shuffle two (or more) list in unison. It's important to shuffle the images
   and the labels maintaining their correspondence.

   :args dataset: list of shuffle with the same order.
   :args seed: set of fixed Cifar parameters.
   :args in_place: if we want to shuffle the same data or we want
                    to return a new shuffled dataset.

   :return: train and test sets composed of images and labels, if in_place
       is set to False.


.. function:: softmax(x)

   Compute softmax values for each sets of scores in x. 


.. function:: count_lines(fpath)

   Count line in file. 


.. function:: pad_data(dataset, mb_size)

   Padding all the matrices contained in dataset to suit the mini-batch
   size. We assume they have the same shape. 


.. function:: compute_one_hot(train_y, class_count)

   Compute one-hot from labels. 


.. function:: imagenet_batch_preproc(img_batch, rgb_swap=True, channel_first=True, avg_sub=True)

   Pre-process batch of PIL img for Imagenet pre-trained models with caffe.
   It may be need adjustements depending on the pre-trained model
   since it is training dependent. 


.. function:: load_all_dataset(dataset: Dataset, num_workers: int = 0)

   Retrieves the contents of a whole dataset by using a DataLoader

   :param dataset: The dataset
   :param num_workers: The number of workers the DataLoader should use.
       Defaults to 0.
   :return: The content of the whole Dataset


.. py:class:: IDataset

   Bases: :class:`Protocol[T_co]`

   Protocol definition of a Dataset.

   Note: no __add__ method is defined.

   .. method:: __getitem__(self, index: int) -> T_co


   .. method:: __len__(self) -> int



.. py:class:: IDatasetWithTargets

   Bases: :class:`IDataset[T_co]`, :class:`typing.Protocol`

   Protocol definition of a Dataset that has a valid targets field (like the
   Datasets in the torchvision package)

   Create and return a new object.  See help(type) for accurate signature.

   .. attribute:: targets
      :annotation: :Sequence[int]

      


.. py:class:: DatasetWithTargets

   Bases: :class:`IDatasetWithTargets[T_co]`, :class:`torch.utils.data.Dataset`

   Dataset that has a valid targets field (like the Datasets in the
   torchvision package)

   The actual value of the targets field should be set by the child class.

   Initialize self.  See help(type(self)) for accurate signature.


.. py:class:: TransformationDataset(dataset: IDatasetWithTargets, transform=None, target_transform=None)

   Bases: :class:`avalanche.training.utils.transform_dataset.DatasetWithTargets`

   A Dataset that applies transformations before returning patterns/targets.
   Also, this Dataset supports basic slicing and advanced indexing.

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: __getitem__(self, idx)


   .. method:: __len__(self) -> int


   .. method:: __get_single_item(self, idx: int)



.. py:class:: TransformationSubset(dataset: IDatasetWithTargets, indices: Union[Sequence[int], None], transform=None, target_transform=None, class_mapping: Optional[Sequence[int]] = None)

   Bases: :class:`avalanche.training.utils.transform_dataset.DatasetWithTargets`

   A Dataset that behaves like a pytorch :class:`torch.utils.data.Subset`,
   with all the goodness of :class:`TransformationDataset`

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: __getitem__(self, idx)


   .. method:: __len__(self) -> int


   .. method:: __get_single_item(self, idx: int)



.. py:class:: ConcatDatasetWithTargets(datasets: Sequence[IDatasetWithTargets])

   Bases: :class:`avalanche.training.utils.transform_dataset.DatasetWithTargets`

   A Dataset that behaves like a pytorch
   :class:`torch.utils.data.ConcatDataset`. However, this dataset also
   supports basic slicing and advanced indexing and also has a targets field.

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: __getitem__(self, idx)


   .. method:: __len__(self) -> int


   .. method:: __get_single_item(self, idx: int)



.. function:: concat_datasets_sequentially(train_dataset_list: Sequence[IDatasetWithTargets], test_dataset_list: Sequence[IDatasetWithTargets])

   Concatenates a list of datasets. This is completely different from
   :class:`ConcatDataset`, in which datasets are merged together without
   other processing. Instead, this function re-maps the datasets class IDs.
   For instance:
   let the dataset[0] contain patterns of 3 different classes,
   let the dataset[1] contain patterns of 2 different classes, then class IDs
   will be mapped as follows:

   dataset[0] class "0" -> new class ID is "0"

   dataset[0] class "1" -> new class ID is "1"

   dataset[0] class "2" -> new class ID is "2"

   dataset[1] class "0" -> new class ID is "3"

   dataset[1] class "1" -> new classID is "4"

   ... -> ...

   dataset[N-1] class "C-1" -> new class ID is "overall_n_classes-1"

   In contract, using PyTorch ConcatDataset:

   dataset[0] class "0" -> ID is "0"

   dataset[0] class "1" -> ID is "1"

   dataset[0] class "2" -> ID is "2"

   dataset[1] class "0" -> ID is "0"

   dataset[1] class "1" -> ID is "1"

   Note: ``train_dataset_list`` and ``test_dataset_list`` must have the same
   number of datasets.

   :param train_dataset_list: A list of training datasets
   :param test_dataset_list: A list of test datasets

   :returns: A concatenated dataset.


.. py:class:: TransformationTensorDataset(dataset_x: Sequence[Any], dataset_y: Sequence[SupportsInt], transform=None, target_transform=None)

   Bases: :class:`avalanche.training.utils.transform_dataset.DatasetWithTargets`

   A Dataset that wraps existing ndarrays, Tensors, lists... to provide
   basic Dataset functionalities. Very similar to TensorDataset from PyTorch,
   this Dataset also supports transformations, basic slicing and advanced
   indexing and the targets field.

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: __getitem__(self, idx)


   .. method:: __len__(self) -> int


   .. method:: __get_single_item(self, idx: int)



