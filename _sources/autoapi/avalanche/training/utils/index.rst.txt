:mod:`avalanche.training.utils`
===============================

.. py:module:: avalanche.training.utils


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   dataset_utils/index.rst
   transform_dataset/index.rst
   utils/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.training.utils.IDataset
   avalanche.training.utils.IDatasetWithTargets
   avalanche.training.utils.IDatasetWithIntTargets
   avalanche.training.utils.DatasetWithTargets
   avalanche.training.utils.LazyClassMapping
   avalanche.training.utils.LazyConcatTargets
   avalanche.training.utils.LazyTargetsConversion
   avalanche.training.utils.SubsetWithTargets
   avalanche.training.utils.ConcatDatasetWithTargets
   avalanche.training.utils.SequenceDataset
   avalanche.training.utils.TransformationDataset
   avalanche.training.utils.TransformationSubset
   avalanche.training.utils.TransformationConcatDataset
   avalanche.training.utils.TransformationTensorDataset



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.training.utils.get_accuracy
   avalanche.training.utils.train_net
   avalanche.training.utils.preprocess_imgs
   avalanche.training.utils.maybe_cuda
   avalanche.training.utils.change_lr
   avalanche.training.utils.set_classifier
   avalanche.training.utils.reset_classifier
   avalanche.training.utils.shuffle_in_unison
   avalanche.training.utils.softmax
   avalanche.training.utils.count_lines
   avalanche.training.utils.pad_data
   avalanche.training.utils.compute_one_hot
   avalanche.training.utils.imagenet_batch_preproc
   avalanche.training.utils.load_all_dataset
   avalanche.training.utils.find_list_from_index
   avalanche.training.utils.manage_advanced_indexing
   avalanche.training.utils.concat_datasets_sequentially
   avalanche.training.utils.as_transformation_dataset
   avalanche.training.utils.train_test_transformation_datasets


.. function:: get_accuracy(model, criterion, batch_size, test_x, test_y, test_it, device=None, mask=None)

   Test accuracy given net and data. 


.. function:: train_net(optimizer, model, criterion, batch_size, train_x, train_y, train_it, device=None, mask=None)

   Train net from memory using pytorch 


.. function:: preprocess_imgs(img_batch, scale=True, norm=True, channel_first=True)

   Here we get a batch of PIL imgs and we return them normalized as for
   the pytorch pre-trained models. 


.. function:: maybe_cuda(what, use_cuda=True, **kw)

   Moves `what` to CUDA and returns it, if `use_cuda` and it's available.
       


.. function:: change_lr(optimizer, lr)

   Change the learning rate of the optimizer


.. function:: set_classifier(model, weigth, bias, clas=None)

   Change weights and biases of the last layer in the network. 


.. function:: reset_classifier(model, val=0, std=None)

   Set weights and biases of the last layer in the network to zero. 


.. function:: shuffle_in_unison(dataset, seed=None, in_place=False)

   Shuffle two (or more) list in unison. It's important to shuffle the images
   and the labels maintaining their correspondence.

   :args dataset: list of shuffle with the same order.
   :args seed: set of fixed Cifar parameters.
   :args in_place: if we want to shuffle the same data or we want
                    to return a new shuffled dataset.

   :return: train and test sets composed of images and labels, if in_place
       is set to False.


.. function:: softmax(x)

   Compute softmax values for each sets of scores in x. 


.. function:: count_lines(fpath)

   Count line in file. 


.. function:: pad_data(dataset, mb_size)

   Padding all the matrices contained in dataset to suit the mini-batch
   size. We assume they have the same shape. 


.. function:: compute_one_hot(train_y, class_count)

   Compute one-hot from labels. 


.. function:: imagenet_batch_preproc(img_batch, rgb_swap=True, channel_first=True, avg_sub=True)

   Pre-process batch of PIL img for Imagenet pre-trained models with caffe.
   It may be need adjustements depending on the pre-trained model
   since it is training dependent. 


.. function:: load_all_dataset(dataset: Dataset, num_workers: int = 0)

   Retrieves the contents of a whole dataset by using a DataLoader

   :param dataset: The dataset
   :param num_workers: The number of workers the DataLoader should use.
       Defaults to 0.
   :return: The content of the whole Dataset


.. py:class:: IDataset

   Bases: :class:`Protocol[T_co]`

   Protocol definition of a Dataset.

   Note: no __add__ method is defined.

   .. method:: __getitem__(self, index: int) -> Tuple[T_co, int]


   .. method:: __len__(self) -> int



.. py:class:: IDatasetWithTargets

   Bases: :class:`IDataset[T_co]`, :class:`typing.Protocol`

   Protocol definition of a Dataset that has a valid targets field (like the
   Datasets in the torchvision package).

   Note: no __add__ method is defined.

   Create and return a new object.  See help(type) for accurate signature.

   .. attribute:: targets
      :annotation: :Sequence[SupportsInt]

      A sequence of ints or a PyTorch Tensor or a NumPy ndarray describing the
      label of each pattern contained in the dataset.


   .. method:: __getitem__(self, index: int) -> Tuple[T_co, int]


   .. method:: __len__(self) -> int



.. py:class:: IDatasetWithIntTargets

   Bases: :class:`IDatasetWithTargets[T_co]`, :class:`typing.Protocol`

   Protocol definition of a Dataset that has a valid targets field (like the
   Datasets in the torchvision package) where the targets field is a sequence
   of native ints.

   Create and return a new object.  See help(type) for accurate signature.

   .. attribute:: targets
      :annotation: :Sequence[int]

      A sequence of ints describing the label of each pattern contained in the
      dataset.


   .. method:: __getitem__(self, index: int) -> Tuple[T_co, int]


   .. method:: __len__(self) -> int



.. py:class:: DatasetWithTargets

   Bases: :class:`IDatasetWithIntTargets[T_co]`, :class:`torch.utils.data.dataset.Dataset`

   Dataset that has a valid targets field (like the Datasets in the
   torchvision package) where the targets field is a sequence of native ints.

   The actual value of the targets field should be set by the child class.

   .. attribute:: targets
      :annotation: = []

      A sequence of ints describing the label of each pattern contained in the
      dataset.



.. py:class:: LazyClassMapping(targets: Sequence[SupportsInt], indices: Union[Sequence[int], None], mapping: Optional[Sequence[int]] = None)

   Bases: :class:`Sequence[int]`

   This class is used when in need of lazy populating a targets field whose
   elements need to be filtered out (when subsetting, see
   :class:`torch.utils.data.Subset`) and/or transformed (remapped). This will
   allow for a more efficient memory usage as the conversion is done on the fly
   instead of actually allocating a new targets list.

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: __len__(self)


   .. method:: __getitem__(self, item_idx) -> int


   .. method:: __str__(self)

      Return str(self).



.. py:class:: LazyConcatTargets(targets_list: Sequence[Sequence[SupportsInt]])

   Bases: :class:`Sequence[int]`

   Defines a lazy targets concatenation.

   This class is used when in need of lazy populating a targets created
   as the concatenation of the targets field of multiple datasets.
   This will allow for a more efficient memory usage as the concatenation is
   done on the fly instead of actually allocating a new targets list.

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: __len__(self)


   .. method:: __getitem__(self, item_idx) -> int


   .. method:: __str__(self)

      Return str(self).



.. py:class:: LazyTargetsConversion(targets: Sequence[SupportsInt])

   Bases: :class:`Sequence[int]`

   Defines a lazy conversion of targets defined in some other format.

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: __len__(self)


   .. method:: __getitem__(self, item_idx) -> int


   .. method:: __str__(self)

      Return str(self).



.. py:class:: SubsetWithTargets(dataset: IDatasetWithTargets[T_co], indices: Union[Sequence[int], None], class_mapping: Optional[Sequence[int]] = None)

   Bases: :class:`DatasetWithTargets[T_co]`

   A Dataset that behaves like a PyTorch :class:`torch.utils.data.Subset`.
   However, this dataset also supports the targets field and class mapping.

   .. method:: __getitem__(self, idx)


   .. method:: __len__(self) -> int



.. py:class:: ConcatDatasetWithTargets(datasets: Sequence[IDatasetWithTargets[T_co]])

   Bases: :class:`DatasetWithTargets[T_co]`

   A Dataset that behaves like a PyTorch
   :class:`torch.utils.data.ConcatDataset`. However, this dataset also
   supports the targets field.

   .. method:: __getitem__(self, idx)


   .. method:: __len__(self) -> int



.. py:class:: SequenceDataset(dataset_x: Sequence[T_co], dataset_y: Sequence[SupportsInt])

   Bases: :class:`DatasetWithTargets[T_co]`

   A Dataset that wraps existing ndarrays, Tensors, lists... to provide
   basic Dataset functionalities. Very similar to TensorDataset.

   Creates a ``SequenceDataset`` instance.

   :param dataset_x: An sequence, Tensor or ndarray representing the X
       values of the patterns.
   :param dataset_y: An sequence, Tensor int or ndarray of integers
       representing the Y values of the patterns.

   .. method:: __getitem__(self, idx)


   .. method:: __len__(self) -> int



.. function:: find_list_from_index(pattern_idx: int, list_sizes: Sequence[int], max_size: int)


.. function:: manage_advanced_indexing(idx, single_element_getter, max_length)

   Utility function used to manage the advanced indexing and slicing.

   If more than a pattern is selected, the X and Y values will be merged
   in two separate torch Tensor objects using the stack operation.

   :param idx: Either an in, a slice object or a list (including ndarrays and
       torch Tensors) of indexes.
   :param single_element_getter: A callable used to obtain a single element
       given its int index.
   :param max_length: The maximum sequence length.
   :return: A tuple consisting of two tensors containing the X and Y values
       of the patterns addressed by the idx parameter.


.. py:class:: TransformationDataset(dataset: IDatasetWithTargets[T_co], *, transform: XTransform = None, target_transform: YTransform = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group='train')

   Bases: :class:`DatasetWithTargets[T_co]`, :class:`Generic[T_co]`

   A Dataset that applies transformations before returning patterns/targets.
   Also, this Dataset supports slicing and advanced indexing.

   This dataset can also be used to apply several operations involving
   transformations. For instance, it allows the user to add and replace
   transformations, freeze them so that they can't be changed, etc.

   This dataset also allows the user to keep distinct transformations groups.
   Simply put, a transformation group is a pair of transform+target_transform
   (exactly as in torchvision datasets). This dataset natively supports keeping
   two transformation groups: the first, 'train', contains transformations
   applied to training patterns. Those transformations usually involve some
   kind of data augmentation. The second one is 'test', that will contain
   transformations applied to test patterns. Having both groups can be
   useful when, for instance, in need to test on the training data (as this
   process usually involves removing data augmentation operations). Switching
   between transformations can be easily achieved by using the
   :func:`train` and :func:`eval` method.

   However, consider that arbitrary groups can be used. For more info see
   the constructor and the :func:`with_transforms` method.

   Creates a ``TransformationDataset`` instance.

   :param dataset: The dataset to decorate. Beware that
       TransformationDataset will not overwrite transformations already
       applied by this dataset.
   :param transform: A function/transform that takes the X value of a
       pattern from the original dataset and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       test transformations. This becomes useful when in need to test on
       the training dataset as test transformations usually don't contain
       random augmentations. ``TransformDataset`` natively supports the
       'train' and 'test' groups by calling the ``train()`` and ``eval()``
       methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'test' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the transform group
       to be used. Defaults to 'train'.

   .. attribute:: _dataset
      :annotation: :IDatasetWithTargets[T_co]

      The original dataset.


   .. attribute:: targets
      :annotation: :Sequence[int]

      A sequence of ints describing the label of each pattern contained in the
      dataset.


   .. attribute:: current_transform_group
      

      The name of the transform group currently in use.


   .. attribute:: transform_groups
      :annotation: :Dict[str, Tuple[XTransform, YTransform]]

      A dictionary containing the transform groups. Transform groups are
      used to quickly switch between training and test transformations.
      This becomes useful when in need to test on the training dataset as test
      transformations usually don't contain random augmentations.

      TransformDataset natively supports switching between the 'train' and
      'test' groups by calling the ``train()`` and ``eval()`` methods. When
      using custom groups one can use the ``with_transforms(group_name)``
      method instead.

      May be null, which means that the current transforms will be used to
      handle both 'train' and 'test' groups.


   .. attribute:: transform
      :annotation: :XTransform

      A function/transform that takes in an PIL image and returns a 
      transformed version.


   .. attribute:: target_transform
      :annotation: :YTransform

      A function/transform that takes in the target and transforms it.


   .. attribute:: _frozen_transforms
      :annotation: :Dict[str, Tuple[XTransform, YTransform]]

      A dictionary containing frozen transformations.


   .. method:: __getitem__(self, idx)


   .. method:: __len__(self)


   .. method:: train(self)

      Returns a new dataset with the transformations of a the 'train' group
      loaded.

      The current dataset will not be affected.

      :return: A new dataset with the training transformations loaded.


   .. method:: eval(self)

      Returns a new dataset with the transformations of a the 'test' group
      loaded.

      Test transformations usually don't contain augmentation procedures.
      This function may be useful when in need to test on training data
      (for instance, in order to run a validation pass).

      The current dataset will not be affected.

      :return: A new dataset with the test transformations loaded.


   .. method:: freeze_transforms(self: TTransformationDataset) -> TTransformationDataset

      Returns a new dataset where the current transformations are frozen.

      Frozen transformations will be permanently glued to the original
      dataset so that they can't be changed anymore. This is usually done
      when using transformations to create derived datasets: in this way
      freezing the transformations will ensure that the user won't be able
      to inadvertently change them by directly setting the transformations
      field or by using the other transformations utility methods like
      ``replace_transforms``. Please note that transformations of all groups
      will be frozen. If you want to freeze a specific group, please use
      ``freeze_group_transforms``.

      The current dataset will not be affected.

      :return: A new dataset with the current transformations frozen.


   .. method:: freeze_group_transforms(self: TTransformationDataset, group_name: str) -> TTransformationDataset

      Returns a new dataset where the transformations for a specific group
      are frozen.

      Frozen transformations will be permanently glued to the original
      dataset so that they can't be changed anymore. This is usually done
      when using transformations to create derived datasets: in this way
      freezing the transformations will ensure that the user won't be able
      to inadvertently change them by directly setting the transformations
      field or by using the other transformations utility methods like
      ``replace_transforms``. To freeze transformations of all groups
      please use ``freeze_transforms``.

      The current dataset will not be affected.

      :return: A new dataset with the transformations frozen for the given
          group.


   .. method:: add_transforms(self: TTransformationDataset, transform: Callable[[T_co], Any] = None, target_transform: Callable[[int], int] = None) -> TTransformationDataset

      Returns a new dataset with the given transformations added to
      the existing ones.

      The transformations will be added to the current transformations group.
      Other transformation groups will not be affected.

      The given transformations will be added "at the end" of previous
      transformations of the current transformations group. This means
      that existing transformations will be applied to the patterns first.

      The current dataset will not be affected.

      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :return: A new dataset with the added transformations.


   .. method:: replace_transforms(self: TTransformationDataset, transform: XTransform, target_transform: YTransform) -> TTransformationDataset

      Returns a new dataset with the existing transformations replaced with
      the given ones.

      The given transformations will replace the ones of the current
      transformations group. Other transformation groups will not be affected.

      If this dataset was created with ``chain_transformations`` set to True
      and if the original dataset is an instance of
      :class:`TransformationDataset`, then the transformations of the
      original set will be overwritten as well. This operation will create a
      copy of this dataset.

      The current dataset will not be affected.

      Note that this function will not override frozen transformations. This
      will also not affect transformations found in datasets that are not
      instances of :class:`TransformationDataset`.

      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :return: A new dataset with the new transformations.


   .. method:: with_transforms(self: TTransformationDataset, group_name: str) -> TTransformationDataset

      Returns a new dataset with the transformations of a different group
      loaded.

      The current dataset will not be affected.

      :param group_name: The name of the transformations group to use.
      :return: A new dataset with the new transformations.


   .. method:: add_transforms_group(self: TTransformationDataset, group_name: str, transform: XTransform, target_transform: YTransform) -> TTransformationDataset

      Returns a new dataset with a new transformations group.

      The current dataset will not be affected.

      This method raises an exception if a group with the same name already
      exists.

      :param group_name: The name of the new transformations group.
      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :return: A new dataset with the new transformations.


   .. method:: _fork_dataset(self: TTransformationDataset) -> TTransformationDataset


   .. method:: _freeze_dataset_group(dataset_copy: TTransformationDataset, group_name: str)
      :staticmethod:


   .. method:: _get_single_item(self, idx: int)


   .. method:: _apply_transforms(self, pattern: T_co, label: int)


   .. method:: _check_groups_dict_format(groups_dict)
      :staticmethod:


   .. method:: _initialize_groups_dict(self, transform_groups: Optional[Dict[str, Tuple[XTransform, YTransform]]], dataset: Any, transform: XTransform, target_transform: YTransform) -> Dict[str, Tuple[XTransform, YTransform]]

      A simple helper method that tries to fill the 'train' and 'test'
      groups as those two groups must always exist.

      If no transform_groups are passed to the class constructor, then
      the transform and target_transform parameters are used for both groups.

      If train transformations are set and test transformations are not, then
      train transformations will be used for the test group.

      :param dataset: The original dataset. Will be used to detect existing
          groups.
      :param transform: The transformation passed as a parameter to the
          class constructor.
      :param target_transform: The target transformation passed as a parameter
          to the class constructor.


   .. method:: _initialize_targets_sequence(self, dataset) -> Sequence[int]


   .. method:: _set_original_dataset_transform_group(self, group_name: str) -> None


   .. method:: _freeze_original_dataset(self, group_name: str) -> None


   .. method:: _replace_original_dataset_group(self, transform: XTransform, target_transform: YTransform) -> None


   .. method:: _add_original_dataset_group(self, group_name: str) -> None


   .. method:: _add_groups_from_original_dataset(self, dataset, transform_groups) -> None



.. py:class:: TransformationSubset(dataset: IDatasetWithTargets[T_co], *, indices: Sequence[int] = None, class_mapping: Sequence[int] = None, transform: Callable[[T_co], Any] = None, target_transform: Callable[[int], int] = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group='train')

   Bases: :class:`TransformationDataset[T_co]`

   A Dataset that behaves like a PyTorch :class:`torch.utils.data.Subset`.
   This Dataset also supports transformations, slicing, advanced indexing,
   the targets field and class mapping.

   Creates a ``TransformationSubset`` instance.

   :param dataset: The whole dataset.
   :param indices: Indices in the whole set selected for subset. Can
       be None, which means that the whole dataset will be returned.
   :param class_mapping: A list that, for each possible target (Y) value,
       contains its corresponding remapped value. Can be None.
   :param transform: A function/transform that takes the X value of a
       pattern from the original dataset and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       test transformations. This becomes useful when in need to test on
       the training dataset as test transformations usually don't contain
       random augmentations. ``TransformDataset`` natively supports the
       'train' and 'test' groups by calling the ``train()`` and ``eval()``
       methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'test' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the transform group
       to be used. Defaults to 'train'.


.. py:class:: TransformationConcatDataset(datasets: Sequence[IDatasetWithTargets[T_co]], *, transform: Callable[[T_co], Any] = None, target_transform: Callable[[int], int] = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group='train')

   Bases: :class:`TransformationDataset[T_co]`

   A Dataset that behaves like a PyTorch
   :class:`torch.utils.data.ConcatDataset`. However, this Dataset also supports
   transformations, slicing, advanced indexing and the targets field.

   This dataset guarantees that the operations involving the transformations
   and transformations groups are consistent across the concatenated dataset
   (if they are subclasses of :class:`TransformationDataset`).

   Creates a ``TransformationConcatDataset`` instance.

   :param datasets: An sequence of datasets.
   :param transform: A function/transform that takes the X value of a
       pattern from the original dataset and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       test transformations. This becomes useful when in need to test on
       the training dataset as test transformations usually don't contain
       random augmentations. ``TransformDataset`` natively supports the
       'train' and 'test' groups by calling the ``train()`` and ``eval()``
       methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'test' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the transform group
       to be used. Defaults to 'train'.

   .. method:: __len__(self) -> int


   .. method:: _get_single_item(self, idx: int)


   .. method:: _fork_dataset(self: TTransformationDataset) -> TTransformationDataset


   .. method:: _initialize_targets_sequence(self, dataset) -> Sequence[int]


   .. method:: _set_original_dataset_transform_group(self, group_name: str) -> None


   .. method:: _freeze_original_dataset(self, group_name: str) -> None


   .. method:: _replace_original_dataset_group(self, transform: XTransform, target_transform: YTransform) -> None


   .. method:: _add_original_dataset_group(self, group_name: str) -> None


   .. method:: _add_groups_from_original_dataset(self, dataset, transform_groups) -> None


   .. method:: _adapt_concat_datasets(self)



.. py:class:: TransformationTensorDataset(dataset_x: Sequence[T_co], dataset_y: Sequence[SupportsInt], *, transform: Callable[[T_co], Any] = None, target_transform: Callable[[int], int] = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group='train')

   Bases: :class:`TransformationDataset[T_co]`

   A Dataset that wraps existing ndarrays, Tensors, lists... to provide
   basic Dataset functionalities. Very similar to TensorDataset from PyTorch,
   this Dataset also supports transformations, slicing, advanced indexing and
   the targets field.

   Creates a ``TransformationTensorDataset`` instance.

   :param dataset_x: An sequence, Tensor or ndarray representing the X
       values of the patterns.
   :param dataset_y: An sequence, Tensor int or ndarray of integers
       representing the Y values of the patterns.
   :param transform: A function/transform that takes in a single element
       from the ``dataset_x`` sequence and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       test transformations. This becomes useful when in need to test on
       the training dataset as test transformations usually don't contain
       random augmentations. ``TransformDataset`` natively supports the
       'train' and 'test' groups by calling the ``train()`` and ``eval()``
       methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'test' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the transform group
       to be used. Defaults to 'train'.


.. function:: concat_datasets_sequentially(train_dataset_list: Sequence[IDatasetWithTargets[T_co]], test_dataset_list: Sequence[IDatasetWithTargets[T_co]]) -> Tuple[TransformationConcatDataset[T_co], TransformationConcatDataset[T_co], List[list]]

   Concatenates a list of datasets. This is completely different from
   :class:`ConcatDataset`, in which datasets are merged together without
   other processing. Instead, this function re-maps the datasets class IDs.
   For instance:
   let the dataset[0] contain patterns of 3 different classes,
   let the dataset[1] contain patterns of 2 different classes, then class IDs
   will be mapped as follows:

   dataset[0] class "0" -> new class ID is "0"

   dataset[0] class "1" -> new class ID is "1"

   dataset[0] class "2" -> new class ID is "2"

   dataset[1] class "0" -> new class ID is "3"

   dataset[1] class "1" -> new class ID is "4"

   ... -> ...

   dataset[-1] class "C-1" -> new class ID is "overall_n_classes-1"

   In contrast, using PyTorch ConcatDataset:

   dataset[0] class "0" -> ID is "0"

   dataset[0] class "1" -> ID is "1"

   dataset[0] class "2" -> ID is "2"

   dataset[1] class "0" -> ID is "0"

   dataset[1] class "1" -> ID is "1"

   Note: ``train_dataset_list`` and ``test_dataset_list`` must have the same
   number of datasets.

   :param train_dataset_list: A list of training datasets
   :param test_dataset_list: A list of test datasets

   :returns: A concatenated dataset.


.. function:: as_transformation_dataset(dataset: IDatasetWithTargets[T_co]) -> TransformationDataset[T_co]


.. function:: train_test_transformation_datasets(train_dataset: IDatasetWithTargets[T_co], test_dataset: IDatasetWithTargets[T_co], train_transformation, test_transformation)


