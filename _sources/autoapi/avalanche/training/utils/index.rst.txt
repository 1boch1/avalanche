:mod:`avalanche.training.utils`
===============================

.. py:module:: avalanche.training.utils

.. autoapi-nested-parse::

   General useful functions for pytorch.



Module Contents
---------------


Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.training.utils.get_accuracy
   avalanche.training.utils.train_net
   avalanche.training.utils.preprocess_imgs
   avalanche.training.utils.maybe_cuda
   avalanche.training.utils.change_lr
   avalanche.training.utils.set_classifier
   avalanche.training.utils.reset_classifier
   avalanche.training.utils.shuffle_in_unison
   avalanche.training.utils.softmax
   avalanche.training.utils.count_lines
   avalanche.training.utils.pad_data
   avalanche.training.utils.compute_one_hot
   avalanche.training.utils.imagenet_batch_preproc
   avalanche.training.utils.load_all_dataset
   avalanche.training.utils.zerolike_params_dict
   avalanche.training.utils.copy_params_dict


.. function:: get_accuracy(model, criterion, batch_size, test_x, test_y, test_it, device=None, mask=None)

   Test accuracy given net and data. 


.. function:: train_net(optimizer, model, criterion, batch_size, train_x, train_y, train_it, device=None, mask=None)

   Train net from memory using pytorch 


.. function:: preprocess_imgs(img_batch, scale=True, norm=True, channel_first=True)

   Here we get a batch of PIL imgs and we return them normalized as for
   the pytorch pre-trained models. 


.. function:: maybe_cuda(what, use_cuda=True, **kw)

   Moves `what` to CUDA and returns it, if `use_cuda` and it's available.
       


.. function:: change_lr(optimizer, lr)

   Change the learning rate of the optimizer


.. function:: set_classifier(model, weigth, bias, clas=None)

   Change weights and biases of the last layer in the network. 


.. function:: reset_classifier(model, val=0, std=None)

   Set weights and biases of the last layer in the network to zero. 


.. function:: shuffle_in_unison(dataset, seed=None, in_place=False)

   Shuffle two (or more) list in unison. It's important to shuffle the images
   and the labels maintaining their correspondence.

   :args dataset: list of shuffle with the same order.
   :args seed: set of fixed Cifar parameters.
   :args in_place: if we want to shuffle the same data or we want
                    to return a new shuffled dataset.

   :return: train and test sets composed of images and labels, if in_place
       is set to False.


.. function:: softmax(x)

   Compute softmax values for each sets of scores in x. 


.. function:: count_lines(fpath)

   Count line in file. 


.. function:: pad_data(dataset, mb_size)

   Padding all the matrices contained in dataset to suit the mini-batch
   size. We assume they have the same shape. 


.. function:: compute_one_hot(train_y, class_count)

   Compute one-hot from labels. 


.. function:: imagenet_batch_preproc(img_batch, rgb_swap=True, channel_first=True, avg_sub=True)

   Pre-process batch of PIL img for Imagenet pre-trained models with caffe.
   It may be need adjustements depending on the pre-trained model
   since it is training dependent. 


.. function:: load_all_dataset(dataset: Dataset, num_workers: int = 0)

   Retrieves the contents of a whole dataset by using a DataLoader

   :param dataset: The dataset
   :param num_workers: The number of workers the DataLoader should use.
       Defaults to 0.
   :return: The content of the whole Dataset


.. function:: zerolike_params_dict(model)

   Create a list of (name, parameter), where parameter is initalized to zero.
   The list has as many parameters as model, with the same size.

   :param model: a pytorch model


.. function:: copy_params_dict(model, copy_grad=False)

   Create a list of (name, parameter), where parameter is copied from model.
   The list has as many parameters as model, with the same size.

   :param model: a pytorch model
   :param copy_grad: if True returns gradients instead of parameter values


