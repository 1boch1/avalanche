:mod:`avalanche.training.plugins`
=================================

.. py:module:: avalanche.training.plugins


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   evaluation_plugin/index.rst
   gdumb_plugin/index.rst
   replay_plugin/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.training.plugins.EvaluationPlugin
   avalanche.training.plugins.ReplayPlugin
   avalanche.training.plugins.GDumbPlugin



.. py:class:: EvaluationPlugin

   Bases: :class:`avalanche.training.skeletons.StrategySkeleton`

   An evaluation plugin that can be plugged in a strategy.

   Instances of this class should be used as strategy plugins.

   This plugin obtains relevant data from the training and testing loops of the
   main strategy by using the integrated callbacks systems.

   Internally, the evaluation plugin tries to use the "evaluation_protocol"
   namespace value. If found and not None, the evaluation protocol
   (usually an instance of :class:`EvalProtocol`), is used to compute the
   required metrics. The "evaluation_protocol" is usually a field of the main
   strategy.

   For an example on how to use it, see :class:`DeepLearningStrategy` and
   :class:`Naive`.

   Beware that, while most of the required callbacks are automatically managed
   by the :class:`DeepLearningStrategy` class, some callbacks such as
   "after_training_iteration" and "after_test_iteration" must be called
   by the implementing strategy subclasses. For an example of a vanilla
   training/testing epoch, see :class:`Naive`.

   Creates a strategy skeleton instance.

   .. method:: get_train_result(self)


   .. method:: get_test_result(self)


   .. method:: before_training(self, step_info: IStepInfo = None)


   .. method:: make_train_dataloader(self, train_dataset=None)


   .. method:: after_training_iteration(self, evaluation_protocol: Optional[EvalProtocol] = None, epoch: int = None, iteration: int = None, train_mb_y: Tensor = None, logits: Tensor = None, loss: Tensor = None, **kwargs)


   .. method:: before_testing(self)


   .. method:: before_step_testing(self, step_info: IStepInfo = None, step_id: int = None)


   .. method:: make_test_dataloader(self, test_dataset=None)


   .. method:: after_test_iteration(self, evaluation_protocol: Optional[EvalProtocol] = None, iteration: int = None, test_mb_y: Tensor = None, test_logits: Tensor = None, test_loss: Tensor = None)


   .. method:: after_step_testing(self, evaluation_protocol: Optional[EvalProtocol] = None)


   .. method:: after_testing(self, evaluation_protocol: Optional[EvalProtocol] = None, step_info: IStepInfo = None)


   .. method:: __missing(*elements)
      :staticmethod:


   .. method:: __no_evaluation_protocol()
      :staticmethod:



.. py:class:: ReplayPlugin(mem_size=200)

   Bases: :class:`avalanche.training.skeletons.cl_strategy.StrategySkeleton`

   An experience replay plugin that can be plugged in a strategy.

   Instances of this class should be used as strategy plugins.

   This simply handles an external memory filled with randomly selected
   patterns and implements the "adapt_train_dataset" callback to add them to
   the training set.

   The :mem_size: params controls the number of patterns to be stored in the
   external memory. We assume the training set to contain at least this
   number of training data points.

   Creates a strategy skeleton instance.

   .. method:: adapt_train_dataset(self, training_step_id, train_dataset, ext_mem)

      Before training we make sure to publish in the namespace a copy
      of :mem_size: randomly selected patterns to be used for replay
      in the next batch and we expand the current training set to
      contain also the data from the external memory. 


   .. method:: after_training(self, training_step_id, rm_add)

      After training we update the external memory with the patterns of
      the current training batch/task. 



.. py:class:: GDumbPlugin(mem_size=200)

   Bases: :class:`avalanche.training.skeletons.StrategySkeleton`

   A GDumb plugin. At each step the model
   is trained with all and only the data of the external memory.
   The memory is updated at the end of each step to add new classes or
   new examples of already encountered classes.


   This plugin can be combined with a Naive strategy to obtain the 
   standard GDumb strategy.

   https://www.robots.ox.ac.uk/~tvg/publications/2020/gdumb.pdf

   Creates a strategy skeleton instance.

   .. method:: adapt_train_dataset(self, training_step_id, train_dataset)

      Before training we make sure to organize the memory following
      GDumb approach and updating the dataset accordingly.



