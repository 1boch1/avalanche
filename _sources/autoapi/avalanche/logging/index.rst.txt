:mod:`avalanche.logging`
========================

.. py:module:: avalanche.logging

.. autoapi-nested-parse::

   The :py:mod:`logging` module provides a set of utilities that can be used for
   logging your experiment metrics results  on stdout, logfile and browser-based
   dashboard such as "Tensorboard" and "Weights & Biases". These resources are
   provided in :py:mod:`interactive_logging`, :py:mod:`text_logging` and
   :py:mod:`tensorboard_logger` respectively. Loggers do not specify
   which metrics to monitor, but only the way metrics will be reported
   to the user. Please, see :py:mod:`evaluation` module for a list of
   metrics and how to use them.
   Loggers should be passed as parameters to the `EvaluationPlugin`
   in order to properly monitor the training and evaluation flows.



Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   interactive_logging/index.rst
   strategy_logger/index.rst
   tensorboard_logger/index.rst
   text_logging/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.logging.StrategyLogger
   avalanche.logging.TensorboardLogger
   avalanche.logging.TextLogger
   avalanche.logging.EvaluationPlugin



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.logging.accuracy_metrics
   avalanche.logging.loss_metrics


.. py:class:: StrategyLogger

   Bases: :class:`StrategyCallbacks[None]`, :class:`abc.ABC`

   The base class for the strategy loggers.

   Strategy loggers will receive events, under the form of callback calls,
   from the :class:`EvaluationPlugin` carrying a reference to the strategy
   as well as the values emitted by the metrics.

   Each child class should implement the `log_metric` method, which
   specifies how to report to the user the metrics gathered during
   training and evaluation flows. The `log_metric` method is invoked
   by default on each callback.
   In addition, child classes may override the desired callbacks
   to customize the logger behavior.

   Make sure, when overriding callbacks, to call
   the proper `super` method.

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: log_metric(self, metric_value: MetricValue, callback: str) -> None

      This abstract method will has to be implemented by child classes.
      This method will be invoked on each callback.
      The `callback` parameter describes the callback from which the metric
      value is coming from.

      :param metric_value: The value to be logged.
      :param callback: The name of the callback (event) from which the
          metric value was obtained.
      :return: None


   .. method:: before_training(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: before_training_exp(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: adapt_train_dataset(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: before_training_epoch(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: before_training_iteration(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: before_forward(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: after_forward(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: before_backward(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: after_backward(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: after_training_iteration(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: before_update(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: after_update(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: after_training_epoch(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: after_training_exp(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: after_training(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: before_eval(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: adapt_eval_dataset(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: before_eval_exp(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: after_eval_exp(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: after_eval(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: before_eval_iteration(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: before_eval_forward(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: after_eval_forward(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: after_eval_iteration(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)



.. py:class:: TensorboardLogger(tb_log_dir='./tb_data', filename_suffix='')

   Bases: :class:`avalanche.logging.StrategyLogger`

   The `TensorboardLogger` provides an easy integration with
   Tensorboard logging. Each monitored metric is automatically
   logged to Tensorboard.
   The user can inspect results in real time by appropriately launching
   tensorboard with `tensorboard --logdir=/path/to/tb_log_exp_name`.

   If no parameters are provided, the default folder in which tensorboard
   log files are placed is "./runs/".
   .. note::
       We rely on PyTorch implementation of Tensorboard. If you
       don't have Tensorflow installed in your environment,
       tensorboard will tell you that it is running with reduced
       feature set. This should not impact on the logger performance.

   Creates an instance of the `TensorboardLogger`.

   :param tb_log_dir: path to the directory where tensorboard log file
       will be stored. Default to "./tb_data".
   :param filename_suffix: string suffix to append at the end of
       tensorboard log file. Default ''.

   .. method:: log_metric(self, metric_value: MetricValue, callback: str)

      This abstract method will has to be implemented by child classes.
      This method will be invoked on each callback.
      The `callback` parameter describes the callback from which the metric
      value is coming from.

      :param metric_value: The value to be logged.
      :param callback: The name of the callback (event) from which the
          metric value was obtained.
      :return: None



.. py:class:: TextLogger(file=sys.stdout)

   Bases: :class:`avalanche.logging.StrategyLogger`

   The `TextLogger` class provides logging facilities
   printed to a user specified file. The logger writes
   metric results after each training epoch, evaluation
   experience and at the end of the entire evaluation stream.

   .. note::
       To avoid an excessive amount of printed lines,
       this logger will **not** print results after
       each iteration. If the user is monitoring
       metrics which emit results after each minibatch
       (e.g., `MinibatchAccuracy`), only the last recorded
       value of such metrics will be reported at the end
       of the epoch.

   .. note::
       Since this logger works on the standard output,
       metrics producing images or more complex visualizations
       will be converted to a textual format suitable for
       console printing. You may want to add more loggers
       to your `EvaluationPlugin` to better support
       different formats.

   Creates an instance of `TextLogger` class.

   :param file: destination file to which print metrics
       (default=sys.stdout).

   .. method:: log_metric(self, metric_value: MetricValue, callback: str) -> None

      This abstract method will has to be implemented by child classes.
      This method will be invoked on each callback.
      The `callback` parameter describes the callback from which the metric
      value is coming from.

      :param metric_value: The value to be logged.
      :param callback: The name of the callback (event) from which the
          metric value was obtained.
      :return: None


   .. method:: _val_to_str(self, m_val)


   .. method:: print_current_metrics(self)


   .. method:: before_training_exp(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: before_eval_exp(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: after_training_epoch(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: after_eval_exp(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: before_training(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: before_eval(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: after_training(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: after_eval(self, strategy: PluggableStrategy, metric_values: List['MetricValue'], **kwargs)


   .. method:: _on_exp_start(self, strategy: PluggableStrategy)



.. py:class:: EvaluationPlugin(*metrics: Union['PluginMetric', Sequence['PluginMetric']], loggers: Union['StrategyLogger', Sequence['StrategyLogger']] = None, collect_all=True)

   Bases: :class:`avalanche.training.plugins.StrategyPlugin`

   An evaluation plugin that obtains relevant data from the
   training and eval loops of the strategy through callbacks.

   This plugin updates the given metrics and logs them using the provided
   loggers.

   Creates an instance of the evaluation plugin.

   :param metrics: The metrics to compute.
   :param loggers: The loggers to be used to log the metric values.
   :param collect_curves (bool): enables the collection of the metric
       curves. If True `self.metric_curves` stores all the values of
       each curve in a dictionary. Please disable this if you log large
       values (embeddings, parameters) and you want to reduce memory usage.

   .. method:: _update_metrics(self, strategy: PluggableStrategy, callback: str)


   .. method:: before_training(self, strategy: PluggableStrategy, **kwargs)


   .. method:: before_training_exp(self, strategy: PluggableStrategy, **kwargs)


   .. method:: adapt_train_dataset(self, strategy: PluggableStrategy, **kwargs)


   .. method:: before_training_epoch(self, strategy: PluggableStrategy, **kwargs)


   .. method:: before_training_iteration(self, strategy: PluggableStrategy, **kwargs)


   .. method:: before_forward(self, strategy: PluggableStrategy, **kwargs)


   .. method:: after_forward(self, strategy: PluggableStrategy, **kwargs)


   .. method:: before_backward(self, strategy: PluggableStrategy, **kwargs)


   .. method:: after_backward(self, strategy: PluggableStrategy, **kwargs)


   .. method:: after_training_iteration(self, strategy: PluggableStrategy, **kwargs)


   .. method:: before_update(self, strategy: PluggableStrategy, **kwargs)


   .. method:: after_update(self, strategy: PluggableStrategy, **kwargs)


   .. method:: after_training_epoch(self, strategy: PluggableStrategy, **kwargs)


   .. method:: after_training_exp(self, strategy: PluggableStrategy, **kwargs)


   .. method:: after_training(self, strategy: PluggableStrategy, **kwargs)


   .. method:: before_eval(self, strategy: PluggableStrategy, **kwargs)


   .. method:: adapt_eval_dataset(self, strategy: PluggableStrategy, **kwargs)


   .. method:: before_eval_exp(self, strategy: PluggableStrategy, **kwargs)


   .. method:: after_eval_exp(self, strategy: PluggableStrategy, **kwargs)


   .. method:: after_eval(self, strategy: PluggableStrategy, **kwargs)


   .. method:: before_eval_iteration(self, strategy: PluggableStrategy, **kwargs)


   .. method:: before_eval_forward(self, strategy: PluggableStrategy, **kwargs)


   .. method:: after_eval_forward(self, strategy: PluggableStrategy, **kwargs)


   .. method:: after_eval_iteration(self, strategy: PluggableStrategy, **kwargs)



.. function:: accuracy_metrics(*, minibatch=False, epoch=False, epoch_running=False, experience=False, stream=False) -> List[PluginMetric]

   Helper method that can be used to obtain the desired set of
   plugin metrics.

   :param minibatch: If True, will return a metric able to log
       the minibatch accuracy at training time.
   :param epoch: If True, will return a metric able to log
       the epoch accuracy at training time.
   :param epoch_running: If True, will return a metric able to log
       the running epoch accuracy at training time.
   :param experience: If True, will return a metric able to log
       the accuracy on each evaluation experience.
   :param stream: If True, will return a metric able to log
       the accuracy averaged over the entire evaluation stream of experiences.

   :return: A list of plugin metrics.


.. function:: loss_metrics(*, minibatch=False, epoch=False, epoch_running=False, experience=False, stream=False) -> List[PluginMetric]

   Helper method that can be used to obtain the desired set of
   plugin metrics.

   :param minibatch: If True, will return a metric able to log
       the minibatch loss at training time.
   :param epoch: If True, will return a metric able to log
       the epoch loss at training time.
   :param epoch_running: If True, will return a metric able to log
       the running epoch loss at training time.
   :param experience: If True, will return a metric able to log
       the loss on each evaluation experience.
   :param stream: If True, will return a metric able to log
       the loss averaged over the entire evaluation stream of experiences.

   :return: A list of plugin metrics.


.. data:: default_logger
   

   

