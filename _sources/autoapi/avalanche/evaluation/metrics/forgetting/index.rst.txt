:mod:`avalanche.evaluation.metrics.forgetting`
==============================================

.. py:module:: avalanche.evaluation.metrics.forgetting


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.evaluation.metrics.forgetting.TaskForgetting



.. py:class:: TaskForgetting

   Bases: :class:`avalanche.evaluation.abstract_metric.AbstractMetric`

   The TaskForgetting metric, describing the accuracy loss detected for a
   certain task.

   This metric is computed separately for each task as the difference between
   the accuracy result obtained after training on a task and the accuracy
   result obtained on the same task at the end of successive steps.

   This metric is computed during the test phase only.

   Creates an instance of the Catastrophic TaskForgetting metric.

   .. attribute:: best_accuracy
      :annotation: :Dict[int, float]

      The best accuracy of each task.


   .. method:: result_emitter(self, eval_data)



