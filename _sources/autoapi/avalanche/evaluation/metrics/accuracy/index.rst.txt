:mod:`avalanche.evaluation.metrics.accuracy`
============================================

.. py:module:: avalanche.evaluation.metrics.accuracy


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.evaluation.metrics.accuracy.Accuracy
   avalanche.evaluation.metrics.accuracy.MinibatchAccuracy
   avalanche.evaluation.metrics.accuracy.EpochAccuracy
   avalanche.evaluation.metrics.accuracy.RunningEpochAccuracy
   avalanche.evaluation.metrics.accuracy.StepAccuracy
   avalanche.evaluation.metrics.accuracy.StreamAccuracy



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.evaluation.metrics.accuracy.accuracy_metrics


.. py:class:: Accuracy

   Bases: :class:`Metric[float]`

   The Accuracy metric. This is a general metric
   used to compute more specific ones.

   Instances of this metric keeps the running average accuracy
   over multiple <prediction, target> pairs of Tensors,
   provided incrementally.
   The "prediction" and "target" tensors may contain plain labels or
   one-hot/logit vectors.

   Each time `result` is called, this metric emits the average accuracy
   across all predictions made since the last `reset`.

   The reset method will bring the metric to its initial state. By default
   this metric in its initial state will return an accuracy value of 0.

   Creates an instance of the Accuracy metric.

   By default this metric in its initial state will return an accuracy
   value of 0. The metric can be updated by using the `update` method
   while the running accuracy can be retrieved using the `result` method.

   .. attribute:: _mean_accuracy
      

      The mean utility that will be used to store the running accuracy.


   .. method:: update(self, predicted_y: Tensor, true_y: Tensor) -> None

      Update the running accuracy given the true and predicted labels.

      :param predicted_y: The model prediction. Both labels and logit vectors
          are supported.
      :param true_y: The ground truth. Both labels and one-hot vectors
          are supported.
      :return: None.


   .. method:: result(self) -> float

      Retrieves the running accuracy.

      Calling this method will not change the internal state of the metric.

      :return: The running accuracy, as a float value between 0 and 1.


   .. method:: reset(self) -> None

      Resets the metric.

      :return: None.



.. py:class:: MinibatchAccuracy

   Bases: :class:`PluginMetric[float]`

   The minibatch accuracy metric.
   This metric only works at training time.

   This metric computes the average accuracy over patterns
   from a single minibatch.
   It reports the result after each iteration.

   If a more coarse-grained logging is needed, consider using
   :class:`EpochAccuracy` instead.

   Creates an instance of the MinibatchAccuracy metric.

   .. method:: result(self) -> float


   .. method:: reset(self) -> None


   .. method:: after_training_iteration(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: _package_result(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: __str__(self)

      Return str(self).



.. py:class:: EpochAccuracy

   Bases: :class:`PluginMetric[float]`

   The average accuracy over a single training epoch.
   This metric only works at training time.

   The accuracy will be logged after each training epoch by computing
   the number of correctly predicted patterns during the epoch divided by
   the overall number of patterns encountered in that epoch.

   Creates an instance of the EpochAccuracy metric.

   .. method:: reset(self) -> None


   .. method:: result(self) -> float


   .. method:: after_training_iteration(self, strategy: PluggableStrategy) -> None


   .. method:: before_training_epoch(self, strategy: PluggableStrategy) -> None


   .. method:: after_training_epoch(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: _package_result(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: __str__(self)

      Return str(self).



.. py:class:: RunningEpochAccuracy

   Bases: :class:`avalanche.evaluation.metrics.accuracy.EpochAccuracy`

   The average accuracy across all minibatches up to the current
   epoch iteration.
   This metric only works at training time.

   At each iteration, this metric logs the accuracy averaged over all patterns
   seen so far in the current epoch.
   The metric resets its state after each training epoch.

   Creates an instance of the RunningEpochAccuracy metric.

   .. method:: after_training_iteration(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: after_training_epoch(self, strategy: PluggableStrategy) -> None


   .. method:: _package_result(self, strategy: PluggableStrategy)


   .. method:: __str__(self)

      Return str(self).



.. py:class:: StepAccuracy

   Bases: :class:`PluginMetric[float]`

   At the end of each step, this metric reports
   the average accuracy over all patterns seen in that step.
   This metric only works at eval time.

   Creates an instance of StepAccuracy metric

   .. method:: reset(self) -> None


   .. method:: result(self) -> float


   .. method:: before_eval_step(self, strategy: PluggableStrategy) -> None


   .. method:: after_eval_iteration(self, strategy: PluggableStrategy) -> None


   .. method:: after_eval_step(self, strategy: PluggableStrategy) -> 'MetricResult'


   .. method:: _package_result(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: __str__(self)

      Return str(self).



.. py:class:: StreamAccuracy

   Bases: :class:`PluginMetric[float]`

   At the end of the entire stream of steps, this metric reports the average
   accuracy over all patterns seen in all steps.
   This metric only works at eval time.

   Creates an instance of StreamAccuracy metric

   .. method:: reset(self) -> None


   .. method:: result(self) -> float


   .. method:: before_eval(self, strategy: PluggableStrategy) -> None


   .. method:: after_eval_iteration(self, strategy: PluggableStrategy) -> None


   .. method:: after_eval(self, strategy: PluggableStrategy) -> 'MetricResult'


   .. method:: _package_result(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: __str__(self)

      Return str(self).



.. function:: accuracy_metrics(*, minibatch=False, epoch=False, epoch_running=False, step=False, stream=False) -> List[PluginMetric]

   Helper method that can be used to obtain the desired set of metric.

   :param minibatch: If True, will return a metric able to log
       the minibatch accuracy at training time.
   :param epoch: If True, will return a metric able to log
       the epoch accuracy at training time.
   :param epoch_running: If True, will return a metric able to log
       the running epoch accuracy at training time.
   :param step: If True, will return a metric able to log
       the accuracy on each evaluation step.
   :param stream: If True, will return a metric able to log
       the accuracy averaged over the entire evaluation stream of steps.

   :return: A list of plugin metrics.


