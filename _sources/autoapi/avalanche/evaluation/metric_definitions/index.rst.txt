:mod:`avalanche.evaluation.metric_definitions`
==============================================

.. py:module:: avalanche.evaluation.metric_definitions


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.evaluation.metric_definitions.Metric
   avalanche.evaluation.metric_definitions.AlternativeValues
   avalanche.evaluation.metric_definitions.MetricTypes
   avalanche.evaluation.metric_definitions.MetricValue



.. data:: MetricResult
   

   

.. py:class:: Metric

   Bases: :class:`typing_extensions.Protocol`

   Protocol definition of a metric.

   A metric simply accepts an evaluation data object containing relevant
   information retrieved from the strategy and optionally outputs values
   to be logged.

   Create and return a new object.  See help(type) for accurate signature.

   .. method:: __call__(self, eval_data: EvalData) -> MetricResult



.. py:class:: AlternativeValues(*alternatives: MetricType)

   A container for alternative representations of the same metric value.

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: best_supported_value(self, *supported_types: type) -> Optional[MetricType]

      Retrieves a supported representation for this metric value.

      :param supported_types: A list of supported value types.
      :return: The best supported representation. Returns None if no supported
          representation is found.



.. py:class:: MetricTypes

   Bases: :class:`enum.Enum`

   Generic enumeration.

   Derive from this class to define new enumerations.


   Create and return a new object.  See help(type) for accurate signature.

   .. attribute:: OTHER
      

      Value used to flag a metric type that doesn't fit in any of the other
      standard types.


   .. attribute:: ACCURACY
      

      Used to flag accuracy values.


   .. attribute:: LOSS
      

      Used to flag loss values.


   .. attribute:: FORGETTING
      

      Used to flag values representing accuracy losses.


   .. attribute:: CONFUSION_MATRIX
      

      Used to flag confusion matrices.


   .. attribute:: ELAPSED_TIME
      

      Used to flag values describing an elapsed time (usually in seconds).


   .. attribute:: CPU_USAGE
      

      Used to flag values describing the CPU usage.


   .. attribute:: GPU_USAGE
      

      Used to flag values describing the GPU usage.


   .. attribute:: RAM_USAGE
      

      Used to flag values describing the RAM usage (usually in MiB).


   .. attribute:: STORAGE_USAGE
      

      Used to flag values describing the storage occupation (usually in MiB).



.. py:class:: MetricValue(origin: Metric, name: str, metric_type: MetricTypes, value: Union[MetricType, AlternativeValues], x_plot: int)

   Bases: :class:`object`

   The result of a Metric.

   A result has a name, a value and a "x" position in which the metric value
   should be plotted.

   The "value" field can also be an instance of "AlternativeValues", in which
   case it means that alternative representations exist for this value. For
   instance, the Confusion Matrix can be represented both as a Tensor and as
   an Image. It's up to the Logger, according to its capabilities, decide which
   representation to use.

   Creates an instance of MetricValue.

   :param origin: The originating Metric instance.
   :param name: The display name of this value.
   :param metric_type: The type of this metric value, as a element
       from the  MetricTypes enumeration.

   :param value:
   :param x_plot:


