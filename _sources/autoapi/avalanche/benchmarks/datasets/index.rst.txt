:mod:`avalanche.benchmarks.datasets`
====================================

.. py:module:: avalanche.benchmarks.datasets


Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   core50/index.rst
   cub200/index.rst
   mini_imagenet/index.rst
   openloris/index.rst
   tiny_imagenet/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   imagenet_data/index.rst
   omniglot/index.rst
   torchvision_wrapper/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.datasets.CORe50
   avalanche.benchmarks.datasets.CUB200
   avalanche.benchmarks.datasets.MiniImageNetDataset
   avalanche.benchmarks.datasets.OpenLORIS
   avalanche.benchmarks.datasets.TinyImagenet
   avalanche.benchmarks.datasets.Omniglot



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.datasets.MNIST
   avalanche.benchmarks.datasets.FashionMNIST
   avalanche.benchmarks.datasets.KMNIST
   avalanche.benchmarks.datasets.EMNIST
   avalanche.benchmarks.datasets.QMNIST
   avalanche.benchmarks.datasets.FakeData
   avalanche.benchmarks.datasets.CocoCaptions
   avalanche.benchmarks.datasets.CocoDetection
   avalanche.benchmarks.datasets.LSUN
   avalanche.benchmarks.datasets.LSUN
   avalanche.benchmarks.datasets.ImageFolder
   avalanche.benchmarks.datasets.DatasetFolder
   avalanche.benchmarks.datasets.ImageNet
   avalanche.benchmarks.datasets.CIFAR10
   avalanche.benchmarks.datasets.CIFAR100
   avalanche.benchmarks.datasets.STL10
   avalanche.benchmarks.datasets.SVHN
   avalanche.benchmarks.datasets.PhotoTour
   avalanche.benchmarks.datasets.SBU
   avalanche.benchmarks.datasets.Flickr8k
   avalanche.benchmarks.datasets.Flickr30k
   avalanche.benchmarks.datasets.VOCDetection
   avalanche.benchmarks.datasets.VOCSegmentation
   avalanche.benchmarks.datasets.Cityscapes
   avalanche.benchmarks.datasets.SBDataset
   avalanche.benchmarks.datasets.USPS
   avalanche.benchmarks.datasets.Kinetics400
   avalanche.benchmarks.datasets.HMDB51
   avalanche.benchmarks.datasets.UCF101
   avalanche.benchmarks.datasets.CelebA


.. py:class:: CORe50(root=expanduser('~') + '/.avalanche/data/core50/', train=True, transform=ToTensor(), target_transform=None, loader=pil_loader, download=True)

   Bases: :class:`torch.utils.data.dataset.Dataset`

   CORe50 Pytorch Dataset 

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: __getitem__(self, index)

      Args:
          index (int): Index

      Returns:
          tuple: (sample, target) where target is class_index of the target
              class.


   .. method:: __len__(self)



.. py:class:: CUB200(root, train=True, transform=None, loader=default_loader, download=False)

   Bases: :class:`torch.utils.data.dataset.Dataset`

   An abstract class representing a :class:`Dataset`.

   All datasets that represent a map from keys to data samples should subclass
   it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a
   data sample for a given key. Subclasses could also optionally overwrite
   :meth:`__len__`, which is expected to return the size of the dataset by many
   :class:`~torch.utils.data.Sampler` implementations and the default options
   of :class:`~torch.utils.data.DataLoader`.

   .. note::
     :class:`~torch.utils.data.DataLoader` by default constructs a index
     sampler that yields integral indices.  To make it work with a map-style
     dataset with non-integral indices/keys, a custom sampler must be provided.

   Initialize self.  See help(type(self)) for accurate signature.

   .. attribute:: filename
      :annotation: = images.tgz

      

   .. attribute:: metadata
      :annotation: = lists.tgz

      

   .. attribute:: basefolder
      :annotation: = images

      

   .. attribute:: tgz_md5
      :annotation: = 2bbe304ef1aa3ddb6094aa8f53487cf2

      

   .. method:: _load_metadata(self)


   .. method:: _check_integrity(self)


   .. method:: __len__(self)


   .. method:: __getitem__(self, idx)



.. py:class:: MiniImageNetDataset(imagenet_path: Union[str, Path], split: Literal['all', 'train', 'val', 'test'] = 'all', resize_to: Union[int, Tuple[int, int]] = 84)

   Bases: :class:`torch.utils.data.dataset.Dataset`

   The MiniImageNet dataset.

   This implementation is based on the one from
   https://github.com/yaoyao-liu/mini-imagenet-tools. Differently from that,
   this class doesn't rely on a pre-generated mini imagenet folder. Instead,
   this will use the original ImageNet folder by resizing images on-the-fly.

   The list of included files are the ones defined in the CSVs taken from the
   aforementioned repository. Those CSVs are generated by Ravi and Larochelle.
   See the linked repository for more details.

   Exactly as happens with the torchvision :class:`ImageNet` class, textual
   class labels (wnids) such as "n02119789", "n02102040", etc. are mapped to
   numerical labels based on their ascending order.

   All the fields found in the torchvision implementation of the ImageNet
   dataset (`wnids`, `wnid_to_idx`, `classes`, `class_to_idx`) are available.

   Creates an instance of the Mini ImageNet dataset.

   This dataset allows to obtain the whole dataset or even only specific
   splits. Beware that, when using a split different that "all", the
   returned dataset will contain patterns of a subset of the 100 classes.
   This happens because MiniImagenet was created with the idea of training,
   validating and testing on a disjoint set of classes.

   This implementation uses the filelists provided by
   https://github.com/yaoyao-liu/mini-imagenet-tools, which are the ones
   generated by Ravi and Larochelle (see the linked repo for more details).

   :param imagenet_path: The path to the imagenet folder. This has to be
       the path to the full imagenet 2012 folder (plain, not resized).
       Only the "train" folder will be used. Because of this, passing the
       path to the imagenet 2012 "train" folder is also allowed.
   :param split: The split to obtain. Defaults to "all". Valid values are
       "all", "train", "val" and "test".
   :param resize_to: The size of the output images. Can be an `int` value
       or a tuple of two ints. When passing a single `int` value, images
       will be resized by forcing as 1:1 aspect ratio. Defaults to 84,
       which means that images will have size 84x84.

   .. attribute:: imagenet_path
      

      The path to the "train" folder of full imagenet 2012 directory.


   .. attribute:: split
      :annotation: :Literal['all', 'train', 'val', 'test']

      The required split.


   .. attribute:: resize_to
      :annotation: :Tuple[int, int]

      The size of the output images, as a two ints tuple.


   .. attribute:: image_paths
      :annotation: :List[str] = []

      The paths to images.


   .. attribute:: targets
      :annotation: :List[int] = []

      The class labels for the patterns. Aligned with the image_paths field.


   .. attribute:: wnids
      :annotation: :List[str] = []

      The list of wnids (the textual class labels, such as "n02119789").


   .. attribute:: wnid_to_idx
      :annotation: :Dict[str, int]

      A dictionary mapping wnids to numerical labels in range [0, 100).


   .. attribute:: classes
      :annotation: :List[Tuple[str, ...]] = []

      A list mapping numerical labels (the element index) to a tuple of human
      readable categories. For instance:
      ('great grey owl', 'great gray owl', 'Strix nebulosa').


   .. attribute:: class_to_idx
      :annotation: :Dict[str, int]

      A dictionary mapping each string of the tuples found in the classes 
      field to their numerical label. That is, this dictionary contains the 
      inverse mapping of classes field.


   .. method:: get_train_path(root_path: Union[str, Path])
      :staticmethod:


   .. method:: prepare_dataset(self)


   .. method:: __len__(self)


   .. method:: __getitem__(self, item)



.. py:class:: OpenLORIS(root=expanduser('~') + '/.avalanche/data/openloris/', train=True, transform=ToTensor(), target_transform=None, loader=pil_loader, download=False)

   Bases: :class:`torch.utils.data.Dataset`

   OpenLORIS Pytorch Dataset 

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: __getitem__(self, index)

      Args:
          index (int): Index

      Returns:
          tuple: (sample, target) where target is class_index of the target
              class.


   .. method:: __len__(self)



.. py:class:: TinyImagenet(data_folder=expanduser('~') + '/.avalanche/data/tinyimagenet/', train=True, transform=ToTensor(), target_transform=None, download=True)

   Bases: :class:`torch.utils.data.dataset.Dataset`

   Tiny Imagenet Pytorch Dataset

   Args:
       :param string data_folder: folder in which to download dataset
       :param boolean train: True for train set, False for test set
       :param fun transform: Pytorch transformation founction for x
       :param fun target_transform: Pytorch transformation founction for y
       :param bool download: True for downloading the dataset

   .. method:: download_tinyImageNet(self)

      Downloads the TintImagenet Dataset 


   .. method:: labels2dict(self)

      Returns dictionaries to convert class names into progressive ids
      and viceversa.
      :returns: label2id, id2label: two Python dictionaries.


   .. method:: load_data(self, train=True)

      Load all images paths and targets.

      :param bool train: True for loading the training set, False for the
          test set.
      :return: train_set, test_set: (train_X_paths, train_y).


   .. method:: get_train_images_paths(self, class_name)

      Gets the training set image paths

      :param class_name: names of the classes of the images to be
          collected.
      :returns img_paths: list of strings (paths)


   .. method:: get_test_images_paths(self, class_name)

      Gets the test set image paths

      :param class_name: names of the classes of the images to be
          collected.
      :returns img_paths: list of strings (paths)


   .. method:: __len__(self)

      Returns the lenght of the set 


   .. method:: __getitem__(self, index)

      Returns the index-th x, y pattern of the set 



.. py:class:: Omniglot(root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)

   Bases: :class:`torchvision.datasets.Omniglot`

   Custom class used to interface Omniglot from
   Torchvision with the method used in Avalanche

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: data(self)
      :property:



.. function:: MNIST(*args, **kwargs)


.. function:: FashionMNIST(*args, **kwargs)


.. function:: KMNIST(*args, **kwargs)


.. function:: EMNIST(*args, **kwargs)


.. function:: QMNIST(*args, **kwargs)


.. function:: FakeData(*args, **kwargs)


.. function:: CocoCaptions(*args, **kwargs)


.. function:: CocoDetection(*args, **kwargs)


.. function:: LSUN(*args, **kwargs)


.. function:: LSUN(*args, **kwargs)


.. function:: ImageFolder(*args, **kwargs)


.. function:: DatasetFolder(*args, **kwargs)


.. function:: ImageNet(*args, **kwargs)


.. function:: CIFAR10(*args, **kwargs)


.. function:: CIFAR100(*args, **kwargs)


.. function:: STL10(*args, **kwargs)


.. function:: SVHN(*args, **kwargs)


.. function:: PhotoTour(*args, **kwargs)


.. function:: SBU(*args, **kwargs)


.. function:: Flickr8k(*args, **kwargs)


.. function:: Flickr30k(*args, **kwargs)


.. function:: VOCDetection(*args, **kwargs)


.. function:: VOCSegmentation(*args, **kwargs)


.. function:: Cityscapes(*args, **kwargs)


.. function:: SBDataset(*args, **kwargs)


.. function:: USPS(*args, **kwargs)


.. function:: Kinetics400(*args, **kwargs)


.. function:: HMDB51(*args, **kwargs)


.. function:: UCF101(*args, **kwargs)


.. function:: CelebA(*args, **kwargs)


