:mod:`avalanche.benchmarks.datasets`
====================================

.. py:module:: avalanche.benchmarks.datasets


Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   core50/index.rst
   tiny_imagenet/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   cub200/index.rst
   datasets_from_filelists/index.rst
   torchvision_wrapper/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.datasets.TinyImagenet
   avalanche.benchmarks.datasets.CORE50_DATA
   avalanche.benchmarks.datasets.CORe50
   avalanche.benchmarks.datasets.TransformationDataset
   avalanche.benchmarks.datasets.FilelistDataset
   avalanche.benchmarks.datasets.CUB200



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.datasets.MNIST
   avalanche.benchmarks.datasets.FashionMNIST
   avalanche.benchmarks.datasets.KMNIST
   avalanche.benchmarks.datasets.EMNIST
   avalanche.benchmarks.datasets.QMNIST
   avalanche.benchmarks.datasets.FakeData
   avalanche.benchmarks.datasets.CocoCaptions
   avalanche.benchmarks.datasets.CocoDetection
   avalanche.benchmarks.datasets.LSUN
   avalanche.benchmarks.datasets.ImageFolder
   avalanche.benchmarks.datasets.DatasetFolder
   avalanche.benchmarks.datasets.ImageNet
   avalanche.benchmarks.datasets.CIFAR10
   avalanche.benchmarks.datasets.CIFAR100
   avalanche.benchmarks.datasets.STL10
   avalanche.benchmarks.datasets.SVHN
   avalanche.benchmarks.datasets.PhotoTour
   avalanche.benchmarks.datasets.SBU
   avalanche.benchmarks.datasets.Flickr8k
   avalanche.benchmarks.datasets.Flickr30k
   avalanche.benchmarks.datasets.VOCDetection
   avalanche.benchmarks.datasets.VOCSegmentation
   avalanche.benchmarks.datasets.Cityscapes
   avalanche.benchmarks.datasets.SBDataset
   avalanche.benchmarks.datasets.USPS
   avalanche.benchmarks.datasets.Kinetics400
   avalanche.benchmarks.datasets.HMDB51
   avalanche.benchmarks.datasets.UCF101
   avalanche.benchmarks.datasets.CelebA
   avalanche.benchmarks.datasets.default_loader
   avalanche.benchmarks.datasets.default_flist_reader
   avalanche.benchmarks.datasets.datasets_from_filelists


.. py:class:: TinyImagenet(data_folder=expanduser('~') + '/.avalanche/data/tinyimagenet/', train=True, transform=ToTensor(), target_transform=None, download=True)

   Bases: :class:`torch.utils.data.Dataset`

   Tiny Imagenet Pytorch Dataset

   Args:
       :param string data_folder: folder in which to download dataset
       :param boolean train: True for train set, False for test set
       :param fun transform: Pytorch transformation founction for x
       :param fun target_transform: Pytorch transformation founction for y
       :param bool download: True for downloading the dataset

   .. method:: download_tinyImageNet(self)

      Downloads the TintImagenet Dataset 


   .. method:: labels2dict(self)

      Returns dictionaries to convert class names into progressive ids
      and viceversa.
      :returns: label2id, id2label: two Python dictionaries.


   .. method:: load_data(self, train=True)

      Load all images paths and targets.

      :param bool train: True for loading the training set, False for the
          test set.
      :return: train_set, test_set: (train_X_paths, train_y).


   .. method:: get_train_images_paths(self, class_name)

      Gets the training set image paths

      :param class_name: names of the classes of the images to be
          collected.
      :returns img_paths: list of strings (paths)


   .. method:: get_test_images_paths(self, class_name)

      Gets the test set image paths

      :param class_name: names of the classes of the images to be
          collected.
      :returns img_paths: list of strings (paths)


   .. method:: __len__(self)

      Returns the lenght of the set 


   .. method:: __getitem__(self, index)

      Returns the index-th x, y pattern of the set 



.. py:class:: CORE50_DATA(data_folder='data/')

   Bases: :class:`object`

   CORE50 downloader.

   Args:
       data_folder (string): folder in which to download core50 dataset. 

   .. method:: download_core50(self)



.. py:class:: CORe50(root=expanduser('~') + '/.avalanche/data/core50/', train=True, transform=ToTensor(), target_transform=None, loader=pil_loader, download=True)

   Bases: :class:`torch.utils.data.Dataset`

   CORe50 Pytorch Dataset 

   .. method:: __getitem__(self, index)

      Args:
          index (int): Index

      Returns:
          tuple: (sample, target) where target is class_index of the target
              class.


   .. method:: __len__(self)



.. function:: MNIST(*args, **kwargs)


.. function:: FashionMNIST(*args, **kwargs)


.. function:: KMNIST(*args, **kwargs)


.. function:: EMNIST(*args, **kwargs)


.. function:: QMNIST(*args, **kwargs)


.. function:: FakeData(*args, **kwargs)


.. function:: CocoCaptions(*args, **kwargs)


.. function:: CocoDetection(*args, **kwargs)


.. function:: LSUN(*args, **kwargs)


.. function:: ImageFolder(*args, **kwargs)


.. function:: DatasetFolder(*args, **kwargs)


.. function:: ImageNet(*args, **kwargs)


.. function:: CIFAR10(*args, **kwargs)


.. function:: CIFAR100(*args, **kwargs)


.. function:: STL10(*args, **kwargs)


.. function:: SVHN(*args, **kwargs)


.. function:: PhotoTour(*args, **kwargs)


.. function:: SBU(*args, **kwargs)


.. function:: Flickr8k(*args, **kwargs)


.. function:: Flickr30k(*args, **kwargs)


.. function:: VOCDetection(*args, **kwargs)


.. function:: VOCSegmentation(*args, **kwargs)


.. function:: Cityscapes(*args, **kwargs)


.. function:: SBDataset(*args, **kwargs)


.. function:: USPS(*args, **kwargs)


.. function:: Kinetics400(*args, **kwargs)


.. function:: HMDB51(*args, **kwargs)


.. function:: UCF101(*args, **kwargs)


.. function:: CelebA(*args, **kwargs)


.. data:: mnist
   

   

.. py:class:: TransformationDataset(dataset: IDatasetWithTargets[T_co], *, transform: XTransform = None, target_transform: YTransform = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group='train')

   Bases: :class:`DatasetWithTargets[T_co]`, :class:`Generic[T_co]`

   A Dataset that applies transformations before returning patterns/targets.
   Also, this Dataset supports slicing and advanced indexing.

   This dataset can also be used to apply several operations involving
   transformations. For instance, it allows the user to add and replace
   transformations, freeze them so that they can't be changed, etc.

   This dataset also allows the user to keep distinct transformations groups.
   Simply put, a transformation group is a pair of transform+target_transform
   (exactly as in torchvision datasets). This dataset natively supports keeping
   two transformation groups: the first, 'train', contains transformations
   applied to training patterns. Those transformations usually involve some
   kind of data augmentation. The second one is 'test', that will contain
   transformations applied to test patterns. Having both groups can be
   useful when, for instance, in need to test on the training data (as this
   process usually involves removing data augmentation operations). Switching
   between transformations can be easily achieved by using the
   :func:`train` and :func:`eval` method.

   However, consider that arbitrary groups can be used. For more info see
   the constructor and the :func:`with_transforms` method.

   Creates a ``TransformationDataset`` instance.

   :param dataset: The dataset to decorate. Beware that
       TransformationDataset will not overwrite transformations already
       applied by this dataset.
   :param transform: A function/transform that takes the X value of a
       pattern from the original dataset and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       test transformations. This becomes useful when in need to test on
       the training dataset as test transformations usually don't contain
       random augmentations. ``TransformDataset`` natively supports the
       'train' and 'test' groups by calling the ``train()`` and ``eval()``
       methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'test' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the transform group
       to be used. Defaults to 'train'.

   .. attribute:: _dataset
      :annotation: :IDatasetWithTargets[T_co]

      The original dataset.


   .. attribute:: targets
      :annotation: :Sequence[int]

      A sequence of ints describing the label of each pattern contained in the
      dataset.


   .. attribute:: current_transform_group
      

      The name of the transform group currently in use.


   .. attribute:: transform_groups
      :annotation: :Dict[str, Tuple[XTransform, YTransform]]

      A dictionary containing the transform groups. Transform groups are
      used to quickly switch between training and test transformations.
      This becomes useful when in need to test on the training dataset as test
      transformations usually don't contain random augmentations.

      TransformDataset natively supports switching between the 'train' and
      'test' groups by calling the ``train()`` and ``eval()`` methods. When
      using custom groups one can use the ``with_transforms(group_name)``
      method instead.

      May be null, which means that the current transforms will be used to
      handle both 'train' and 'test' groups.


   .. attribute:: transform
      :annotation: :XTransform

      A function/transform that takes in an PIL image and returns a 
      transformed version.


   .. attribute:: target_transform
      :annotation: :YTransform

      A function/transform that takes in the target and transforms it.


   .. attribute:: _frozen_transforms
      :annotation: :Dict[str, Tuple[XTransform, YTransform]]

      A dictionary containing frozen transformations.


   .. method:: __getitem__(self, idx)


   .. method:: __len__(self)


   .. method:: train(self)

      Returns a new dataset with the transformations of a the 'train' group
      loaded.

      The current dataset will not be affected.

      :return: A new dataset with the training transformations loaded.


   .. method:: eval(self)

      Returns a new dataset with the transformations of a the 'test' group
      loaded.

      Test transformations usually don't contain augmentation procedures.
      This function may be useful when in need to test on training data
      (for instance, in order to run a validation pass).

      The current dataset will not be affected.

      :return: A new dataset with the test transformations loaded.


   .. method:: freeze_transforms(self: TTransformationDataset) -> TTransformationDataset

      Returns a new dataset where the current transformations are frozen.

      Frozen transformations will be permanently glued to the original
      dataset so that they can't be changed anymore. This is usually done
      when using transformations to create derived datasets: in this way
      freezing the transformations will ensure that the user won't be able
      to inadvertently change them by directly setting the transformations
      field or by using the other transformations utility methods like
      ``replace_transforms``. Please note that transformations of all groups
      will be frozen. If you want to freeze a specific group, please use
      ``freeze_group_transforms``.

      The current dataset will not be affected.

      :return: A new dataset with the current transformations frozen.


   .. method:: freeze_group_transforms(self: TTransformationDataset, group_name: str) -> TTransformationDataset

      Returns a new dataset where the transformations for a specific group
      are frozen.

      Frozen transformations will be permanently glued to the original
      dataset so that they can't be changed anymore. This is usually done
      when using transformations to create derived datasets: in this way
      freezing the transformations will ensure that the user won't be able
      to inadvertently change them by directly setting the transformations
      field or by using the other transformations utility methods like
      ``replace_transforms``. To freeze transformations of all groups
      please use ``freeze_transforms``.

      The current dataset will not be affected.

      :return: A new dataset with the transformations frozen for the given
          group.


   .. method:: add_transforms(self: TTransformationDataset, transform: Callable[[T_co], Any] = None, target_transform: Callable[[int], int] = None) -> TTransformationDataset

      Returns a new dataset with the given transformations added to
      the existing ones.

      The transformations will be added to the current transformations group.
      Other transformation groups will not be affected.

      The given transformations will be added "at the end" of previous
      transformations of the current transformations group. This means
      that existing transformations will be applied to the patterns first.

      The current dataset will not be affected.

      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :return: A new dataset with the added transformations.


   .. method:: replace_transforms(self: TTransformationDataset, transform: XTransform, target_transform: YTransform) -> TTransformationDataset

      Returns a new dataset with the existing transformations replaced with
      the given ones.

      The given transformations will replace the ones of the current
      transformations group. Other transformation groups will not be affected.

      If this dataset was created with ``chain_transformations`` set to True
      and if the original dataset is an instance of
      :class:`TransformationDataset`, then the transformations of the
      original set will be overwritten as well. This operation will create a
      copy of this dataset.

      The current dataset will not be affected.

      Note that this function will not override frozen transformations. This
      will also not affect transformations found in datasets that are not
      instances of :class:`TransformationDataset`.

      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :return: A new dataset with the new transformations.


   .. method:: with_transforms(self: TTransformationDataset, group_name: str) -> TTransformationDataset

      Returns a new dataset with the transformations of a different group
      loaded.

      The current dataset will not be affected.

      :param group_name: The name of the transformations group to use.
      :return: A new dataset with the new transformations.


   .. method:: add_transforms_group(self: TTransformationDataset, group_name: str, transform: XTransform, target_transform: YTransform) -> TTransformationDataset

      Returns a new dataset with a new transformations group.

      The current dataset will not be affected.

      This method raises an exception if a group with the same name already
      exists.

      :param group_name: The name of the new transformations group.
      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :return: A new dataset with the new transformations.


   .. method:: _fork_dataset(self: TTransformationDataset) -> TTransformationDataset


   .. method:: _freeze_dataset_group(dataset_copy: TTransformationDataset, group_name: str)
      :staticmethod:


   .. method:: _get_single_item(self, idx: int)


   .. method:: _apply_transforms(self, pattern: T_co, label: int)


   .. method:: _check_groups_dict_format(groups_dict)
      :staticmethod:


   .. method:: _initialize_groups_dict(self, transform_groups: Optional[Dict[str, Tuple[XTransform, YTransform]]], dataset: Any, transform: XTransform, target_transform: YTransform) -> Dict[str, Tuple[XTransform, YTransform]]

      A simple helper method that tries to fill the 'train' and 'test'
      groups as those two groups must always exist.

      If no transform_groups are passed to the class constructor, then
      the transform and target_transform parameters are used for both groups.

      If train transformations are set and test transformations are not, then
      train transformations will be used for the test group.

      :param dataset: The original dataset. Will be used to detect existing
          groups.
      :param transform: The transformation passed as a parameter to the
          class constructor.
      :param target_transform: The target transformation passed as a parameter
          to the class constructor.


   .. method:: _initialize_targets_sequence(self, dataset) -> Sequence[int]


   .. method:: _set_original_dataset_transform_group(self, group_name: str) -> None


   .. method:: _freeze_original_dataset(self, group_name: str) -> None


   .. method:: _replace_original_dataset_group(self, transform: XTransform, target_transform: YTransform) -> None


   .. method:: _add_original_dataset_group(self, group_name: str) -> None


   .. method:: _add_groups_from_original_dataset(self, dataset, transform_groups) -> None



.. function:: default_loader(path)

   Sets the default image loader for the Pytorch Dataset.

   :param path: relative or absolute path of the file to load.

   :returns: Returns the image as a RGB PIL image.


.. function:: default_flist_reader(flist, root)

   This reader reads a filelist and return a list of paths.

   :param flist: path of the flislist to read. The flist format should be:
       impath label, impath label,  ...(same to caffe's filelist)
   :param root: path to the dataset root. Each file defined in the file list
       will be searched in <root>/<impath>.

   :returns: Returns a list of paths (the examples to be loaded).


.. py:class:: FilelistDataset(root, flist, transform=None, target_transform=None, flist_reader=default_flist_reader, loader=default_loader)

   Bases: :class:`torch.utils.data.Dataset`

   This class extends the basic Pytorch Dataset class to handle filelists as
   main data source.

           This reader reads a filelist and return a list of paths.

           :param root: root path where the data to load are stored.
           :param flist: path of the flislist to read. The flist format should be:
               impath label
   impath label
    ...(same to caffe's filelist)
           :param transform: eventual transformation to add to the input data (x)
           :param target_transform: eventual transformation to add to the targets
               (y)
           :param root: root path where the data to load are stored.
           :param flist_reader: loader function to use (for the filelists) given
               path.
           :param loader: loader function to use (for the real data) given path.
           

   .. method:: __getitem__(self, index)

      Returns next element in the dataset given the current index.

      :param index: index of the data to get.
      :return: loaded item.


   .. method:: __len__(self)

      Returns the total number of elements in the dataset.

      :return: Total number of dataset items.



.. function:: datasets_from_filelists(root, train_filelists, test_filelists, complete_test_set_only=False, train_transform=None, train_target_transform=None, test_transform=None, test_target_transform=None)

   This reader reads a list of Caffe-style filelists and returns the proper
       Dataset objects.

       A Caffe-style list is just a text file where, for each line, two elements
       are described: the path to the pattern (relative to the root parameter)
       and its class label. Those two elements are separated by a single white
       space.

       This method reads each file list and returns a separate
       dataset for each of them.

       :param root: root path where the data to load are stored.
       :param train_filelists: list of paths to train filelists. The flist format
           should be: impath label
   impath label
    ...(same to caffe's filelist)
       :param test_filelists: list of paths to test filelists. It can be also a
           single path when the datasets is the same for each batch.
       :param complete_test_set_only: if True, test_filelists must contain
           the path to a single filelist that will serve as the complete test set.
           Alternatively, test_filelists can be the path (str) to the complete test
           set filelist. If False, train_filelists and test_filelists must contain
           the same amount of filelists paths. Defaults to False.
       :param train_transform: The transformation to apply to training patterns.
           Defaults to None.
       :param train_target_transform: The transformation to apply to training
           patterns targets. Defaults to None.
       :param test_transform: The transformation to apply to test patterns.
           Defaults to None.
       :param test_target_transform: The transformation to apply to test
           patterns targets. Defaults to None.

       :return: list of tuples (train dataset, test dataset) for each train
           filelist in the list.
       


.. py:class:: CUB200(root, train=True, transform=None, loader=default_loader, download=False)

   Bases: :class:`torch.utils.data.Dataset`

   An abstract class representing a :class:`Dataset`.

   All datasets that represent a map from keys to data samples should subclass
   it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a
   data sample for a given key. Subclasses could also optionally overwrite
   :meth:`__len__`, which is expected to return the size of the dataset by many
   :class:`~torch.utils.data.Sampler` implementations and the default options
   of :class:`~torch.utils.data.DataLoader`.

   .. note::
     :class:`~torch.utils.data.DataLoader` by default constructs a index
     sampler that yields integral indices.  To make it work with a map-style
     dataset with non-integral indices/keys, a custom sampler must be provided.

   .. attribute:: filename
      :annotation: = images.tgz

      

   .. attribute:: metadata
      :annotation: = lists.tgz

      

   .. attribute:: basefolder
      :annotation: = images

      

   .. attribute:: tgz_md5
      :annotation: = 2bbe304ef1aa3ddb6094aa8f53487cf2

      

   .. method:: _load_metadata(self)


   .. method:: _check_integrity(self)


   .. method:: __len__(self)


   .. method:: __getitem__(self, idx)



.. data:: dataset
   

   

