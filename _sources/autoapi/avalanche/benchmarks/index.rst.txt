:mod:`avalanche.benchmarks`
===========================

.. py:module:: avalanche.benchmarks


Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   classic/index.rst
   datasets/index.rst
   generators/index.rst
   scenarios/index.rst
   utils/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.DatasetPart
   avalanche.benchmarks.DatasetType
   avalanche.benchmarks.IStepInfo
   avalanche.benchmarks.IScenarioStream
   avalanche.benchmarks.GenericCLScenario
   avalanche.benchmarks.GenericScenarioStream
   avalanche.benchmarks.GenericStepInfo
   avalanche.benchmarks.AbstractStepInfo
   avalanche.benchmarks.NCScenario
   avalanche.benchmarks.NCStepInfo
   avalanche.benchmarks.NIScenario
   avalanche.benchmarks.NIStepInfo
   avalanche.benchmarks.OPENLORIS_DATA



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.create_multi_dataset_generic_scenario
   avalanche.benchmarks.create_generic_scenario_from_filelists
   avalanche.benchmarks.create_generic_scenario_from_tensors
   avalanche.benchmarks.make_ni_transformation_subset
   avalanche.benchmarks.nc_scenario
   avalanche.benchmarks.ni_scenario
   avalanche.benchmarks.dataset_scenario
   avalanche.benchmarks.filelist_scenario
   avalanche.benchmarks.tensor_scenario
   avalanche.benchmarks.CORe50
   avalanche.benchmarks.SplitTinyImageNet
   avalanche.benchmarks.SplitCIFAR10
   avalanche.benchmarks._get_cifar10_dataset
   avalanche.benchmarks.SplitCIFAR100
   avalanche.benchmarks.SplitCIFAR110
   avalanche.benchmarks.SplitMNIST
   avalanche.benchmarks.PermutedMNIST
   avalanche.benchmarks.RotatedMNIST
   avalanche.benchmarks.SplitFMNIST
   avalanche.benchmarks.SplitImageNet
   avalanche.benchmarks.SplitCUB200
   avalanche.benchmarks.create_generic_scenario_from_filelists
   avalanche.benchmarks.OpenLORIS


.. py:class:: DatasetPart

   Bases: :class:`enum.Enum`

   An enumeration defining the different dataset parts

   Create and return a new object.  See help(type) for accurate signature.

   .. attribute:: CURRENT
      :annotation: = 1

      

   .. attribute:: CUMULATIVE
      :annotation: = 2

      

   .. attribute:: OLD
      :annotation: = 3

      

   .. attribute:: FUTURE
      :annotation: = 4

      

   .. attribute:: COMPLETE
      :annotation: = 5

      


.. py:class:: DatasetType

   Bases: :class:`enum.Enum`

   An enumeration defining the different dataset types

   Create and return a new object.  See help(type) for accurate signature.

   .. attribute:: TRAIN
      :annotation: = 1

      

   .. attribute:: VALIDATION
      :annotation: = 2

      


.. data:: TrainSet
   

   

.. data:: TestSet
   

   

.. py:class:: IStepInfo

   Bases: :class:`Protocol[TScenario, TScenarioStream]`

   Definition of a learning step. A learning step contains a set of patterns
   which has become available at a particular time instant. The content and
   size of a Step is defined by the specific benchmark that creates the
   IStepInfo instance.

   For instance, a step of a New Classes scenario will contain all patterns
   belonging to a subset of classes of the original training set. A step of a
   New Instance scenario will contain patterns from previously seen classes.

   Steps of  Single Incremental Task (a.k.a. task-free) scenarios are usually
   called "batches" while in Multi Task scenarios a Step is usually associated
   to a "task". Finally, in a Multi Incremental Task scenario the Step may be
   composed by patterns from different tasks.

   .. attribute:: origin_stream
      :annotation: :TScenarioStream

      A reference to the original stream from which this step was obtained.


   .. attribute:: scenario
      :annotation: :TScenario

      A reference to the scenario.


   .. attribute:: current_step
      :annotation: :int

      The current step. This is an incremental, 0-indexed, value used to
      keep track of the position of current step in the original stream.

      Beware that this value only describes the step position in the original
      stream and may be unrelated to the order in which the strategy will
      receive steps


   .. method:: dataset(self) -> TransformationDataset
      :property:

      The dataset containing the patterns available in this step.


   .. method:: task_label(self) -> int
      :property:

      The task label. This value will never have value "None". However,
      for scenarios that don't produce task labels a placeholder value like 0
      is usually set.



.. data:: TStepInfo
   

   

.. data:: TScenario
   

   

.. py:class:: IScenarioStream

   Bases: :class:`Protocol[TScenario, TStepInfo]`

   A scenario stream describes a sequence of incremental steps. Steps are
   described as :class:`IStepInfo` instances. They contain a set of patterns
   which has become available at a particular time instant along with any
   optional, scenario specific, metadata.

   Most scenario expose two different streams: the training stream and the test
   stream.

   .. attribute:: name
      :annotation: :str

      The name of the stream.


   .. attribute:: scenario
      :annotation: :TScenario

      A reference to the scenario this stream belongs to.


   .. method:: __getitem__(self: TScenarioStream, step_idx: Union[int, slice, Iterable[int]]) -> Union[TStepInfo, TScenarioStream]

      Gets a step given its step index (or a stream slice given the step
      order).

      :param step_idx: An int describing the step index or an iterable/slice
          object describing a slice of this stream.
      :return: The step instance associated to the given step index or
          a sliced stream instance.


   .. method:: __len__(self) -> int



.. data:: TScenarioStream
   

   

.. data:: TGenericCLScenario
   

   

.. py:class:: GenericCLScenario(: TGenericCLScenario, original_train_dataset: TrainSet, original_test_dataset: TestSet, train_dataset: TransformationDataset, test_dataset: TransformationDataset, train_steps_patterns_assignment: Sequence[Sequence[int]], test_steps_patterns_assignment: Sequence[Sequence[int]], task_labels: Sequence[int], complete_test_set_only: bool = False, reproducibility_data: Optional[Dict[str, Any]] = None, step_factory: Callable[['GenericScenarioStream', int], TStepInfo] = None)

   Bases: :class:`Generic[TrainSet, TestSet, TStepInfo]`

   Base implementation of a Continual Learning scenario. A Continual Learning
   scenario is defined by a sequence of steps (batches or tasks depending on
   the terminology), with each step containing the training (and test) data
   that becomes available at a certain time instant.

   From a practical point of view, this means that we usually have to define
   two datasets (training and test), and some way to assign the patterns
   contained in these datasets to each step.

   This assignment is usually made in children classes, with this class serving
   as the more general implementation. This class handles the most simple type
   of assignment: each step is defined by a list of patterns (identified by
   their indexes) contained in that step.

   Creates an instance of a Continual Learning scenario.

   The scenario is defined by the train and test datasets plus the
   assignment of patterns to steps (batches/tasks).

   :param train_dataset: The training dataset. The dataset must be a
       subclass of :class:`TransformationDataset`. For instance, one can
       use the datasets from the torchvision package like that:
       ``train_dataset=TransformationDataset(torchvision_dataset)``.
   :param test_dataset: The test dataset. The dataset must be a
       subclass of :class:`TransformationDataset`. For instance, one can
       use the datasets from the torchvision package like that:
       ``test_dataset=TransformationDataset(torchvision_dataset)``.
   :param train_steps_patterns_assignment: A list of steps. Each step is
       in turn defined by a list of integers describing the pattern index
       inside the training dataset.
   :param test_steps_patterns_assignment: A list of steps. Each step is
       in turn defined by a list of integers describing the pattern index
       inside the test dataset.
   :param task_labels: The mapping from step IDs to task labels, usually
       as a list of integers.
   :param complete_test_set_only: If True, only the complete test
       set will be returned from test set related methods of the linked
       :class:`GenericStepInfo` instances. This also means that the
       ``test_steps_patterns_assignment`` parameter can be a single element
       or even an empty list (in which case, the full set defined by
       the ``test_dataset`` parameter will be returned). The returned
       task label for the complete test set will be the first element
       of the ``task_labels`` parameter. Defaults to False, which means
       that ```train_steps_patterns_assignment`` and
       ``test_steps_patterns_assignment`` parameters must describe an equal
       amount of steps.
   :param reproducibility_data: If not None, overrides the
       ``train/test_steps_patterns_assignment`` and ``task_labels``
       parameters. This is usually a dictionary containing data used to
       reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.
   :param step_factory: If not None, a callable that, given the scenario
       instance and the step ID, returns a step info instance. This
       parameter is usually used in subclasses (when invoking the super
       constructor) to specialize the step info class. Defaults to None,
       which means that the :class:`GenericStepInfo` constructor will be
       used.

   .. attribute:: original_train_dataset
      :annotation: :TrainSet

      The original training set. 


   .. attribute:: original_test_dataset
      :annotation: :TestSet

      The original test set. 


   .. attribute:: train_dataset
      :annotation: :TransformationDataset

      The training set used to generate the incremental steps. 


   .. attribute:: test_dataset
      :annotation: :TransformationDataset

      The test set used to generate the incremental steps. 


   .. attribute:: train_steps_patterns_assignment
      :annotation: :Sequence[Sequence[int]]

      A list containing which training patterns are assigned to each step.
      Patterns are identified by their id w.r.t. the dataset found in the 
      train_dataset field. 


   .. attribute:: test_steps_patterns_assignment
      :annotation: :Sequence[Sequence[int]]

      A list containing which test patterns are assigned to each step.
      Patterns are identified by their id w.r.t. the dataset found in the 
      test_dataset field 


   .. attribute:: task_labels
      :annotation: :Sequence[int]

      The task label of each step. 


   .. attribute:: complete_test_set_only
      :annotation: :bool

      If True, only the complete test set will be returned from step info
      instances.

      This flag is usually set to true in scenarios where having one separate
      test set aligned to each training step is impossible or doesn't make
      sense from a semantic point of view.


   .. attribute:: n_steps
      :annotation: :int

      The number of incremental steps this scenario is made of. 


   .. attribute:: train_stream
      :annotation: :GenericScenarioStream[TStepInfo, TGenericCLScenario]

      The stream used to obtain the training steps. This stream can be sliced
      in order to obtain a subset of this stream.


   .. attribute:: test_stream
      :annotation: :GenericScenarioStream[TStepInfo, TGenericCLScenario]

      The stream used to obtain the test steps. This stream can be sliced
      in order to obtain a subset of this stream.

      Beware that, in certain scenarios, this stream may contain a single
      element. Check the ``complete_test_set_only`` field for more details.


   .. method:: get_reproducibility_data(self) -> Dict[str, Any]

      Gets the data needed to reproduce this experiment.

      This data can be stored using the pickle module or some other mechanism.
      It can then be loaded by passing it as the ``reproducibility_data``
      parameter in the constructor.

      Child classes should get the reproducibility dictionary from super class
      and then merge their custom data before returning it.

      :return: A dictionary containing the data needed to reproduce the
          experiment.


   .. method:: get_classes_timeline(self, current_step: int)

      Returns the classes timeline for a this scenario.

      Given a step ID, this method returns the classes in this step,
      previously seen classes, the cumulative class list and a list
      of classes that will be encountered in next steps.

      :param current_step: The reference step ID.
      :return: A tuple composed of four lists: the first list contains the
          IDs of classes in this step, the second contains IDs of classes seen
          in previous steps, the third returns a cumulative list of classes
          (that is, the union of the first two list) while the last one
          returns a list of classes that will be encountered in next steps.


   .. method:: classes_in_step(self) -> Sequence[Set[int]]
      :property:

      A list that, for each step (identified by its index/ID),
      stores a set of the (optionally remapped) IDs of classes of patterns
      assigned to that step. 



.. py:class:: GenericScenarioStream(: TGenericScenarioStream, name: str, scenario: TGenericCLScenario, *, slice_ids: List[int] = None)

   Bases: :class:`Generic[TStepInfo, TGenericCLScenario]`, :class:`IScenarioStream[TGenericCLScenario, TStepInfo]`, :class:`Sequence[TStepInfo]`

   Initialize self.  See help(type(self)) for accurate signature.

   .. attribute:: slice_ids
      :annotation: :Optional[List[int]]

      Describes which steps are contained in the current stream slice. 
      Can be None, which means that this object is the original stream. 


   .. method:: __len__(self) -> int

      Gets the number of steps this scenario it's made of.

      :return: The number of steps in this scenario.


   .. method:: __getitem__(self, step_idx: Union[int, slice, Iterable[int]]) -> Union[TStepInfo, TScenarioStream]

      Gets a step given its step index (or a stream slice given the step
      order).

      :param step_idx: An int describing the step index or an iterable/slice
          object describing a slice of this stream.

      :return: The step instance associated to the given step index or
          a sliced stream instance.


   .. method:: _create_slice(self: TGenericScenarioStream, steps_slice: Union[int, slice, Iterable[int]]) -> TScenarioStream

      Creates a sliced version of this stream.

      In its base version, a shallow copy of this stream is created and
      then its ``slice_ids`` field is adapted.

      :param steps_slice: The slice to use.
      :return: A sliced version of this stream.



.. py:class:: GenericStepInfo(: TGenericStepInfo, origin_stream: GenericScenarioStream[TGenericStepInfo, TGenericCLScenario], current_step: int)

   Bases: :class:`AbstractStepInfo[TGenericCLScenario, GenericScenarioStream[TGenericStepInfo, TGenericCLScenario]]`

   Definition of a learning step based on a :class:`GenericCLScenario`
   instance.

   This step implementation uses the generic step-patterns assignment defined
   in the :class:`GenericCLScenario` instance. Instances of this class are
   usually obtained from a scenario stream.

   Creates an instance of a generic step info given the stream from this
   step was taken and and the current step ID.

   :param origin_stream: The stream from which this step was obtained.
   :param current_step: The current step ID, as an integer.

   .. method:: _get_task_label(self, step: int)

      Returns the task label given the step ID.

      :param step: The step ID.

      :return: The task label of the step.


   .. method:: dataset(self) -> TransformationDataset
      :property:


   .. method:: task_label(self) -> int
      :property:


   .. method:: _is_train(self)



.. py:class:: AbstractStepInfo(: TStepInfo, origin_stream: TScenarioStream, current_step: int, classes_in_this_step: Sequence[int], previous_classes: Sequence[int], classes_seen_so_far: Sequence[int], future_classes: Optional[Sequence[int]])

   Bases: :class:`IStepInfo[TScenario, TScenarioStream]`, :class:`abc.ABC`

   Definition of a learning step. A learning step contains a set of patterns
   which has become available at a particular time instant. The content and
   size of a Step is defined by the specific benchmark that creates the
   step instance.

   For instance, a step of a New Classes scenario will contain all patterns
   belonging to a subset of classes of the original training set. A step of a
   New Instance scenario will contain patterns from previously seen classes.

   Steps of  Single Incremental Task (a.k.a. task-free) scenarios are usually
   called "batches" while in Multi Task scenarios a Step is usually associated
   to a "task". Finally, in a Multi Incremental Task scenario the Step may be
   composed by patterns from different tasks.

   Creates an instance of the abstract step info given the scenario stream,
   the current step ID and data about the classes timeline.

   :param origin_stream: The stream from which this step was obtained.
   :param current_step: The current step ID, as an integer.
   :param classes_in_this_step: The list of classes in this step.
   :param previous_classes: The list of classes in previous steps.
   :param classes_seen_so_far: List of classes of current and previous
       steps.
   :param future_classes: The list of classes of next steps.

   .. attribute:: classes_in_this_step
      :annotation: :Sequence[int]

      The list of classes in this step 


   .. attribute:: previous_classes
      :annotation: :Sequence[int]

      The list of classes in previous steps 


   .. attribute:: classes_seen_so_far
      :annotation: :Sequence[int]

      List of classes of current and previous steps 


   .. attribute:: future_classes
      :annotation: :Optional[Sequence[int]]

      The list of classes of next steps 



.. function:: create_multi_dataset_generic_scenario(train_dataset_list: Sequence[SupportedDataset], test_dataset_list: Sequence[SupportedDataset], task_labels: Sequence[int], complete_test_set_only: bool = False) -> GenericCLScenario

   Creates a generic scenario given a list of datasets and the respective task
   labels. Each training dataset will be considered as a separate training
   step. Contents of the datasets will not be changed, including the targets.

   When loading the datasets from a set of fixed filelist, consider using
   the :func:`create_generic_scenario_from_filelists` helper method instead.

   In its base form, this function accepts a list of test datsets that must
   contain the same amount of datasets of the training list.
   Those pairs are then used to create the "past", "cumulative"
   (a.k.a. growing) and "future" test sets. However, in certain Continual
   Learning scenarios only the concept of "complete" test set makes sense. In
   that case, the ``complete_test_set_only`` should be set to True (see the
   parameter description for more info).

   Beware that pattern transformations must already be included in the
   datasets (when needed).

   :param train_dataset_list: A list of training datasets.
   :param test_dataset_list: A list of test datasets.
   :param task_labels: A list of task labels. Must contain the same amount of
       elements of the ``train_dataset_list`` parameter. For
       Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
       a list of zeros. For Multi Task scenario, this is usually a list of
       ascending task labels (starting from 0).
   :param complete_test_set_only: If True, only the complete test set will
       be returned by the scenario. This means that the ``test_dataset_list``
       parameter must be list with a single element (the complete test set).
       Defaults to False, which means that ``train_dataset_list`` and
       ``test_dataset_list`` must contain the same amount of datasets.

   :returns: A :class:`GenericCLScenario` instance.


.. function:: create_generic_scenario_from_filelists(root: Union[str, Path], train_file_lists: Sequence[Union[str, Path]], test_file_lists: Union[Union[str, Path], Sequence[Union[str, Path]]], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, test_transform=None, test_target_transform=None) -> GenericCLScenario

   Creates a generic scenario given a list of filelists and the respective task
   labels. A separate dataset will be created for each filelist and each of
   those training datasets will be considered a separate training step.
   Contents of the datasets will not be changed, including the targets.

   In its base form, this function accepts a list of filelists for the test
   datsets that must contain the same amount of elements of the training list.
   Those pairs of datasets are then used to create the "past", "cumulative"
   (a.k.a. growing) and "future" test sets. However, in certain Continual
   Learning scenarios only the concept of "complete" test set makes sense. In
   that case, the ``complete_test_set_only`` should be set to True (see the
   parameter description for more info).

   This helper functions is the best shot when loading Caffe-style dataset
   based on filelists.

   :param root: The root path of the dataset.
   :param train_file_lists: A list of filelists describing the
       paths of the training patterns for each step.
   :param test_file_lists: A list of filelists describing the
       paths of the test patterns for each step.
   :param task_labels: A list of task labels. Must contain the same amount of
       elements of the ``train_file_lists`` parameter. For
       Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
       a list of zeros. For Multi Task scenario, this is usually a list of
       ascending task labels (starting from 0).
   :param complete_test_set_only: If True, only the complete test set will
       be returned by the scenario. This means that the ``test_file_lists``
       parameter must be list with a single element (the complete test set).
       Alternatively, can be a plain string or :class:`Path` object.
       Defaults to False, which means that ``train_file_lists`` and
       ``test_file_lists`` must contain the same amount of filelists paths.
   :param train_transform: The transformation to apply to training patterns.
       Defaults to None.
   :param train_target_transform: The transformation to apply to training
       patterns targets. Defaults to None.
   :param test_transform: The transformation to apply to test patterns.
       Defaults to None.
   :param test_target_transform: The transformation to apply to test
       patterns targets. Defaults to None.

   :returns: A :class:`GenericCLScenario` instance.


.. function:: create_generic_scenario_from_tensors(train_data_x: Sequence[Any], train_data_y: Sequence[Sequence[SupportsInt]], test_data_x: Union[Any, Sequence[Any]], test_data_y: Union[Any, Sequence[Sequence[SupportsInt]]], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, test_transform=None, test_target_transform=None) -> GenericCLScenario

   Creates a generic scenario given lists of Tensors and the respective task
   labels. A separate dataset will be created from each Tensor pair (x + y)
   and each of those training datasets will be considered a separate
   training step. Contents of the datasets will not be changed, including the
   targets. Using this helper function is the lower level way to create a
   Continual Learning scenario. When possible, consider using higher level
   helpers.

   In its base form, the test lists must contain the same amount of elements of
   the training lists. Those pairs of datasets are then used to create the
   "past", "cumulative" (a.k.a. growing) and "future" test sets.
   However, in certain Continual Learning scenarios only the concept of
   "complete" test set makes sense. In that case, the
   ``complete_test_set_only`` should be set to True (see the parameter
   description for more info).

   :param train_data_x: A list of Tensors (one per step) containing the
       patterns of the training sets.
   :param train_data_y: A list of Tensors or int lists containing the
       labels of the patterns of the training sets. Must contain the same
       number of elements of ``train_datasets_x``.
   :param test_data_x: A Tensor or a list of Tensors (one per step) containing
       the patterns of the test sets.
   :param test_data_y: A Tensor or a list of Tensors or int lists containing
       the labels of the patterns of the test sets. Must contain the same
       number of elements of ``test_datasets_x``.
   :param task_labels: A list of task labels. Must contain the same amount of
       elements of the ``train_datasets_x`` parameter. For
       Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
       a list of zeros. For Multi Task scenario, this is usually a list of
       ascending task labels (starting from 0).
   :param complete_test_set_only: If True, only the complete test set will
       be returned by the scenario. This means that the ``test_datasets_x`` and
       ``test_datasets_y`` parameters must be lists with a single element
       (the complete test set). Defaults to False, which means that
       ``train_file_lists`` and ``test_file_lists`` must contain the same
       amount of filelists paths.
   :param train_transform: The transformation to apply to training patterns.
       Defaults to None.
   :param train_target_transform: The transformation to apply to training
       patterns targets. Defaults to None.
   :param test_transform: The transformation to apply to test patterns.
       Defaults to None.
   :param test_target_transform: The transformation to apply to test
       patterns targets. Defaults to None.

   :returns: A :class:`GenericCLScenario` instance.


.. py:class:: NCScenario(train_dataset: TrainSet, test_dataset: TestSet, n_steps: int, task_labels: bool, shuffle: bool = True, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, per_step_classes: Optional[Dict[int, int]] = None, class_ids_from_zero_from_first_step: bool = False, class_ids_from_zero_in_each_step: bool = False, reproducibility_data: Optional[Dict[str, Any]] = None)

   Bases: :class:`GenericCLScenario[TrainSet, TestSet, 'NCStepInfo']`, :class:`Generic[TrainSet, TestSet]`

   This class defines a "New Classes" scenario. Once created, an instance
   of this class can be iterated in order to obtain the step sequence
   under the form of instances of :class:`NCStepInfo`.

   This class can be used directly. However, we recommend using facilities like
   :func:`avalanche.benchmarks.generators.nc_scenario`.

   Creates a ``NCGenericScenario`` instance given the training and test
   Datasets and the number of steps.

   By default, the number of classes will be automatically detected by
   looking at the training Dataset ``targets`` field. Classes will be
   uniformly distributed across ``n_steps`` unless a ``per_step_classes``
   argument is specified.

   The number of classes must be divisible without remainder by the number
   of steps. This also applies when the ``per_step_classes`` argument is
   not None.

   :param train_dataset: The training dataset. The dataset must be a
       subclass of :class:`TransformationDataset`. For instance, one can
       use the datasets from the torchvision package like that:
       ``train_dataset=TransformationDataset(torchvision_dataset)``.
   :param test_dataset: The test dataset. The dataset must be a
       subclass of :class:`TransformationDataset`. For instance, one can
       use the datasets from the torchvision package like that:
       ``test_dataset=TransformationDataset(torchvision_dataset)``.
   :param n_steps: The number of steps.
   :param task_labels: If True, each step will have an ascending task
       label. If False, the task label will be 0 for all the steps.
   :param shuffle: If True, the class order will be shuffled. Defaults to
       True.
   :param seed: If shuffle is True and seed is not None, the class order
       will be shuffled according to the seed. When None, the current
       PyTorch random number generator state will be used.
       Defaults to None.
   :param fixed_class_order: If not None, the class order to use (overrides
       the shuffle argument). Very useful for enhancing
       reproducibility. Defaults to None.
   :param per_step_classes: Is not None, a dictionary whose keys are
       (0-indexed) step IDs and their values are the number of classes
       to include in the respective steps. The dictionary doesn't
       have to contain a key for each step! All the remaining steps
       will contain an equal amount of the remaining classes. The
       remaining number of classes must be divisible without remainder
       by the remaining number of steps. For instance,
       if you want to include 50 classes in the first step
       while equally distributing remaining classes across remaining
       steps, just pass the "{0: 50}" dictionary as the
       per_step_classes parameter. Defaults to None.
   :param class_ids_from_zero_from_first_step: If True, original class IDs
       will be remapped so that they will appear as having an ascending
       order. For instance, if the resulting class order after shuffling
       (or defined by fixed_class_order) is [23, 34, 11, 7, 6, ...] and
       class_ids_from_zero_from_first_step is True, then all the patterns
       belonging to class 23 will appear as belonging to class "0",
       class "34" will be mapped to "1", class "11" to "2" and so on.
       This is very useful when drawing confusion matrices and when dealing
       with algorithms with dynamic head expansion. Defaults to False.
       Mutually exclusive with the ``class_ids_from_zero_in_each_step``
       parameter.
   :param class_ids_from_zero_in_each_step: If True, original class IDs
       will be mapped to range [0, n_classes_in_step) for each step.
       Defaults to False. Mutually exclusive with the
       ``class_ids_from_zero_from_first_step parameter``.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options. This is usually a dictionary containing
       data used to reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   .. attribute:: classes_order
      :annotation: :List[int] = []

      Stores the class order (remapped class IDs). 


   .. attribute:: classes_order_original_ids
      :annotation: :List[int]

      Stores the class order (original class IDs) 


   .. attribute:: class_mapping
      :annotation: :List[int] = []

      class_mapping stores the class mapping so that
      mapped_class_id = class_mapping[original_class_id]. 


   .. attribute:: n_classes_per_step
      :annotation: :List[int] = []

      A list that, for each step (identified by its index/ID),
      stores the number of classes assigned to that step. 


   .. attribute:: original_classes_in_step
      :annotation: :List[Set[int]] = []

      A list that, for each step (identified by its index/ID),
      stores a list of the original IDs of classes assigned 
      to that step. 


   .. attribute:: class_ids_from_zero_from_first_step
      :annotation: :bool

      If True the class IDs have been remapped to start from zero. 


   .. attribute:: class_ids_from_zero_in_each_step
      :annotation: :bool

      If True the class IDs have been remapped to start from zero in 
      each step 


   .. attribute:: n_classes
      :annotation: :int

      The number of classes 


   .. method:: classes_in_step(self) -> Sequence[Set[int]]
      :property:


   .. method:: get_reproducibility_data(self)


   .. method:: classes_in_step_range(self, step_start: int, step_end: Optional[int] = None) -> List[int]

      Gets a list of classes contained in the given steps. The steps are
      defined by range. This means that only the classes in range
      [step_start, step_end) will be included.

      :param step_start: The starting step ID.
      :param step_end: The final step ID. Can be None, which means that all
          the remaining steps will be taken.

      :returns: The classes contained in the required step range.



.. py:class:: NCStepInfo(origin_stream: GenericScenarioStream['NCStepInfo', NCScenario[TrainSet, TestSet]], current_step: int)

   Bases: :class:`GenericStepInfo[NCScenario[TrainSet, TestSet], GenericScenarioStream['NCStepInfo', NCScenario[TrainSet, TestSet]]]`, :class:`Generic[TrainSet, TestSet]`

   Defines a "New Classes" step. It defines fields to obtain the current
   dataset and the associated task label. It also keeps a reference to the
   stream from which this step was taken.

   Creates a ``NCStepInfo`` instance given the stream from this
   step was taken and and the current step ID.

   :param origin_stream: The stream from which this step was obtained.
   :param current_step: The current step ID, as an integer.

   .. method:: dataset(self)
      :property:



.. py:class:: NIScenario(train_dataset: TrainSet, test_dataset: TestSet, n_steps: int, task_labels: bool = False, shuffle: bool = True, seed: Optional[int] = None, balance_steps: bool = False, min_class_patterns_in_step: int = 0, fixed_step_assignment: Optional[Sequence[Sequence[int]]] = None, reproducibility_data: Optional[Dict[str, Any]] = None)

   Bases: :class:`GenericCLScenario[TrainSet, TestSet, 'NIStepInfo']`, :class:`Generic[TrainSet, TestSet]`

   This class defines a "New Instance" scenario.
   Once created, an instance of this class can be iterated in order to obtain
   the step sequence under the form of instances of :class:`NIStepInfo`.

   Instances of this class can be created using the constructor directly.
   However, we recommend using facilities like
   :func:`avalanche.benchmarks.generators.ni_scenario`.

   Consider that every method from :class:`NIStepInfo` used to retrieve
   parts of the test set (past, current, future, cumulative) always return the
   complete test set. That is, they behave as the getter for the complete test
   set.

   Creates a NIScenario instance given the training and test Datasets and
   the number of steps.

   :param train_dataset: The training dataset. The dataset must be a
       subclass of :class:`TransformationDataset`. For instance, one can
       use the datasets from the torchvision package like that:
       ``train_dataset=TransformationDataset(torchvision_dataset)``.
   :param test_dataset: The test dataset. The dataset must be a
       subclass of :class:`TransformationDataset`. For instance, one can
       use the datasets from the torchvision package like that:
       ``test_dataset=TransformationDataset(torchvision_dataset)``.
   :param n_steps: The number of steps.
   :param task_labels: If True, each step will have an ascending task
       label. If False, the task label will be 0 for all the steps.
       Defaults to False.
   :param shuffle: If True, the patterns order will be shuffled. Defaults
       to True.
   :param seed: If shuffle is True and seed is not None, the class order
       will be shuffled according to the seed. When None, the current
       PyTorch random number generator state will be used.
       Defaults to None.
   :param balance_steps: If True, pattern of each class will be equally
       spread across all steps. If False, patterns will be assigned to
       steps in a complete random way. Defaults to False.
   :param min_class_patterns_in_step: The minimum amount of patterns of
       every class that must be assigned to every step. Compatible with
       the ``balance_steps`` parameter. An exception will be raised if
       this constraint can't be satisfied. Defaults to 0.
   :param fixed_step_assignment: If not None, the pattern assignment
       to use. It must be a list with an entry for each step. Each entry
       is a list that contains the indexes of patterns belonging to that
       step. Overrides the ``shuffle``, ``balance_steps`` and
       ``min_class_patterns_in_step`` parameters.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options, including ``fixed_step_assignment``.
       This is usually a dictionary containing data used to
       reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   .. method:: classes_in_step(self) -> Sequence[Set[int]]
      :property:


   .. method:: get_reproducibility_data(self) -> Dict[str, Any]



.. py:class:: NIStepInfo(origin_stream: GenericScenarioStream['NIStepInfo', NIScenario[TrainSet, TestSet]], current_step: int)

   Bases: :class:`GenericStepInfo[NIScenario[TrainSet, TestSet], GenericScenarioStream['NIStepInfo', NIScenario[TrainSet, TestSet]]]`, :class:`Generic[TrainSet, TestSet]`

   Defines a "New Instances" step. It defines fields to obtain the current
   dataset and the associated task label. It also keeps a reference to the
   stream from which this step was taken.

   Creates a ``NIStepInfo`` instance given the stream from this
   step was taken and and the current step ID.

   :param origin_stream: The stream from which this step was obtained.
   :param current_step: The current step ID, as an integer.


.. function:: make_ni_transformation_subset(dataset: IDatasetWithTargets, transform: Any, target_transform: Any, patterns_indexes: Union[None, Sequence[int]], bucket_classes: bool = False, sort_classes: bool = False, sort_indexes: bool = False) -> TransformationSubset

   Creates a subset given the list of patterns to include.

   :param dataset: The original dataset
   :param transform: The transform function for patterns. Can be None.
   :param target_transform: The transform function for targets. Can be None.
   :param patterns_indexes: A list of indexes of patterns to include.
       If None, all patterns will be included.
   :param bucket_classes: If True, the final Dataset will output patterns by
       grouping them by class. Defaults to True.
   :param sort_classes: If ``bucket_classes`` and ``sort_classes`` are both
       True, the final Dataset will output patterns by grouping them by class
       and the class groups will be ordered by class ID (ascending). Ignored
       if ``bucket_classes`` is False. Defaults to False.
   :param sort_indexes: If True, pattern indexes will be sorted (ascending).
       When grouping by class, patterns will be sorted inside their respective
       class buckets. Defaults to False.

   :returns: A :class:`TransformationSubset` that includes only the required
       patterns, in the order controlled by the ``bucket_classes``,
       ``sort_classes`` and ``sort_indexes`` parameters.


.. function:: nc_scenario(train_dataset: Union[Sequence[SupportedDataset], SupportedDataset], test_dataset: Union[Sequence[SupportedDataset], SupportedDataset], n_steps: int, task_labels: bool, *, shuffle: bool = True, seed: Optional[int] = None, fixed_class_order: Sequence[int] = None, per_step_classes: Dict[int, int] = None, class_ids_from_zero_from_first_step: bool = False, class_ids_from_zero_in_each_step: bool = False, one_dataset_per_step: bool = False, reproducibility_data: Dict[str, Any] = None) -> NCScenario

   This method is the high-level specific scenario generator for the
   "New Classes" (NC) case. Given a sequence of train and test datasets creates
   the continual stream of data as a series of steps. Each step will contain
   all the patterns belonging to a certain set of classes and a class won't be
   assigned to more than one step.

   The ``task_labels`` parameter determines if each incremental step has
   an increasing task label or if, at the contrary, a default task label "0"
   has to be assigned to all steps. This can be useful when differentiating
   between Single-Incremental-Task and Multi-Task scenarios.

   There are other important parameters that can be specified in order to tweak
   the behaviour of the resulting scenario. Please take a few minutes to read
   and understand them as they may save you a lot of work.

   This generator features an integrated reproducibility mechanism that allows
   the user to store and later re-load a scenario. For more info see the
   ``reproducibility_data`` parameter.

   :param train_dataset: A list of training datasets, or a single dataset.
   :param test_dataset: A list of test datasets, or a single test dataset.
   :param n_steps: The number of incremental steps. This is not used when
       using multiple train/test datasets with the ``one_dataset_per_step``
       parameter set to True.
   :param task_labels: If True, each step will have an ascending task
           label. If False, the task label will be 0 for all the steps.
   :param shuffle: If True, the class (or step) order will be shuffled.
       Defaults to True.
   :param seed: If ``shuffle`` is True and seed is not None, the class (or
       step) order will be shuffled according to the seed. When None, the
       current PyTorch random number generator state will be used. Defaults to
       None.
   :param fixed_class_order: If not None, the class order to use (overrides
       the shuffle argument). Very useful for enhancing reproducibility.
       Defaults to None.
   :param per_step_classes: Is not None, a dictionary whose keys are
       (0-indexed) step IDs and their values are the number of classes
       to include in the respective steps. The dictionary doesn't
       have to contain a key for each step! All the remaining steps
       will contain an equal amount of the remaining classes. The
       remaining number of classes must be divisible without remainder
       by the remaining number of steps. For instance,
       if you want to include 50 classes in the first step
       while equally distributing remaining classes across remaining
       steps, just pass the "{0: 50}" dictionary as the
       per_step_classes parameter. Defaults to None.
   :param class_ids_from_zero_from_first_step: If True, original class IDs
       will be remapped so that they will appear as having an ascending
       order. For instance, if the resulting class order after shuffling
       (or defined by fixed_class_order) is [23, 34, 11, 7, 6, ...] and
       class_ids_from_zero_from_first_step is True, then all the patterns
       belonging to class 23 will appear as belonging to class "0",
       class "34" will be mapped to "1", class "11" to "2" and so on.
       This is very useful when drawing confusion matrices and when dealing
       with algorithms with dynamic head expansion. Defaults to False.
       Mutually exclusive with the ``class_ids_from_zero_in_each_step``
       parameter.
   :param class_ids_from_zero_in_each_step: If True, original class IDs
       will be mapped to range [0, n_classes_in_step) for each step.
       Defaults to False. Mutually exclusive with the
       ``class_ids_from_zero_from_first_step`` parameter.
   :param one_dataset_per_step: available only when multiple train-test
       datasets are provided. If True, each dataset will be treated as a step.
       Mutually exclusive with the ``per_step_classes`` and
       ``fixed_class_order`` parameters. Overrides the ``n_steps`` parameter.
       Defaults to False.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options. This is usually a dictionary containing
       data used to reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   :return: A :class:`NCMultiTaskScenario` or :class:`NCSingleTaskScenario`
       instance initialized for the the SIT or MT scenario.


.. function:: ni_scenario(train_dataset: Union[Sequence[SupportedDataset], SupportedDataset], test_dataset: Union[Sequence[SupportedDataset], SupportedDataset], n_steps: int, *, task_labels: bool = False, shuffle: bool = True, seed: Optional[int] = None, balance_steps: bool = False, min_class_patterns_in_step: int = 0, fixed_step_assignment: Optional[Sequence[Sequence[int]]] = None, reproducibility_data: Optional[Dict[str, Any]] = None) -> NIScenario

   This method is the high-level specific scenario generator for the
   "New Instances" (NI) case. Given a sequence of train and test datasets
   creates the continual stream of data as a series of steps. Each step will
   contain patterns belonging to the same classes.

   The ``task_labels`` parameter determines if each incremental step has
   an increasing task label or if, at the contrary, a default task label "0"
   has to be assigned to all steps. This can be useful when differentiating
   between Single-Incremental-Task and Multi-Task scenarios.

   There are other important parameters that can be specified in order to tweak
   the behaviour of the resulting scenario. Please take a few minutes to read
   and understand them as they may save you a lot of work.

   This generator features an integrated reproducibility mechanism that allows
   the user to store and later re-load a scenario. For more info see the
   ``reproducibility_data`` parameter.

   :param train_dataset: A list of training datasets, or a single dataset.
   :param test_dataset: A list of test datasets, or a single test dataset.
   :param n_steps: The number of steps.
   :param task_labels: If True, each step will have an ascending task
           label. If False, the task label will be 0 for all the steps.
   :param shuffle: If True, patterns order will be shuffled.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param balance_steps: If True, pattern of each class will be equally
       spread across all steps. If False, patterns will be assigned to
       steps in a complete random way. Defaults to False.
   :param min_class_patterns_in_step: The minimum amount of patterns of
       every class that must be assigned to every step. Compatible with
       the ``balance_steps`` parameter. An exception will be raised if
       this constraint can't be satisfied. Defaults to 0.
   :param fixed_step_assignment: If not None, the pattern assignment
       to use. It must be a list with an entry for each step. Each entry
       is a list that contains the indexes of patterns belonging to that
       step. Overrides the ``shuffle``, ``balance_steps`` and
       ``min_class_patterns_in_step`` parameters.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options, including ``fixed_step_assignment``.
       This is usually a dictionary containing data used to
       reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   :return: A :class:`NIScenario` instance.


.. function:: dataset_scenario(train_dataset_list: Sequence[SupportedDataset], test_dataset_list: Sequence[SupportedDataset], task_labels: Sequence[int], complete_test_set_only: bool = False) -> GenericCLScenario

   Creates a generic scenario given a list of datasets and the respective task
   labels. Each training dataset will be considered as a separate training
   step. Contents of the datasets will not be changed, including the targets.

   When loading the datasets from a set of fixed file lists, consider using
   the :func:`filelist_scenario` helper method instead.

   In its base form, this function accepts a list of test datasets that must
   contain the same amount of datasets of the training list.
   Those pairs are then used to create the "past", "cumulative"
   (a.k.a. growing) and "future" test sets. However, in certain Continual
   Learning scenarios only the concept of "complete" test set makes sense. In
   that case, the ``complete_test_set_only`` should be set to True (see the
   parameter description for more info).

   Beware that pattern transformations must already be included in the
   datasets (when needed).

   :param train_dataset_list: A list of training datasets.
   :param test_dataset_list: A list of test datasets.
   :param task_labels: A list of task labels. Must contain the same amount of
       elements of the ``train_dataset_list`` parameter. For
       Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
       a list of zeros. For Multi Task scenario, this is usually a list of
       ascending task labels (starting from 0).
   :param complete_test_set_only: If True, only the complete test set will
       be returned by the scenario. This means that the ``test_dataset_list``
       parameter must be list with a single element (the complete test set).
       Defaults to False, which means that ``train_dataset_list`` and
       ``test_dataset_list`` must contain the same amount of datasets.

   :returns: A :class:`GenericCLScenario` instance.


.. function:: filelist_scenario(root: Union[str, Path], train_file_lists: Sequence[Union[str, Path]], test_file_lists: Union[Union[str, Path], Sequence[Union[str, Path]]], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, test_transform=None, test_target_transform=None) -> GenericCLScenario

   Creates a generic scenario given a list of filelists and the respective task
   labels. A separate dataset will be created for each filelist and each of
   those training datasets will be considered a separate training step.
   Contents of the datasets will not be changed, including the targets.

   In its base form, this function accepts a list of filelists for the test
   datsets that must contain the same amount of elements of the training list.
   Those pairs of datasets are then used to create the "past", "cumulative"
   (a.k.a. growing) and "future" test sets. However, in certain Continual
   Learning scenarios only the concept of "complete" test set makes sense. In
   that case, the ``complete_test_set_only`` should be set to True (see the
   parameter description for more info).

   This helper functions is the best shot when loading Caffe-style dataset
   based on filelists.

   :param root: The root path of the dataset.
   :param train_file_lists: A list of filelists describing the
       paths of the training patterns for each step.
   :param test_file_lists: A list of filelists describing the
       paths of the test patterns for each step.
   :param task_labels: A list of task labels. Must contain the same amount of
       elements of the ``train_file_lists`` parameter. For
       Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
       a list of zeros. For Multi Task scenario, this is usually a list of
       ascending task labels (starting from 0).
   :param complete_test_set_only: If True, only the complete test set will
       be returned by the scenario. This means that the ``test_file_lists``
       parameter must be list with a single element (the complete test set).
       Alternatively, can be a plain string or :class:`Path` object.
       Defaults to False, which means that ``train_file_lists`` and
       ``test_file_lists`` must contain the same amount of filelists paths.
   :param train_transform: The transformation to apply to training patterns.
       Defaults to None.
   :param train_target_transform: The transformation to apply to training
       patterns targets. Defaults to None.
   :param test_transform: The transformation to apply to test patterns.
       Defaults to None.
   :param test_target_transform: The transformation to apply to test
       patterns targets. Defaults to None.

   :returns: A :class:`GenericCLScenario` instance.


.. function:: tensor_scenario(train_data_x: Sequence[Any], train_data_y: Sequence[Sequence[SupportsInt]], test_data_x: Union[Any, Sequence[Any]], test_data_y: Union[Any, Sequence[Sequence[SupportsInt]]], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, test_transform=None, test_target_transform=None) -> GenericCLScenario

   Creates a generic scenario given lists of Tensors and the respective task
   labels. A separate dataset will be created from each Tensor pair (x + y)
   and each of those training datasets will be considered a separate
   training step. Contents of the datasets will not be changed, including the
   targets. Using this helper function is the lower level way to create a
   Continual Learning scenario. When possible, consider using higher level
   helpers.

   In its base form, the test lists must contain the same amount of elements of
   the training lists. Those pairs of datasets are then used to create the
   "past", "cumulative" (a.k.a. growing) and "future" test sets.
   However, in certain Continual Learning scenarios only the concept of
   "complete" test set makes sense. In that case, the
   ``complete_test_set_only`` should be set to True (see the parameter
   description for more info).

   :param train_data_x: A list of Tensors (one per step) containing the
       patterns of the training sets.
   :param train_data_y: A list of Tensors or int lists containing the
       labels of the patterns of the training sets. Must contain the same
       number of elements of ``train_datasets_x``.
   :param test_data_x: A Tensor or a list of Tensors (one per step) containing
       the patterns of the test sets.
   :param test_data_y: A Tensor or a list of Tensors or int lists containing
       the labels of the patterns of the test sets. Must contain the same
       number of elements of ``test_datasets_x``.
   :param task_labels: A list of task labels. Must contain the same amount of
       elements of the ``train_datasets_x`` parameter. For
       Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
       a list of zeros. For Multi Task scenario, this is usually a list of
       ascending task labels (starting from 0).
   :param complete_test_set_only: If True, only the complete test set will
       be returned by the scenario. This means that the ``test_datasets_x`` and
       ``test_datasets_y`` parameters must be lists with a single element
       (the complete test set). Defaults to False, which means that
       ``train_file_lists`` and ``test_file_lists`` must contain the same
       amount of filelists paths.
   :param train_transform: The transformation to apply to training patterns.
       Defaults to None.
   :param train_target_transform: The transformation to apply to training
       patterns targets. Defaults to None.
   :param test_transform: The transformation to apply to test patterns.
       Defaults to None.
   :param test_target_transform: The transformation to apply to test
       patterns targets. Defaults to None.

   :returns: A :class:`GenericCLScenario` instance.


.. function:: CORe50(root=expanduser('~') + '/.avalanche/data/core50/', scenario='nicv2_391', run=0)

   CORe50 continual scenario generator

   :param root: Path indicating where to store the dataset and related
       metadata. By default they will be stored in
       avalanche/datasets/core50/data/.
   :param scenario: CORe50 main scanario. I can be chosen between 'ni', 'nc',
       'nic', 'nicv2_79', 'nicv2_196' or 'nicv2_391.'
   :param run: number of run for the scenario. Batch ordering change based
       on this parameter (a number between 0 and 9).

   :returns: it returns a :class:`GenericCLScenario` instance that can be
       iterated.


.. function:: SplitTinyImageNet(n_steps=10, return_task_id=False, seed=0, fixed_class_order=None, train_transform=_default_train_transform, test_transform=_default_test_transform)

   Creates a CL scenario using the Tiny ImageNet dataset.
   If the dataset is not present in the computer the method automatically
   download it and store the data in the data folder.

   :param n_steps: The number of steps in the current scenario.
   :param return_task_id: if True, for every step the task id is returned and
       the Scenario is Multi Task. This means that the scenario returned
       will be of type ``NCMultiTaskScenario``. If false the task index is
       not returned (default to 0 for every batch) and the returned scenario
       is of type ``NCSingleTaskScenario``.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param fixed_class_order: A list of class IDs used to define the class
       order. If None, value of ``seed`` will be used to define the class
       order. If non-None, ``seed`` parameter will be ignored.
       Defaults to None.
   :param train_transform: The transformation to apply to the training data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default train transformation
       will be used.
   :param test_transform: The transformation to apply to the test data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default test transformation
       will be used.

   :returns: A :class:`NCMultiTaskScenario` instance initialized for the the
       MT scenario using CIFAR10 if the parameter ``return_task_id`` is True,
       a :class:`NCSingleTaskScenario` initialized for the SIT scenario using
       CIFAR10 otherwise.
       


.. function:: SplitCIFAR10(n_steps: int, first_step_with_half_classes: bool = False, return_task_id=False, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, train_transform=_default_cifar10_train_transform, test_transform=_default_cifar10_test_transform)

   Creates a CL scenario using the CIFAR10 dataset.
   If the dataset is not present in the computer the method automatically
   download it and store the data in the data folder.

   :param n_steps: The number of steps in the current scenario.
       The value of this parameter should be a divisor of 10 if
       first_task_with_half_classes if false, a divisor of 5 otherwise.
   :param first_step_with_half_classes: A boolean value that indicates if a
       first pretraining step containing half of the classes should be used.
       If it's True, the first step will use half of the classes (5 for
       cifar100). If this parameter is False no pretraining step will be
       used, and the dataset is simply split into a the number of steps
       defined by the parameter n_steps. Default to False.
   :param return_task_id: if True, for every step the task id is returned and
       the Scenario is Multi Task. This means that the scenario returned
       will be of type ``NCMultiTaskScenario``. If false the task index is
       not returned (default to 0 for every batch) and the returned scenario
       is of type ``NCSingleTaskScenario``.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param fixed_class_order: A list of class IDs used to define the class
       order. If None, value of ``seed`` will be used to define the class
       order. If non-None, ``seed`` parameter will be ignored.
       Defaults to None.
   :param train_transform: The transformation to apply to the training data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default train transformation
       will be used.
   :param test_transform: The transformation to apply to the test data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default test transformation
       will be used.

   :returns: A :class:`NCMultiTaskScenario` instance initialized for the the
       MT scenario using CIFAR10 if the parameter ``return_task_id`` is True,
       a :class:`NCSingleTaskScenario` initialized for the SIT scenario using
       CIFAR10 otherwise.


.. function:: _get_cifar10_dataset(train_transformation, test_transformation)


.. function:: SplitCIFAR100(n_steps: int, first_step_with_half_classes: bool = False, return_task_id=False, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, train_transform=_default_cifar100_train_transform, test_transform=_default_cifar100_test_transform)

   Creates a CL scenario using the CIFAR100 dataset.
   If the dataset is not present in the computer the method automatically
   download it and store the data in the data folder.

   :param n_steps: The number of incremental steps in the current
       scenario. The value of this parameter should be a divisor of 100 if
       first_task_with_half_classes if false, a divisor of 50 otherwise.
   :param first_step_with_half_classes: A boolean value that indicates if a
       first pretraining batch containing half of the classes should be used.
       If it's True, a pretraining step with half of the classes (50 for
       cifar100) is used. If this parameter is False no pretraining task
       will be used, and the dataset is simply split into a the number of
       steps defined by the parameter n_steps. Default to False.
   :param return_task_id: if True, for every step the task id is returned and
       the Scenario is Multi Task. This means that the scenario returned
       will be of type ``NCMultiTaskScenario``. If false the task index is
       not returned (default to 0 for every batch) and the returned scenario
       is of type ``NCSingleTaskScenario``.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param fixed_class_order: A list of class IDs used to define the class
       order. If None, value of ``seed`` will be used to define the class
       order. If non-None, ``seed`` parameter will be ignored.
       Defaults to None.
   :param train_transform: The transformation to apply to the training data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default train transformation
       will be used.
   :param test_transform: The transformation to apply to the test data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default test transformation
       will be used.

   :returns: A :class:`NCMultiTaskScenario` instance initialized for the the
       MT scenario using CIFAR100 if the parameter ``return_task_id`` is True,
       a :class:`NCSingleTaskScenario` initialized for the SIT scenario using
       CIFAR100 otherwise.


.. function:: SplitCIFAR110(n_steps: int, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, train_transform=_default_cifar100_train_transform, test_transform=_default_cifar100_test_transform) -> NCScenario

   Creates a Single Incremental Task (SIT) scenario using the CIFAR100 dataset,
   with a pretrain first batch using CIFAR10.
   If the datasets are not present in the computer the method automatically
   download them and store the data in the data folder.

   :param n_steps: The number of steps for the entire scenario. The first
   step will be the entire cifar10, while the other n-1 steps about
   the incremental training on cifar100.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param fixed_class_order: A list of class IDs used to define the class
       order ONLY for the incremental part on cifar100. The classes must be in
       range 0-99.
       If None, value of ``seed`` will be used to define the class
       order for the incremental batches on cifar100.
       If non-None, ``seed`` parameter will be ignored.
       Defaults to None.
   :param train_transform: The transformation to apply to the training data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default train transformation
       will be used.
   :param test_transform: The transformation to apply to the test data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default test transformation
       will be used.

   :returns: A :class:`NCSingleTaskScenario` instance initialized for the the
       SIT scenario using CIFAR10 as a pretrain batch zero and CIFAR100 for the
       incremental training.  


.. function:: SplitMNIST(n_steps: int, return_task_id=False, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, train_transform=_default_mnist_train_transform, test_transform=_default_mnist_test_transform)

   Creates a CL scenario using the MNIST dataset.
   This helper create the basic split MNIST scenario, where the 10 classes of
   the MNIST dataset are evenly splitted into the given nuber of tasks.
   If the dataset is not present in the computer the method automatically
   download it and store the data in the data folder.

   :param n_steps: The number of incremental steps in the current
       scenario.
       The value of this parameter should be a divisor of 10.
   :param return_task_id: if True, for every step the task id is returned and
       the Scenario is Multi Task. This means that the scenario returned
       will be of type ``NCMultiTaskScenario``. If false the task index is
       not returned (default to 0 for every batch) and the returned scenario
       is of type ``NCSingleTaskScenario``.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param fixed_class_order: A list of class IDs used to define the class
       order. If None, value of ``seed`` will be used to define the class
       order. If non-None, ``seed`` parameter will be ignored.
       Defaults to None.
   :param train_transform: The transformation to apply to the training data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default train transformation
       will be used.
   :param test_transform: The transformation to apply to the test data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default test transformation
       will be used.

   :returns: A :class:`NCMultiTaskScenario` instance initialized for the the
       MT split MNIST scenario if the parameter ``return_task_id`` is True,
       a :class:`NCSingleTaskScenario` initialized for the SIT split MNIST
       scenario otherwise.


.. function:: PermutedMNIST(n_steps: int, seed: Optional[int] = None, train_transform: Any = _default_mnist_train_transform, test_transform: Any = _default_mnist_test_transform) -> NCScenario

   This helper create a permuted MNIST scenario: where a given number of random
   pixel permutations is used to permute the MNIST images in
   ``n_steps`` different manners, creating an equal number of tasks.
   Each task is composed of all the original MNIST 10 classes, but the pixel
   in the images are permuted in different ways in every task.
   If the dataset is not present in the computer the method automatically
   download it and store the data in the data folder.

   :param n_steps: The number of steps (tasks) in the current
       scenario. It indicates how many different permutations of the MNIST
       dataset have to be created.
       The value of this parameter should be a divisor of 10.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param train_transform: The transformation to apply to the training data
       before the random permutation, e.g. a random crop, a normalization or a
       concatenation of different transformations (see torchvision.transform
       documentation for a comprehensive list of possible transformations).
       If no transformation is passed, the default train transformation
       will be used.
   :param test_transform: The transformation to apply to the test data
       before the random permutation, e.g. a random crop, a normalization or a
       concatenation of different transformations (see torchvision.transform
       documentation for a comprehensive list of possible transformations).
       If no transformation is passed, the default test transformation
       will be used.

   :returns: A :class:`NCMultiTaskScenario` instance initialized for the the
       MT permuted MNIST scenario.


.. function:: RotatedMNIST(n_steps: int, seed: Optional[int] = None, rotations_list: Optional[Sequence[int]] = None, train_transform=_default_mnist_train_transform, test_transform=_default_mnist_test_transform) -> NCScenario

   This helper create a rotated MNIST scenario: where a given number of random
   rotations are used to rotate the MNIST images in
   ``n_steps`` different manners, creating an equal number of tasks.
   Each task is composed of all the original MNIST 10 classes, but the images
   are rotated in different ways and using different values in every task.
   If the dataset is not present in the computer the method automatically
   download it and store the data in the data folder.

   :param n_steps: The number of steps (tasks) in the current
       scenario. It indicates how many different rotations of the MNIST
       dataset have to be created.
       The value of this parameter should be a divisor of 10.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param rotations_list: A list of rotations values in degrees (from -180 to
       180) used to define the rotations. The rotation specified in position
       0 of the list will be applieed to the task 0, the rotation specified in
       position 1 will be applyed to task 1 and so on.
       If None, value of ``seed`` will be used to define the rotations.
       If non-None, ``seed`` parameter will be ignored.
       Defaults to None.
   :param train_transform: The transformation to apply to the training data
       after the random rotation, e.g. a random crop, a normalization or a
       concatenation of different transformations (see torchvision.transform
       documentation for a comprehensive list of possible transformations).
       If no transformation is passed, the default train transformation
       will be used.
   :param test_transform: The transformation to apply to the test data
       after the random rotation, e.g. a random crop, a normalization or a
       concatenation of different transformations (see torchvision.transform
       documentation for a comprehensive list of possible transformations).
       If no transformation is passed, the default test transformation
       will be used.

   :returns: A :class:`NCMultiTaskScenario` instance initialized for the the
       MT rotated MNIST scenario.


.. function:: SplitFMNIST(n_steps: int, first_batch_with_half_classes: bool = False, return_task_id=False, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, train_transform=_default_cifar10_train_transform, test_transform=_default_cifar10_test_transform)

   Creates a CL scenario using the Fashion MNIST dataset.
   If the dataset is not present in the computer the method automatically
   download it and store the data in the data folder.

   :param n_steps: The number of steps in the current
       scenario. If the first step is a "pretraining" step and it contains
       half of the classes. The value of this parameter should be a divisor
       of 10 if first_task_with_half_classes if false, a divisor of 5
       otherwise.
   :param first_batch_with_half_classes: A boolean value that indicates if a
       first pretraining batch containing half of the classes should be used.
       If it's True, a pretraining batch with half of the classes (5 for
       cifar100) is used. If this parameter is False no pretraining task
       will be used, and the dataset is simply split into
       a the number of steps defined by the parameter n_steps.
       Default to False.
   :param return_task_id: if True, for every step the task id is returned and
       the Scenario is Multi Task. This means that the scenario returned
       will be of type ``NCMultiTaskScenario``. If false the task index is
       not returned (default to 0 for every batch) and the returned scenario
       is of type ``NCSingleTaskScenario``.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param fixed_class_order: A list of class IDs used to define the class
       order. If None, value of ``seed`` will be used to define the class
       order. If non-None, ``seed`` parameter will be ignored.
       Defaults to None.
   :param train_transform: The transformation to apply to the training data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default train transformation
       will be used.
   :param test_transform: The transformation to apply to the test data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default test transformation
       will be used.

   :returns: A :class:`NCMultiTaskScenario` instance initialized for the the
       MT scenario using CIFAR10 if the parameter ``return_task_id`` is True,
       a :class:`NCSingleTaskScenario` initialized for the SIT scenario using
       CIFAR10 otherwise.


.. function:: SplitImageNet(root, n_steps=10, per_step_classes=None, return_task_id=False, seed=0, fixed_class_order=None, train_transform=_default_train_transform, test_transform=_default_test_transform)

   Creates a CL scenario using the Tiny ImageNet dataset.
   If the dataset is not present in the computer the method automatically
   download it and store the data in the data folder.

   :param root: Base path where Imagenet data are stored.
   :param n_steps: The number of  steps in the current scenario.
   :param per_step_classes: Is not None, a dictionary whose keys are
       (0-indexed) step IDs and their values are the number of classes
       to include in the respective steps. The dictionary doesn't
       have to contain a key for each step! All the remaining steps
       will contain an equal amount of the remaining classes. The
       remaining number of classes must be divisible without remainder
       by the remaining number of steps. For instance,
       if you want to include 50 classes in the first step
       while equally distributing remaining classes across remaining
       steps, just pass the "{0: 50}" dictionary as the
       per_step_classes parameter. Defaults to None.
   :param return_task_id: if True, for every step the task id is returned and
       the Scenario is Multi Task. This means that the scenario returned
       will be of type ``NCMultiTaskScenario``. If false the task index is
       not returned (default to 0 for every batch) and the returned scenario
       is of type ``NCSingleTaskScenario``.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param fixed_class_order: A list of class IDs used to define the class
       order. If None, value of ``seed`` will be used to define the class
       order. If non-None, ``seed`` parameter will be ignored.
       Defaults to None.
   :param train_transform: The transformation to apply to the training data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default train transformation
       will be used.
   :param test_transform: The transformation to apply to the test data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default test transformation
       will be used.

   :returns: A :class:`NCMultiTaskScenario` instance initialized for the the
       MT scenario using CIFAR10 if the parameter ``return_task_id`` is True,
       a :class:`NCSingleTaskScenario` initialized for the SIT scenario using
       CIFAR10 otherwise.
       


.. function:: SplitCUB200(root, n_steps=11, classes_first_batch=100, return_task_id=False, seed=0, fixed_class_order=None, shuffle=False, train_transform=_default_train_transform, test_transform=_default_test_transform)

   Creates a CL scenario using the Tiny ImageNet dataset.
   If the dataset is not present in the computer the method automatically
   download it and store the data in the data folder.

   :param root: Base path where Imagenet data are stored.
   :param n_steps: The number of steps in the current scenario.
   :param classes_first_batch: Number of classes in the first batch.
   Usually this is set to 500. Default to None.
   :param return_task_id: if True, for every step the task id is returned and
       the Scenario is Multi Task. This means that the scenario returned
       will be of type ``NCMultiTaskScenario``. If false the task index is
       not returned (default to 0 for every batch) and the returned scenario
       is of type ``NCSingleTaskScenario``.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param fixed_class_order: A list of class IDs used to define the class
       order. If None, value of ``seed`` will be used to define the class
       order. If non-None, ``seed`` parameter will be ignored.
       Defaults to None.
   :param shuffle: If true, the class order in the incremental steps is
       randomly shuffled. Default to false.
   :param train_transform: The transformation to apply to the training data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default train transformation
       will be used.
   :param test_transform: The transformation to apply to the test data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations).
       If no transformation is passed, the default test transformation
       will be used.

   :returns: A :class:`NCMultiTaskScenario` instance initialized for the the
       MT scenario using CIFAR10 if the parameter ``return_task_id`` is True,
       a :class:`NCSingleTaskScenario` initialized for the SIT scenario using
       CIFAR10 otherwise.
       


.. py:class:: OPENLORIS_DATA(data_folder='data/')

   Bases: :class:`object`

   OpenlORIS downloader.

   Args:
       data_folder (string): folder in which to download openloris dataset.

   .. method:: download_openloris(self)
      :abstractmethod:



.. function:: create_generic_scenario_from_filelists(root: Union[str, Path], train_file_lists: Sequence[Union[str, Path]], test_file_lists: Union[Union[str, Path], Sequence[Union[str, Path]]], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, test_transform=None, test_target_transform=None) -> GenericCLScenario

   Creates a generic scenario given a list of filelists and the respective task
   labels. A separate dataset will be created for each filelist and each of
   those training datasets will be considered a separate training step.
   Contents of the datasets will not be changed, including the targets.

   In its base form, this function accepts a list of filelists for the test
   datsets that must contain the same amount of elements of the training list.
   Those pairs of datasets are then used to create the "past", "cumulative"
   (a.k.a. growing) and "future" test sets. However, in certain Continual
   Learning scenarios only the concept of "complete" test set makes sense. In
   that case, the ``complete_test_set_only`` should be set to True (see the
   parameter description for more info).

   This helper functions is the best shot when loading Caffe-style dataset
   based on filelists.

   :param root: The root path of the dataset.
   :param train_file_lists: A list of filelists describing the
       paths of the training patterns for each step.
   :param test_file_lists: A list of filelists describing the
       paths of the test patterns for each step.
   :param task_labels: A list of task labels. Must contain the same amount of
       elements of the ``train_file_lists`` parameter. For
       Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
       a list of zeros. For Multi Task scenario, this is usually a list of
       ascending task labels (starting from 0).
   :param complete_test_set_only: If True, only the complete test set will
       be returned by the scenario. This means that the ``test_file_lists``
       parameter must be list with a single element (the complete test set).
       Alternatively, can be a plain string or :class:`Path` object.
       Defaults to False, which means that ``train_file_lists`` and
       ``test_file_lists`` must contain the same amount of filelists paths.
   :param train_transform: The transformation to apply to training patterns.
       Defaults to None.
   :param train_target_transform: The transformation to apply to training
       patterns targets. Defaults to None.
   :param test_transform: The transformation to apply to test patterns.
       Defaults to None.
   :param test_target_transform: The transformation to apply to test
       patterns targets. Defaults to None.

   :returns: A :class:`GenericCLScenario` instance.


.. data:: nbatch
   

   

.. data:: fac2dirs
   

   

.. function:: OpenLORIS(root=expanduser('~') + '/.avalanche/data/openloris/', factor='clutter')

   OpenLORIS continual scenario generator

   :param root: Path indicating where to store the dataset and related
       metadata. By default they will be stored in
       avalanche/datasets/openloris/data/.
   :param factor: OpenLORIS main factors, indicating different environmental
       variations. It can be chosen between 'clutter', 'illumination',
       'occlusion', 'pixel', or 'mixture-iros'. The first three factors are
       included in the ICRA 2020 paper and the last factor (mixture-iros) is
       the benchmark setting for IROS 2019 Lifelong robotic vision competition.

   :returns: it returns a :class:`GenericCLScenario` instance that can be
       iterated.


.. data:: factor
   

   

