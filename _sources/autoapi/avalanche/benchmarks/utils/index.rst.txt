:mod:`avalanche.benchmarks.utils`
=================================

.. py:module:: avalanche.benchmarks.utils


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   data_loader/index.rst
   dataset_utils/index.rst
   datasets_from_filelists/index.rst
   torchvision_wrapper/index.rst
   transform_dataset/index.rst
   utils/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.utils.IDataset
   avalanche.benchmarks.utils.IDatasetWithTargets
   avalanche.benchmarks.utils.TransformationDataset
   avalanche.benchmarks.utils.TransformationSubset
   avalanche.benchmarks.utils.TransformationTensorDataset
   avalanche.benchmarks.utils.TransformationConcatDataset
   avalanche.benchmarks.utils.PathsDataset
   avalanche.benchmarks.utils.FilelistDataset



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.utils.tensor_as_list
   avalanche.benchmarks.utils.grouped_and_ordered_indexes
   avalanche.benchmarks.utils.concat_datasets_sequentially
   avalanche.benchmarks.utils.as_transformation_dataset
   avalanche.benchmarks.utils.train_test_transformation_datasets
   avalanche.benchmarks.utils.default_image_loader
   avalanche.benchmarks.utils.default_flist_reader
   avalanche.benchmarks.utils.datasets_from_filelists
   avalanche.benchmarks.utils.datasets_from_paths
   avalanche.benchmarks.utils.ImageFolder
   avalanche.benchmarks.utils.DatasetFolder


.. function:: tensor_as_list(sequence) -> List


.. function:: grouped_and_ordered_indexes(targets: Sequence[int], patterns_indexes: Union[None, Sequence[int]], bucket_classes: bool = True, sort_classes: bool = False, sort_indexes: bool = False) -> Union[List[int], None]

   Given the targets list of a dataset and the patterns to include, returns the
   pattern indexes sorted according to the ``bucket_classes``,
   ``sort_classes`` and ``sort_indexes`` parameters.

   :param targets: The list of pattern targets, as a list.
   :param patterns_indexes: A list of pattern indexes to include in the set.
       If None, all patterns will be included.
   :param bucket_classes: If True, pattern indexes will be returned so that
       patterns will be grouped by class. Defaults to True.
   :param sort_classes: If both ``bucket_classes`` and ``sort_classes`` are
       True, class groups will be sorted by class index. Ignored if
       ``bucket_classes`` is False. Defaults to False.
   :param sort_indexes: If True, patterns indexes will be sorted. When
       bucketing by class, patterns will be sorted inside their buckets.
       Defaults to False.

   :returns: The list of pattern indexes sorted according to the
       ``bucket_classes``, ``sort_classes`` and ``sort_indexes`` parameters or
       None if the patterns_indexes is None and the whole dataset can be taken
       using the existing patterns order.


.. py:class:: IDataset

   Bases: :class:`Protocol[T_co]`

   Protocol definition of a Dataset.

   Note: no __add__ method is defined.

   .. method:: __getitem__(self, index: int) -> Tuple[T_co, int]


   .. method:: __len__(self) -> int



.. py:class:: IDatasetWithTargets

   Bases: :class:`IDataset[T_co]`, :class:`typing.Protocol`

   Protocol definition of a Dataset that has a valid targets field (like the
   Datasets in the torchvision package).

   Note: no __add__ method is defined.

   Create and return a new object.  See help(type) for accurate signature.

   .. attribute:: targets
      :annotation: :Sequence[SupportsInt]

      A sequence of ints or a PyTorch Tensor or a NumPy ndarray describing the
      label of each pattern contained in the dataset.


   .. method:: __getitem__(self, index: int) -> Tuple[T_co, int]


   .. method:: __len__(self) -> int



.. data:: SupportedDataset
   

   

.. py:class:: TransformationDataset(dataset: SupportedDataset[T_co], *, transform: XTransform = None, target_transform: YTransform = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group='train')

   Bases: :class:`DatasetWithTargets[T_co]`, :class:`Generic[T_co]`

   A Dataset that applies transformations before returning patterns/targets.
   Also, this Dataset supports slicing and advanced indexing.

   This dataset can also be used to apply several operations involving
   transformations. For instance, it allows the user to add and replace
   transformations, freeze them so that they can't be changed, etc.

   This dataset also allows the user to keep distinct transformations groups.
   Simply put, a transformation group is a pair of transform+target_transform
   (exactly as in torchvision datasets). This dataset natively supports keeping
   two transformation groups: the first, 'train', contains transformations
   applied to training patterns. Those transformations usually involve some
   kind of data augmentation. The second one is 'test', that will contain
   transformations applied to test patterns. Having both groups can be
   useful when, for instance, in need to test on the training data (as this
   process usually involves removing data augmentation operations). Switching
   between transformations can be easily achieved by using the
   :func:`train` and :func:`eval` method.

   However, consider that arbitrary groups can be used. For more info see
   the constructor and the :func:`with_transforms` method.

   Creates a ``TransformationDataset`` instance.

   :param dataset: The dataset to decorate. Beware that
       TransformationDataset will not overwrite transformations already
       applied by this dataset.
   :param transform: A function/transform that takes the X value of a
       pattern from the original dataset and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       test transformations. This becomes useful when in need to test on
       the training dataset as test transformations usually don't contain
       random augmentations. ``TransformDataset`` natively supports the
       'train' and 'test' groups by calling the ``train()`` and ``eval()``
       methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'test' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the transform group
       to be used. Defaults to 'train'.

   .. attribute:: _dataset
      :annotation: :SupportedDataset[T_co]

      The original dataset.


   .. attribute:: targets
      :annotation: :Sequence[int]

      A sequence of ints describing the label of each pattern contained in the
      dataset.


   .. attribute:: current_transform_group
      

      The name of the transform group currently in use.


   .. attribute:: transform_groups
      :annotation: :Dict[str, Tuple[XTransform, YTransform]]

      A dictionary containing the transform groups. Transform groups are
      used to quickly switch between training and test transformations.
      This becomes useful when in need to test on the training dataset as test
      transformations usually don't contain random augmentations.

      TransformDataset natively supports switching between the 'train' and
      'test' groups by calling the ``train()`` and ``eval()`` methods. When
      using custom groups one can use the ``with_transforms(group_name)``
      method instead.

      May be null, which means that the current transforms will be used to
      handle both 'train' and 'test' groups.


   .. attribute:: transform
      :annotation: :XTransform

      A function/transform that takes in an PIL image and returns a 
      transformed version.


   .. attribute:: target_transform
      :annotation: :YTransform

      A function/transform that takes in the target and transforms it.


   .. attribute:: _frozen_transforms
      :annotation: :Dict[str, Tuple[XTransform, YTransform]]

      A dictionary containing frozen transformations.


   .. method:: __getitem__(self, idx)


   .. method:: __len__(self)


   .. method:: train(self)

      Returns a new dataset with the transformations of a the 'train' group
      loaded.

      The current dataset will not be affected.

      :return: A new dataset with the training transformations loaded.


   .. method:: eval(self)

      Returns a new dataset with the transformations of a the 'test' group
      loaded.

      Test transformations usually don't contain augmentation procedures.
      This function may be useful when in need to test on training data
      (for instance, in order to run a validation pass).

      The current dataset will not be affected.

      :return: A new dataset with the test transformations loaded.


   .. method:: freeze_transforms(self: TTransformationDataset) -> TTransformationDataset

      Returns a new dataset where the current transformations are frozen.

      Frozen transformations will be permanently glued to the original
      dataset so that they can't be changed anymore. This is usually done
      when using transformations to create derived datasets: in this way
      freezing the transformations will ensure that the user won't be able
      to inadvertently change them by directly setting the transformations
      field or by using the other transformations utility methods like
      ``replace_transforms``. Please note that transformations of all groups
      will be frozen. If you want to freeze a specific group, please use
      ``freeze_group_transforms``.

      The current dataset will not be affected.

      :return: A new dataset with the current transformations frozen.


   .. method:: freeze_group_transforms(self: TTransformationDataset, group_name: str) -> TTransformationDataset

      Returns a new dataset where the transformations for a specific group
      are frozen.

      Frozen transformations will be permanently glued to the original
      dataset so that they can't be changed anymore. This is usually done
      when using transformations to create derived datasets: in this way
      freezing the transformations will ensure that the user won't be able
      to inadvertently change them by directly setting the transformations
      field or by using the other transformations utility methods like
      ``replace_transforms``. To freeze transformations of all groups
      please use ``freeze_transforms``.

      The current dataset will not be affected.

      :return: A new dataset with the transformations frozen for the given
          group.


   .. method:: add_transforms(self: TTransformationDataset, transform: Callable[[T_co], Any] = None, target_transform: Callable[[int], int] = None) -> TTransformationDataset

      Returns a new dataset with the given transformations added to
      the existing ones.

      The transformations will be added to the current transformations group.
      Other transformation groups will not be affected.

      The given transformations will be added "at the end" of previous
      transformations of the current transformations group. This means
      that existing transformations will be applied to the patterns first.

      The current dataset will not be affected.

      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :return: A new dataset with the added transformations.


   .. method:: replace_transforms(self: TTransformationDataset, transform: XTransform, target_transform: YTransform) -> TTransformationDataset

      Returns a new dataset with the existing transformations replaced with
      the given ones.

      The given transformations will replace the ones of the current
      transformations group. Other transformation groups will not be affected.

      If this dataset was created with ``chain_transformations`` set to True
      and if the original dataset is an instance of
      :class:`TransformationDataset`, then the transformations of the
      original set will be overwritten as well. This operation will create a
      copy of this dataset.

      The current dataset will not be affected.

      Note that this function will not override frozen transformations. This
      will also not affect transformations found in datasets that are not
      instances of :class:`TransformationDataset`.

      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :return: A new dataset with the new transformations.


   .. method:: with_transforms(self: TTransformationDataset, group_name: str) -> TTransformationDataset

      Returns a new dataset with the transformations of a different group
      loaded.

      The current dataset will not be affected.

      :param group_name: The name of the transformations group to use.
      :return: A new dataset with the new transformations.


   .. method:: add_transforms_group(self: TTransformationDataset, group_name: str, transform: XTransform, target_transform: YTransform) -> TTransformationDataset

      Returns a new dataset with a new transformations group.

      The current dataset will not be affected.

      This method raises an exception if a group with the same name already
      exists.

      :param group_name: The name of the new transformations group.
      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :return: A new dataset with the new transformations.


   .. method:: _fork_dataset(self: TTransformationDataset) -> TTransformationDataset


   .. method:: _freeze_dataset_group(dataset_copy: TTransformationDataset, group_name: str)
      :staticmethod:


   .. method:: _get_single_item(self, idx: int)


   .. method:: _apply_transforms(self, pattern: T_co, label: int)


   .. method:: _check_groups_dict_format(groups_dict)
      :staticmethod:


   .. method:: _initialize_groups_dict(self, transform_groups: Optional[Dict[str, Tuple[XTransform, YTransform]]], dataset: Any, transform: XTransform, target_transform: YTransform) -> Dict[str, Tuple[XTransform, YTransform]]

      A simple helper method that tries to fill the 'train' and 'test'
      groups as those two groups must always exist.

      If no transform_groups are passed to the class constructor, then
      the transform and target_transform parameters are used for both groups.

      If train transformations are set and test transformations are not, then
      train transformations will be used for the test group.

      :param dataset: The original dataset. Will be used to detect existing
          groups.
      :param transform: The transformation passed as a parameter to the
          class constructor.
      :param target_transform: The target transformation passed as a parameter
          to the class constructor.


   .. method:: _initialize_targets_sequence(self, dataset) -> Sequence[int]


   .. method:: _set_original_dataset_transform_group(self, group_name: str) -> None


   .. method:: _freeze_original_dataset(self, group_name: str) -> None


   .. method:: _replace_original_dataset_group(self, transform: XTransform, target_transform: YTransform) -> None


   .. method:: _add_original_dataset_group(self, group_name: str) -> None


   .. method:: _add_groups_from_original_dataset(self, dataset, transform_groups) -> None



.. py:class:: TransformationSubset(dataset: SupportedDataset[T_co], *, indices: Sequence[int] = None, class_mapping: Sequence[int] = None, transform: Callable[[T_co], Any] = None, target_transform: Callable[[int], int] = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group='train')

   Bases: :class:`TransformationDataset[T_co]`

   A Dataset that behaves like a PyTorch :class:`torch.utils.data.Subset`.
   This Dataset also supports transformations, slicing, advanced indexing,
   the targets field and class mapping.

   Creates a ``TransformationSubset`` instance.

   :param dataset: The whole dataset.
   :param indices: Indices in the whole set selected for subset. Can
       be None, which means that the whole dataset will be returned.
   :param class_mapping: A list that, for each possible target (Y) value,
       contains its corresponding remapped value. Can be None.
   :param transform: A function/transform that takes the X value of a
       pattern from the original dataset and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       test transformations. This becomes useful when in need to test on
       the training dataset as test transformations usually don't contain
       random augmentations. ``TransformDataset`` natively supports the
       'train' and 'test' groups by calling the ``train()`` and ``eval()``
       methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'test' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the transform group
       to be used. Defaults to 'train'.


.. py:class:: TransformationTensorDataset(dataset_x: Sequence[T_co], dataset_y: Sequence[SupportsInt], *, transform: Callable[[T_co], Any] = None, target_transform: Callable[[int], int] = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group='train')

   Bases: :class:`TransformationDataset[T_co]`

   A Dataset that wraps existing ndarrays, Tensors, lists... to provide
   basic Dataset functionalities. Very similar to TensorDataset from PyTorch,
   this Dataset also supports transformations, slicing, advanced indexing and
   the targets field.

   Creates a ``TransformationTensorDataset`` instance.

   :param dataset_x: An sequence, Tensor or ndarray representing the X
       values of the patterns.
   :param dataset_y: An sequence, Tensor int or ndarray of integers
       representing the Y values of the patterns.
   :param transform: A function/transform that takes in a single element
       from the ``dataset_x`` sequence and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       test transformations. This becomes useful when in need to test on
       the training dataset as test transformations usually don't contain
       random augmentations. ``TransformDataset`` natively supports the
       'train' and 'test' groups by calling the ``train()`` and ``eval()``
       methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'test' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the transform group
       to be used. Defaults to 'train'.


.. py:class:: TransformationConcatDataset(datasets: Sequence[SupportedDataset[T_co]], *, transform: Callable[[T_co], Any] = None, target_transform: Callable[[int], int] = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group='train')

   Bases: :class:`TransformationDataset[T_co]`

   A Dataset that behaves like a PyTorch
   :class:`torch.utils.data.ConcatDataset`. However, this Dataset also supports
   transformations, slicing, advanced indexing and the targets field.

   This dataset guarantees that the operations involving the transformations
   and transformations groups are consistent across the concatenated dataset
   (if they are subclasses of :class:`TransformationDataset`).

   Creates a ``TransformationConcatDataset`` instance.

   :param datasets: An sequence of datasets.
   :param transform: A function/transform that takes the X value of a
       pattern from the original dataset and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       test transformations. This becomes useful when in need to test on
       the training dataset as test transformations usually don't contain
       random augmentations. ``TransformDataset`` natively supports the
       'train' and 'test' groups by calling the ``train()`` and ``eval()``
       methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'test' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the transform group
       to be used. Defaults to 'train'.

   .. method:: __len__(self) -> int


   .. method:: _get_single_item(self, idx: int)


   .. method:: _fork_dataset(self: TTransformationDataset) -> TTransformationDataset


   .. method:: _initialize_targets_sequence(self, dataset) -> Sequence[int]


   .. method:: _set_original_dataset_transform_group(self, group_name: str) -> None


   .. method:: _freeze_original_dataset(self, group_name: str) -> None


   .. method:: _replace_original_dataset_group(self, transform: XTransform, target_transform: YTransform) -> None


   .. method:: _add_original_dataset_group(self, group_name: str) -> None


   .. method:: _add_groups_from_original_dataset(self, dataset, transform_groups) -> None


   .. method:: _adapt_concat_datasets(self)



.. function:: concat_datasets_sequentially(train_dataset_list: Sequence[IDatasetWithTargets[T_co]], test_dataset_list: Sequence[IDatasetWithTargets[T_co]]) -> Tuple[TransformationConcatDataset[T_co], TransformationConcatDataset[T_co], List[list]]

   Concatenates a list of datasets. This is completely different from
   :class:`ConcatDataset`, in which datasets are merged together without
   other processing. Instead, this function re-maps the datasets class IDs.
   For instance:
   let the dataset[0] contain patterns of 3 different classes,
   let the dataset[1] contain patterns of 2 different classes, then class IDs
   will be mapped as follows:

   dataset[0] class "0" -> new class ID is "0"

   dataset[0] class "1" -> new class ID is "1"

   dataset[0] class "2" -> new class ID is "2"

   dataset[1] class "0" -> new class ID is "3"

   dataset[1] class "1" -> new class ID is "4"

   ... -> ...

   dataset[-1] class "C-1" -> new class ID is "overall_n_classes-1"

   In contrast, using PyTorch ConcatDataset:

   dataset[0] class "0" -> ID is "0"

   dataset[0] class "1" -> ID is "1"

   dataset[0] class "2" -> ID is "2"

   dataset[1] class "0" -> ID is "0"

   dataset[1] class "1" -> ID is "1"

   Note: ``train_dataset_list`` and ``test_dataset_list`` must have the same
   number of datasets.

   :param train_dataset_list: A list of training datasets
   :param test_dataset_list: A list of test datasets

   :returns: A concatenated dataset.


.. function:: as_transformation_dataset(dataset: IDatasetWithTargets[T_co]) -> TransformationDataset[T_co]


.. function:: train_test_transformation_datasets(train_dataset: IDatasetWithTargets[T_co], test_dataset: IDatasetWithTargets[T_co], train_transformation, test_transformation)


.. function:: default_image_loader(path)

   Sets the default image loader for the Pytorch Dataset.

   :param path: relative or absolute path of the file to load.

   :returns: Returns the image as a RGB PIL image.


.. function:: default_flist_reader(flist, root)

   This reader reads a filelist and return a list of paths.

   :param flist: path of the flislist to read. The flist format should be:
       impath label, impath label,  ...(same to caffe's filelist)
   :param root: path to the dataset root. Each file defined in the file list
       will be searched in <root>/<impath>.

   :returns: Returns a list of paths (the examples to be loaded).


.. py:class:: PathsDataset(root, files, transform=None, target_transform=None, loader=default_image_loader)

   Bases: :class:`torch.utils.data.Dataset`

   This class extends the basic Pytorch Dataset class to handle list of paths
   as the main data source.

   Creates a File Dataset from a list of files and labels.

   :param root: root path where the data to load are stored. May be None.
   :param files: list of tuples. Each tuple must contain two elements: the
       full path to the pattern and its class label. Optionally, the tuple
       may contain a third element describing the bounding box to use for
       cropping (top, left, height, width).
   :param transform: eventual transformation to add to the input data (x)
   :param target_transform: eventual transformation to add to the targets
       (y)
   :param loader: loader function to use (for the real data) given path.

   .. method:: __getitem__(self, index)

      Returns next element in the dataset given the current index.

      :param index: index of the data to get.
      :return: loaded item.


   .. method:: __len__(self)

      Returns the total number of elements in the dataset.

      :return: Total number of dataset items.



.. py:class:: FilelistDataset(root, flist, transform=None, target_transform=None, flist_reader=default_flist_reader, loader=default_image_loader)

   Bases: :class:`avalanche.benchmarks.utils.datasets_from_filelists.PathsDataset`

   This class extends the basic Pytorch Dataset class to handle filelists as
   main data source.

           This reader reads a filelist and return a list of paths.

           :param root: root path where the data to load are stored. May be None.
           :param flist: path of the flislist to read. The flist format should be:
               impath label
   impath label
    ...(same to caffe's filelist).
           :param transform: eventual transformation to add to the input data (x).
           :param target_transform: eventual transformation to add to the targets
               (y).
           :param flist_reader: loader function to use (for the filelists) given
               path.
           :param loader: loader function to use (for the real data) given path.
           


.. function:: datasets_from_filelists(root, train_filelists, test_filelists, complete_test_set_only=False, train_transform=None, train_target_transform=None, test_transform=None, test_target_transform=None)

   This reader reads a list of Caffe-style filelists and returns the proper
   Dataset objects.

   A Caffe-style list is just a text file where, for each line, two elements
   are described: the path to the pattern (relative to the root parameter)
   and its class label. Those two elements are separated by a single white
   space.

   This method reads each file list and returns a separate
   dataset for each of them.

   Beware that the parameters must be **list of paths to Caffe-style
   filelists**. If you need to create a dataset given a list of
   **pattern paths**, use `datasets_from_paths` instead.

   :param root: root path where the data to load are stored. May be None.
   :param train_filelists: list of paths to train filelists. The flist format
       should be: impath label\nimpath label\n ...(same to Caffe's filelist).
   :param test_filelists: list of paths to test filelists. It can be also a
       single path when the datasets is the same for each batch.
   :param complete_test_set_only: if True, test_filelists must contain
       the path to a single filelist that will serve as the complete test set.
       Alternatively, test_filelists can be the path (str) to the complete test
       set filelist. If False, train_filelists and test_filelists must contain
       the same amount of filelists paths. Defaults to False.
   :param train_transform: The transformation to apply to training patterns.
       Defaults to None.
   :param train_target_transform: The transformation to apply to training
       patterns targets. Defaults to None.
   :param test_transform: The transformation to apply to test patterns.
       Defaults to None.
   :param test_target_transform: The transformation to apply to test
       patterns targets. Defaults to None.

   :return: list of tuples (train dataset, test dataset) for each train
       filelist in the list.


.. function:: datasets_from_paths(train_list, test_list, complete_test_set_only=False, train_transform=None, train_target_transform=None, test_transform=None, test_target_transform=None)

   This utility takes, for each dataset to generate, a list of tuples each
   containing two elements: the full path to the pattern and its class label.
   Optionally, the tuple may contain a third element describing the bounding
   box to use for cropping.

   This is equivalent to `datasets_from_filelists`, which description
   contains more details on the behaviour of this utility. The two utilities
   differ in which `datasets_from_filelists` accepts paths to Caffe-style
   filelists while this one is able to create the datasets from an in-memory
   list.

   Note: this utility may try to detect (and strip) the common root path of
   all patterns in order to save some RAM memory.

   :param train_list: list of lists. Each list must contain tuples of two
       elements: the full path to the pattern and its class label. Optionally,
       the tuple may contain a third element describing the bounding box to use
       for cropping (top, left, height, width).
   :param test_list: list of lists. Each list must contain tuples of two
       elements: the full path to the pattern and its class label. Optionally,
       the tuple may contain a third element describing the bounding box to use
       for cropping (top, left, height, width). It can be also a single list
       when the test dataset is the same for each step.
   :param complete_test_set_only: if True, test_list must contain a single list
       that will serve as the complete test set. If False, train_list and
       test_list must describe the same amount of datasets. Defaults to False.
   :param train_transform: The transformation to apply to training patterns.
       Defaults to None.
   :param train_target_transform: The transformation to apply to training
       patterns targets. Defaults to None.
   :param test_transform: The transformation to apply to test patterns.
       Defaults to None.
   :param test_target_transform: The transformation to apply to test
       patterns targets. Defaults to None.

   :return: A list of tuples (train dataset, test dataset).


.. function:: ImageFolder(*args, **kwargs)


.. function:: DatasetFolder(*args, **kwargs)


