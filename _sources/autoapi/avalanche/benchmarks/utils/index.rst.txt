:mod:`avalanche.benchmarks.utils`
=================================

.. py:module:: avalanche.benchmarks.utils


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   data_loader/index.rst
   dataset_utils/index.rst
   datasets_from_filelists/index.rst
   torchvision_wrapper/index.rst
   transform_dataset/index.rst
   utils/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.utils.IDataset
   avalanche.benchmarks.utils.IDatasetWithTargets
   avalanche.benchmarks.utils.ITensorDataset
   avalanche.benchmarks.utils.IDatasetWithIntTargets
   avalanche.benchmarks.utils.DatasetWithTargets
   avalanche.benchmarks.utils.LazyClassMapping
   avalanche.benchmarks.utils.LazyConcatTargets
   avalanche.benchmarks.utils.LazyTargetsConversion
   avalanche.benchmarks.utils.SubsetWithTargets
   avalanche.benchmarks.utils.ConcatDatasetWithTargets
   avalanche.benchmarks.utils.SequenceDataset
   avalanche.benchmarks.utils.TensorDatasetWrapper
   avalanche.benchmarks.utils.TransformationDataset
   avalanche.benchmarks.utils.TransformationSubset
   avalanche.benchmarks.utils.TransformationConcatDataset
   avalanche.benchmarks.utils.TransformationTensorDataset
   avalanche.benchmarks.utils.FilelistDataset



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.utils.remove_some_labels
   avalanche.benchmarks.utils.change_some_labels
   avalanche.benchmarks.utils.tensor_as_list
   avalanche.benchmarks.utils._indexes_grouped_by_classes
   avalanche.benchmarks.utils.grouped_and_ordered_indexes
   avalanche.benchmarks.utils.find_list_from_index
   avalanche.benchmarks.utils.manage_advanced_indexing
   avalanche.benchmarks.utils.concat_datasets_sequentially
   avalanche.benchmarks.utils.as_transformation_dataset
   avalanche.benchmarks.utils.train_test_transformation_datasets
   avalanche.benchmarks.utils.default_loader
   avalanche.benchmarks.utils.default_flist_reader
   avalanche.benchmarks.utils.datasets_from_filelists
   avalanche.benchmarks.utils.ImageFolder
   avalanche.benchmarks.utils.DatasetFolder


.. function:: remove_some_labels(dataset, labels_set, scale_labels=False)

   This method simply remove patterns with labels contained in
   the labels_set. 


.. function:: change_some_labels(dataset, labels_set, change_set)

   This method simply change labels contained in
   the labels_set. 


.. function:: tensor_as_list(sequence) -> List


.. function:: _indexes_grouped_by_classes(targets: Sequence[int], patterns_indexes: Union[None, Sequence[int]], sort_indexes: bool = True, sort_classes: bool = True) -> Union[List[int], None]


.. function:: grouped_and_ordered_indexes(targets: Sequence[int], patterns_indexes: Union[None, Sequence[int]], bucket_classes: bool = True, sort_classes: bool = False, sort_indexes: bool = False) -> Union[List[int], None]

   Given the targets list of a dataset and the patterns to include, returns the
   pattern indexes sorted according to the ``bucket_classes``,
   ``sort_classes`` and ``sort_indexes`` parameters.

   :param targets: The list of pattern targets, as a list.
   :param patterns_indexes: A list of pattern indexes to include in the set.
       If None, all patterns will be included.
   :param bucket_classes: If True, pattern indexes will be returned so that
       patterns will be grouped by class. Defaults to True.
   :param sort_classes: If both ``bucket_classes`` and ``sort_classes`` are
       True, class groups will be sorted by class index. Ignored if
       ``bucket_classes`` is False. Defaults to False.
   :param sort_indexes: If True, patterns indexes will be sorted. When
       bucketing by class, patterns will be sorted inside their buckets.
       Defaults to False.

   :returns: The list of pattern indexes sorted according to the
       ``bucket_classes``, ``sort_classes`` and ``sort_indexes`` parameters or
       None if the patterns_indexes is None and the whole dataset can be taken
       using the existing patterns order.


.. py:class:: IDataset

   Bases: :class:`Protocol[T_co]`

   Protocol definition of a Dataset.

   Note: no __add__ method is defined.

   .. method:: __getitem__(self, index: int) -> Tuple[T_co, int]


   .. method:: __len__(self) -> int



.. py:class:: IDatasetWithTargets

   Bases: :class:`IDataset[T_co]`, :class:`typing.Protocol`

   Protocol definition of a Dataset that has a valid targets field (like the
   Datasets in the torchvision package).

   Note: no __add__ method is defined.

   Create and return a new object.  See help(type) for accurate signature.

   .. attribute:: targets
      :annotation: :Sequence[SupportsInt]

      A sequence of ints or a PyTorch Tensor or a NumPy ndarray describing the
      label of each pattern contained in the dataset.


   .. method:: __getitem__(self, index: int) -> Tuple[T_co, int]


   .. method:: __len__(self) -> int



.. py:class:: ITensorDataset

   Bases: :class:`IDataset[T_co]`, :class:`typing.Protocol`

   Protocol definition of a Dataset that has a tensors field (like
   TensorDataset).

   Note: no __add__ method is defined.

   Create and return a new object.  See help(type) for accurate signature.

   .. attribute:: tensors
      :annotation: :Sequence[T_co]

      A sequence of PyTorch Tensors describing the contents of the Dataset.


   .. method:: __getitem__(self, index: int) -> Tuple[T_co, int]


   .. method:: __len__(self) -> int



.. py:class:: IDatasetWithIntTargets

   Bases: :class:`IDatasetWithTargets[T_co]`, :class:`typing.Protocol`

   Protocol definition of a Dataset that has a valid targets field (like the
   Datasets in the torchvision package) where the targets field is a sequence
   of native ints.

   Create and return a new object.  See help(type) for accurate signature.

   .. attribute:: targets
      :annotation: :Sequence[int]

      A sequence of ints describing the label of each pattern contained in the
      dataset.


   .. method:: __getitem__(self, index: int) -> Tuple[T_co, int]


   .. method:: __len__(self) -> int



.. py:class:: DatasetWithTargets

   Bases: :class:`IDatasetWithIntTargets[T_co]`, :class:`torch.utils.data.dataset.Dataset`

   Dataset that has a valid targets field (like the Datasets in the
   torchvision package) where the targets field is a sequence of native ints.

   The actual value of the targets field should be set by the child class.

   .. attribute:: targets
      :annotation: = []

      A sequence of ints describing the label of each pattern contained in the
      dataset.



.. py:class:: LazyClassMapping(targets: Sequence[SupportsInt], indices: Union[Sequence[int], None], mapping: Optional[Sequence[int]] = None)

   Bases: :class:`Sequence[int]`

   This class is used when in need of lazy populating a targets field whose
   elements need to be filtered out (when subsetting, see
   :class:`torch.utils.data.Subset`) and/or transformed (remapped). This will
   allow for a more efficient memory usage as the conversion is done on the fly
   instead of actually allocating a new targets list.

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: __len__(self)


   .. method:: __getitem__(self, item_idx) -> int


   .. method:: __str__(self)

      Return str(self).



.. py:class:: LazyConcatTargets(targets_list: Sequence[Sequence[SupportsInt]])

   Bases: :class:`Sequence[int]`

   Defines a lazy targets concatenation.

   This class is used when in need of lazy populating a targets created
   as the concatenation of the targets field of multiple datasets.
   This will allow for a more efficient memory usage as the concatenation is
   done on the fly instead of actually allocating a new targets list.

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: __len__(self)


   .. method:: __getitem__(self, item_idx) -> int


   .. method:: __str__(self)

      Return str(self).



.. py:class:: LazyTargetsConversion(targets: Sequence[SupportsInt])

   Bases: :class:`Sequence[int]`

   Defines a lazy conversion of targets defined in some other format.

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: __len__(self)


   .. method:: __getitem__(self, item_idx) -> int


   .. method:: __str__(self)

      Return str(self).



.. py:class:: SubsetWithTargets(dataset: IDatasetWithTargets[T_co], indices: Union[Sequence[int], None], class_mapping: Optional[Sequence[int]] = None)

   Bases: :class:`DatasetWithTargets[T_co]`

   A Dataset that behaves like a PyTorch :class:`torch.utils.data.Subset`.
   However, this dataset also supports the targets field and class mapping.

   .. method:: __getitem__(self, idx)


   .. method:: __len__(self) -> int



.. py:class:: ConcatDatasetWithTargets(datasets: Sequence[IDatasetWithTargets[T_co]])

   Bases: :class:`DatasetWithTargets[T_co]`

   A Dataset that behaves like a PyTorch
   :class:`torch.utils.data.ConcatDataset`. However, this dataset also
   supports the targets field.

   .. method:: __getitem__(self, idx)


   .. method:: __len__(self) -> int



.. py:class:: SequenceDataset(dataset_x: Sequence[T_co], dataset_y: Sequence[SupportsInt])

   Bases: :class:`DatasetWithTargets[T_co]`

   A Dataset that wraps existing ndarrays, Tensors, lists... to provide
   basic Dataset functionalities. Very similar to TensorDataset.

   Creates a ``SequenceDataset`` instance.

   :param dataset_x: An sequence, Tensor or ndarray representing the X
       values of the patterns.
   :param dataset_y: An sequence, Tensor int or ndarray of integers
       representing the Y values of the patterns.

   .. method:: __getitem__(self, idx)


   .. method:: __len__(self) -> int



.. py:class:: TensorDatasetWrapper(tensor_dataset: ITensorDataset[T_co])

   Bases: :class:`DatasetWithTargets[T_co]`

   A Dataset that wraps a Tensor Dataset to provide the targets field.

   A Tensor Dataset is any dataset with a "tensors" field. The tensors
   field must be a sequence of Tensor. To provide a valid targets field,
   the "tensors" field must contain at least 2 tensors. The second tensor
   must contain elements that can be converted to int.

   Beware that the second element obtained from the wrapped dataset using
   __getitem__ will always be converted to int, This differs from the
   behaviour of PyTorch TensorDataset. This is required to keep a better
   compatibility with torchvision datasets.

   Creates a ``TensorDatasetWrapper`` instance.

   :param tensor_dataset: An instance of a TensorDataset. See class
       description for more details.

   .. method:: __getitem__(self, idx)


   .. method:: __len__(self) -> int



.. function:: find_list_from_index(pattern_idx: int, list_sizes: Sequence[int], max_size: int)


.. function:: manage_advanced_indexing(idx, single_element_getter, max_length)

   Utility function used to manage the advanced indexing and slicing.

   If more than a pattern is selected, the X and Y values will be merged
   in two separate torch Tensor objects using the stack operation.

   :param idx: Either an in, a slice object or a list (including ndarrays and
       torch Tensors) of indexes.
   :param single_element_getter: A callable used to obtain a single element
       given its int index.
   :param max_length: The maximum sequence length.
   :return: A tuple consisting of two tensors containing the X and Y values
       of the patterns addressed by the idx parameter.


.. data:: SupportedDataset
   

   

.. py:class:: TransformationDataset(dataset: SupportedDataset[T_co], *, transform: XTransform = None, target_transform: YTransform = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group='train')

   Bases: :class:`DatasetWithTargets[T_co]`, :class:`Generic[T_co]`

   A Dataset that applies transformations before returning patterns/targets.
   Also, this Dataset supports slicing and advanced indexing.

   This dataset can also be used to apply several operations involving
   transformations. For instance, it allows the user to add and replace
   transformations, freeze them so that they can't be changed, etc.

   This dataset also allows the user to keep distinct transformations groups.
   Simply put, a transformation group is a pair of transform+target_transform
   (exactly as in torchvision datasets). This dataset natively supports keeping
   two transformation groups: the first, 'train', contains transformations
   applied to training patterns. Those transformations usually involve some
   kind of data augmentation. The second one is 'test', that will contain
   transformations applied to test patterns. Having both groups can be
   useful when, for instance, in need to test on the training data (as this
   process usually involves removing data augmentation operations). Switching
   between transformations can be easily achieved by using the
   :func:`train` and :func:`eval` method.

   However, consider that arbitrary groups can be used. For more info see
   the constructor and the :func:`with_transforms` method.

   Creates a ``TransformationDataset`` instance.

   :param dataset: The dataset to decorate. Beware that
       TransformationDataset will not overwrite transformations already
       applied by this dataset.
   :param transform: A function/transform that takes the X value of a
       pattern from the original dataset and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       test transformations. This becomes useful when in need to test on
       the training dataset as test transformations usually don't contain
       random augmentations. ``TransformDataset`` natively supports the
       'train' and 'test' groups by calling the ``train()`` and ``eval()``
       methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'test' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the transform group
       to be used. Defaults to 'train'.

   .. attribute:: _dataset
      :annotation: :SupportedDataset[T_co]

      The original dataset.


   .. attribute:: targets
      :annotation: :Sequence[int]

      A sequence of ints describing the label of each pattern contained in the
      dataset.


   .. attribute:: current_transform_group
      

      The name of the transform group currently in use.


   .. attribute:: transform_groups
      :annotation: :Dict[str, Tuple[XTransform, YTransform]]

      A dictionary containing the transform groups. Transform groups are
      used to quickly switch between training and test transformations.
      This becomes useful when in need to test on the training dataset as test
      transformations usually don't contain random augmentations.

      TransformDataset natively supports switching between the 'train' and
      'test' groups by calling the ``train()`` and ``eval()`` methods. When
      using custom groups one can use the ``with_transforms(group_name)``
      method instead.

      May be null, which means that the current transforms will be used to
      handle both 'train' and 'test' groups.


   .. attribute:: transform
      :annotation: :XTransform

      A function/transform that takes in an PIL image and returns a 
      transformed version.


   .. attribute:: target_transform
      :annotation: :YTransform

      A function/transform that takes in the target and transforms it.


   .. attribute:: _frozen_transforms
      :annotation: :Dict[str, Tuple[XTransform, YTransform]]

      A dictionary containing frozen transformations.


   .. method:: __getitem__(self, idx)


   .. method:: __len__(self)


   .. method:: train(self)

      Returns a new dataset with the transformations of a the 'train' group
      loaded.

      The current dataset will not be affected.

      :return: A new dataset with the training transformations loaded.


   .. method:: eval(self)

      Returns a new dataset with the transformations of a the 'test' group
      loaded.

      Test transformations usually don't contain augmentation procedures.
      This function may be useful when in need to test on training data
      (for instance, in order to run a validation pass).

      The current dataset will not be affected.

      :return: A new dataset with the test transformations loaded.


   .. method:: freeze_transforms(self: TTransformationDataset) -> TTransformationDataset

      Returns a new dataset where the current transformations are frozen.

      Frozen transformations will be permanently glued to the original
      dataset so that they can't be changed anymore. This is usually done
      when using transformations to create derived datasets: in this way
      freezing the transformations will ensure that the user won't be able
      to inadvertently change them by directly setting the transformations
      field or by using the other transformations utility methods like
      ``replace_transforms``. Please note that transformations of all groups
      will be frozen. If you want to freeze a specific group, please use
      ``freeze_group_transforms``.

      The current dataset will not be affected.

      :return: A new dataset with the current transformations frozen.


   .. method:: freeze_group_transforms(self: TTransformationDataset, group_name: str) -> TTransformationDataset

      Returns a new dataset where the transformations for a specific group
      are frozen.

      Frozen transformations will be permanently glued to the original
      dataset so that they can't be changed anymore. This is usually done
      when using transformations to create derived datasets: in this way
      freezing the transformations will ensure that the user won't be able
      to inadvertently change them by directly setting the transformations
      field or by using the other transformations utility methods like
      ``replace_transforms``. To freeze transformations of all groups
      please use ``freeze_transforms``.

      The current dataset will not be affected.

      :return: A new dataset with the transformations frozen for the given
          group.


   .. method:: add_transforms(self: TTransformationDataset, transform: Callable[[T_co], Any] = None, target_transform: Callable[[int], int] = None) -> TTransformationDataset

      Returns a new dataset with the given transformations added to
      the existing ones.

      The transformations will be added to the current transformations group.
      Other transformation groups will not be affected.

      The given transformations will be added "at the end" of previous
      transformations of the current transformations group. This means
      that existing transformations will be applied to the patterns first.

      The current dataset will not be affected.

      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :return: A new dataset with the added transformations.


   .. method:: replace_transforms(self: TTransformationDataset, transform: XTransform, target_transform: YTransform) -> TTransformationDataset

      Returns a new dataset with the existing transformations replaced with
      the given ones.

      The given transformations will replace the ones of the current
      transformations group. Other transformation groups will not be affected.

      If this dataset was created with ``chain_transformations`` set to True
      and if the original dataset is an instance of
      :class:`TransformationDataset`, then the transformations of the
      original set will be overwritten as well. This operation will create a
      copy of this dataset.

      The current dataset will not be affected.

      Note that this function will not override frozen transformations. This
      will also not affect transformations found in datasets that are not
      instances of :class:`TransformationDataset`.

      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :return: A new dataset with the new transformations.


   .. method:: with_transforms(self: TTransformationDataset, group_name: str) -> TTransformationDataset

      Returns a new dataset with the transformations of a different group
      loaded.

      The current dataset will not be affected.

      :param group_name: The name of the transformations group to use.
      :return: A new dataset with the new transformations.


   .. method:: add_transforms_group(self: TTransformationDataset, group_name: str, transform: XTransform, target_transform: YTransform) -> TTransformationDataset

      Returns a new dataset with a new transformations group.

      The current dataset will not be affected.

      This method raises an exception if a group with the same name already
      exists.

      :param group_name: The name of the new transformations group.
      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :return: A new dataset with the new transformations.


   .. method:: _fork_dataset(self: TTransformationDataset) -> TTransformationDataset


   .. method:: _freeze_dataset_group(dataset_copy: TTransformationDataset, group_name: str)
      :staticmethod:


   .. method:: _get_single_item(self, idx: int)


   .. method:: _apply_transforms(self, pattern: T_co, label: int)


   .. method:: _check_groups_dict_format(groups_dict)
      :staticmethod:


   .. method:: _initialize_groups_dict(self, transform_groups: Optional[Dict[str, Tuple[XTransform, YTransform]]], dataset: Any, transform: XTransform, target_transform: YTransform) -> Dict[str, Tuple[XTransform, YTransform]]

      A simple helper method that tries to fill the 'train' and 'test'
      groups as those two groups must always exist.

      If no transform_groups are passed to the class constructor, then
      the transform and target_transform parameters are used for both groups.

      If train transformations are set and test transformations are not, then
      train transformations will be used for the test group.

      :param dataset: The original dataset. Will be used to detect existing
          groups.
      :param transform: The transformation passed as a parameter to the
          class constructor.
      :param target_transform: The target transformation passed as a parameter
          to the class constructor.


   .. method:: _initialize_targets_sequence(self, dataset) -> Sequence[int]


   .. method:: _set_original_dataset_transform_group(self, group_name: str) -> None


   .. method:: _freeze_original_dataset(self, group_name: str) -> None


   .. method:: _replace_original_dataset_group(self, transform: XTransform, target_transform: YTransform) -> None


   .. method:: _add_original_dataset_group(self, group_name: str) -> None


   .. method:: _add_groups_from_original_dataset(self, dataset, transform_groups) -> None



.. py:class:: TransformationSubset(dataset: SupportedDataset[T_co], *, indices: Sequence[int] = None, class_mapping: Sequence[int] = None, transform: Callable[[T_co], Any] = None, target_transform: Callable[[int], int] = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group='train')

   Bases: :class:`TransformationDataset[T_co]`

   A Dataset that behaves like a PyTorch :class:`torch.utils.data.Subset`.
   This Dataset also supports transformations, slicing, advanced indexing,
   the targets field and class mapping.

   Creates a ``TransformationSubset`` instance.

   :param dataset: The whole dataset.
   :param indices: Indices in the whole set selected for subset. Can
       be None, which means that the whole dataset will be returned.
   :param class_mapping: A list that, for each possible target (Y) value,
       contains its corresponding remapped value. Can be None.
   :param transform: A function/transform that takes the X value of a
       pattern from the original dataset and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       test transformations. This becomes useful when in need to test on
       the training dataset as test transformations usually don't contain
       random augmentations. ``TransformDataset`` natively supports the
       'train' and 'test' groups by calling the ``train()`` and ``eval()``
       methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'test' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the transform group
       to be used. Defaults to 'train'.


.. py:class:: TransformationConcatDataset(datasets: Sequence[SupportedDataset[T_co]], *, transform: Callable[[T_co], Any] = None, target_transform: Callable[[int], int] = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group='train')

   Bases: :class:`TransformationDataset[T_co]`

   A Dataset that behaves like a PyTorch
   :class:`torch.utils.data.ConcatDataset`. However, this Dataset also supports
   transformations, slicing, advanced indexing and the targets field.

   This dataset guarantees that the operations involving the transformations
   and transformations groups are consistent across the concatenated dataset
   (if they are subclasses of :class:`TransformationDataset`).

   Creates a ``TransformationConcatDataset`` instance.

   :param datasets: An sequence of datasets.
   :param transform: A function/transform that takes the X value of a
       pattern from the original dataset and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       test transformations. This becomes useful when in need to test on
       the training dataset as test transformations usually don't contain
       random augmentations. ``TransformDataset`` natively supports the
       'train' and 'test' groups by calling the ``train()`` and ``eval()``
       methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'test' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the transform group
       to be used. Defaults to 'train'.

   .. method:: __len__(self) -> int


   .. method:: _get_single_item(self, idx: int)


   .. method:: _fork_dataset(self: TTransformationDataset) -> TTransformationDataset


   .. method:: _initialize_targets_sequence(self, dataset) -> Sequence[int]


   .. method:: _set_original_dataset_transform_group(self, group_name: str) -> None


   .. method:: _freeze_original_dataset(self, group_name: str) -> None


   .. method:: _replace_original_dataset_group(self, transform: XTransform, target_transform: YTransform) -> None


   .. method:: _add_original_dataset_group(self, group_name: str) -> None


   .. method:: _add_groups_from_original_dataset(self, dataset, transform_groups) -> None


   .. method:: _adapt_concat_datasets(self)



.. py:class:: TransformationTensorDataset(dataset_x: Sequence[T_co], dataset_y: Sequence[SupportsInt], *, transform: Callable[[T_co], Any] = None, target_transform: Callable[[int], int] = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group='train')

   Bases: :class:`TransformationDataset[T_co]`

   A Dataset that wraps existing ndarrays, Tensors, lists... to provide
   basic Dataset functionalities. Very similar to TensorDataset from PyTorch,
   this Dataset also supports transformations, slicing, advanced indexing and
   the targets field.

   Creates a ``TransformationTensorDataset`` instance.

   :param dataset_x: An sequence, Tensor or ndarray representing the X
       values of the patterns.
   :param dataset_y: An sequence, Tensor int or ndarray of integers
       representing the Y values of the patterns.
   :param transform: A function/transform that takes in a single element
       from the ``dataset_x`` sequence and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       test transformations. This becomes useful when in need to test on
       the training dataset as test transformations usually don't contain
       random augmentations. ``TransformDataset`` natively supports the
       'train' and 'test' groups by calling the ``train()`` and ``eval()``
       methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'test' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the transform group
       to be used. Defaults to 'train'.


.. function:: concat_datasets_sequentially(train_dataset_list: Sequence[IDatasetWithTargets[T_co]], test_dataset_list: Sequence[IDatasetWithTargets[T_co]]) -> Tuple[TransformationConcatDataset[T_co], TransformationConcatDataset[T_co], List[list]]

   Concatenates a list of datasets. This is completely different from
   :class:`ConcatDataset`, in which datasets are merged together without
   other processing. Instead, this function re-maps the datasets class IDs.
   For instance:
   let the dataset[0] contain patterns of 3 different classes,
   let the dataset[1] contain patterns of 2 different classes, then class IDs
   will be mapped as follows:

   dataset[0] class "0" -> new class ID is "0"

   dataset[0] class "1" -> new class ID is "1"

   dataset[0] class "2" -> new class ID is "2"

   dataset[1] class "0" -> new class ID is "3"

   dataset[1] class "1" -> new class ID is "4"

   ... -> ...

   dataset[-1] class "C-1" -> new class ID is "overall_n_classes-1"

   In contrast, using PyTorch ConcatDataset:

   dataset[0] class "0" -> ID is "0"

   dataset[0] class "1" -> ID is "1"

   dataset[0] class "2" -> ID is "2"

   dataset[1] class "0" -> ID is "0"

   dataset[1] class "1" -> ID is "1"

   Note: ``train_dataset_list`` and ``test_dataset_list`` must have the same
   number of datasets.

   :param train_dataset_list: A list of training datasets
   :param test_dataset_list: A list of test datasets

   :returns: A concatenated dataset.


.. function:: as_transformation_dataset(dataset: IDatasetWithTargets[T_co]) -> TransformationDataset[T_co]


.. function:: train_test_transformation_datasets(train_dataset: IDatasetWithTargets[T_co], test_dataset: IDatasetWithTargets[T_co], train_transformation, test_transformation)


.. function:: default_loader(path)

   Sets the default image loader for the Pytorch Dataset.

   :param path: relative or absolute path of the file to load.

   :returns: Returns the image as a RGB PIL image.


.. function:: default_flist_reader(flist, root)

   This reader reads a filelist and return a list of paths.

   :param flist: path of the flislist to read. The flist format should be:
       impath label, impath label,  ...(same to caffe's filelist)
   :param root: path to the dataset root. Each file defined in the file list
       will be searched in <root>/<impath>.

   :returns: Returns a list of paths (the examples to be loaded).


.. py:class:: FilelistDataset(root, flist, transform=None, target_transform=None, flist_reader=default_flist_reader, loader=default_loader)

   Bases: :class:`torch.utils.data.Dataset`

   This class extends the basic Pytorch Dataset class to handle filelists as
   main data source.

           This reader reads a filelist and return a list of paths.

           :param root: root path where the data to load are stored.
           :param flist: path of the flislist to read. The flist format should be:
               impath label
   impath label
    ...(same to caffe's filelist)
           :param transform: eventual transformation to add to the input data (x)
           :param target_transform: eventual transformation to add to the targets
               (y)
           :param root: root path where the data to load are stored.
           :param flist_reader: loader function to use (for the filelists) given
               path.
           :param loader: loader function to use (for the real data) given path.
           

   .. method:: __getitem__(self, index)

      Returns next element in the dataset given the current index.

      :param index: index of the data to get.
      :return: loaded item.


   .. method:: __len__(self)

      Returns the total number of elements in the dataset.

      :return: Total number of dataset items.



.. function:: datasets_from_filelists(root, train_filelists, test_filelists, complete_test_set_only=False, train_transform=None, train_target_transform=None, test_transform=None, test_target_transform=None)

   This reader reads a list of Caffe-style filelists and returns the proper
       Dataset objects.

       A Caffe-style list is just a text file where, for each line, two elements
       are described: the path to the pattern (relative to the root parameter)
       and its class label. Those two elements are separated by a single white
       space.

       This method reads each file list and returns a separate
       dataset for each of them.

       :param root: root path where the data to load are stored.
       :param train_filelists: list of paths to train filelists. The flist format
           should be: impath label
   impath label
    ...(same to caffe's filelist)
       :param test_filelists: list of paths to test filelists. It can be also a
           single path when the datasets is the same for each batch.
       :param complete_test_set_only: if True, test_filelists must contain
           the path to a single filelist that will serve as the complete test set.
           Alternatively, test_filelists can be the path (str) to the complete test
           set filelist. If False, train_filelists and test_filelists must contain
           the same amount of filelists paths. Defaults to False.
       :param train_transform: The transformation to apply to training patterns.
           Defaults to None.
       :param train_target_transform: The transformation to apply to training
           patterns targets. Defaults to None.
       :param test_transform: The transformation to apply to test patterns.
           Defaults to None.
       :param test_target_transform: The transformation to apply to test
           patterns targets. Defaults to None.

       :return: list of tuples (train dataset, test dataset) for each train
           filelist in the list.
       


.. function:: ImageFolder(*args, **kwargs)


.. function:: DatasetFolder(*args, **kwargs)


.. data:: mnist
   

   

