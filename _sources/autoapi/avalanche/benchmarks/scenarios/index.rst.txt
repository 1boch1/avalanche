:mod:`avalanche.benchmarks.scenarios`
=====================================

.. py:module:: avalanche.benchmarks.scenarios


Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   new_classes/index.rst
   new_instances/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   generic_cl_scenario/index.rst
   generic_definitions/index.rst
   generic_scenario_creation/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.scenarios.NCGenericScenario
   avalanche.benchmarks.scenarios.NCMultiTaskScenario
   avalanche.benchmarks.scenarios.NCTaskInfo
   avalanche.benchmarks.scenarios.NCSingleTaskScenario
   avalanche.benchmarks.scenarios.NCBatchInfo
   avalanche.benchmarks.scenarios.NIScenario
   avalanche.benchmarks.scenarios.NIBatchInfo
   avalanche.benchmarks.scenarios.DatasetPart
   avalanche.benchmarks.scenarios.DatasetType
   avalanche.benchmarks.scenarios.IStepInfo



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.scenarios.create_nc_single_dataset_sit_scenario
   avalanche.benchmarks.scenarios.create_nc_single_dataset_multi_task_scenario
   avalanche.benchmarks.scenarios.create_nc_multi_dataset_sit_scenario
   avalanche.benchmarks.scenarios.create_nc_multi_dataset_multi_task_scenario
   avalanche.benchmarks.scenarios.make_ni_transformation_subset
   avalanche.benchmarks.scenarios.create_ni_single_dataset_sit_scenario
   avalanche.benchmarks.scenarios.create_ni_multi_dataset_sit_scenario
   avalanche.benchmarks.scenarios.create_multi_dataset_generic_scenario
   avalanche.benchmarks.scenarios.create_generic_scenario_from_filelists
   avalanche.benchmarks.scenarios.create_generic_scenario_from_tensors


.. py:class:: NCGenericScenario(train_dataset: TrainSetWithTargets, test_dataset: TestSetWithTargets, n_batches: int, shuffle: bool = True, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, per_batch_classes: Optional[Dict[int, int]] = None, remap_class_indexes: bool = False, reproducibility_data: Optional[Dict[str, Any]] = None)

   Bases: :class:`Generic[TrainSetWithTargets, TestSetWithTargets]`

   This class defines a "New Classes" scenario. It is used when creating both
   task-oriented and single-incremental-batches (a.k.a. task-free) as
   it doesn't make any difference between them. Once created, an instance
   of this class can be iterated in order to obtain the batches/batch sequence
   under the form of instances of :class:`NCGenericBatchInfo`.

   This class can be used directly. However, we recommend using facilities like
   :func:`.scenario_creation.create_nc_single_dataset_sit_scenario`,
   :func:`.scenario_creation.create_nc_single_dataset_multi_task_scenario`,
   :func:`.scenario_creation.create_nc_multi_dataset_sit_scenario` and
   :func:`.scenario_creation.create_nc_multi_dataset_multi_task_scenario`.

   Creates a NCGenericScenario instance given the training and test
   Datasets and the number of batches.

   By default, the number of classes will be automatically detected by
   looking at the training Dataset targets field. Classes will be
   uniformly distributed across the "n_batches" unless a per_task_classes
   argument is specified.

   The number of classes must be divisible without remainder by the number
   of batches. This also applies when the per_task_classes argument is not
   None.

   :param train_dataset: The training dataset. The dataset must contain a
       "targets" field. For instance, one can safely use the datasets from
       the torchvision package.
   :param test_dataset: The test dataset. The dataset must contain a
       "targets" field. For instance, one can safely use the datasets from
       the torchvision package.
   :param n_batches: The number of batches.
   :param shuffle: If True, the class order will be shuffled. Defaults to
       True.
   :param seed: If shuffle is True and seed is not None, the class order
       will be shuffled according to the seed. When None, the current
       PyTorch random number generator state will be used.
       Defaults to None.
   :param fixed_class_order: If not None, the class order to use (overrides
       the shuffle argument). Very useful for enhancing
       reproducibility. Defaults to None.
   :param per_batch_classes: Is not None, a dictionary whose keys are
       (0-indexed) batch IDs and their values are the number of classes
       to include in the respective batches. The dictionary doesn't
       have to contain a key for each batch! All the remaining batches
       will contain an equal amount of the remaining classes. The
       remaining number of classes must be divisible without remainder
       by the remaining number of batches. For instance,
       if you want to include 50 classes in the first batch
       while equally distributing remaining classes across remaining
       batches, just pass the "{0: 50}" dictionary as the
       per_batch_classes parameter. Defaults to None.
   :param remap_class_indexes: If True, original class IDs will be
       remapped so that they will appear as having an ascending order.
       For instance, if the resulting class order after shuffling
       (or defined by fixed_class_order) is [23, 34, 11, 7, 6, ...] and
       remap_class_indexes is True, then all the patterns belonging to
       class 23 will appear as belonging to class "0", class "34" will
       be mapped to "1", class "11" to "2" and so on. This is very
       useful when drawing confusion matrices and when dealing with
       algorithms with dynamic head expansion. Defaults to False.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options. This is usually a dictionary containing
       data used to reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   .. method:: get_reproducibility_data(self)


   .. method:: classes_in_batch_range(self, batch_start: int, batch_end: Optional[int] = None) -> List[int]

      Gets a list of classes contained int the given batches. The batches are
      defined by range. This means that only the classes in range
      [batch_start, batch_end) will be included.

      :param batch_start: The starting batch ID
      :param batch_end: The final batch ID. Can be None, which means that all
          the remaining batches will be taken.

      :returns: The classes contained in the required batch range.


   .. method:: get_class_split(self, batch_id: int)



.. py:class:: NCMultiTaskScenario(nc_generic_scenario: NCGenericScenario[TrainSetWithTargets, TestSetWithTargets], classes_ids_from_zero_in_each_task: bool = True, reproducibility_data: Optional[Dict[str, Any]] = None)

   Bases: :class:`GenericCLScenario[TrainSetWithTargets, TestSetWithTargets, 'NCTaskInfo']`, :class:`Generic[TrainSetWithTargets, TestSetWithTargets]`

   This class defines a "New Classes" multi task scenario based on a
   :class:`NCGenericScenario` instance. Once created, an instance of this
   class can be iterated in order to obtain the task sequence under
   the form of instances of :class:`NCTaskInfo`.

   Instances of this class can be created using the constructor directly.
   However, we recommend using facilities like:
   :func:`.scenario_creation.create_nc_single_dataset_sit_scenario`,
   :func:`.scenario_creation.create_nc_single_dataset_multi_task_scenario`,
   :func:`.scenario_creation.create_nc_multi_dataset_sit_scenario` and
   :func:`.scenario_creation.create_nc_multi_dataset_multi_task_scenario`.

   This class acts as a wrapper for :class:`NCGenericScenario`, adding the
   task label as the output to training/test set related functions
   (see: :class:`NCTaskInfo`).

   Creates a NC multi task scenario given a :class:`NCGenericScenario`
   instance. That instance will be used as the batches factory.

   :param nc_generic_scenario: The :class:`NCGenericScenario` instance
       used to populate this scenario.
   :param classes_ids_from_zero_in_each_task: If True, class ids will be
       mapped to range [0, n_classes) for each task. Defaults to True.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options. This is usually a dictionary containing
       data used to reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   .. method:: get_reproducibility_data(self) -> Dict[str, Any]

      Gets the data needed to reproduce this experiment.

      This data can be stored using the pickle module or some other mechanism.
      It can then be loaded by passing it as the ``reproducibility_data``
      parameter in the constructor.

      Child classes should get the reproducibility dictionary from super class
      and then merge their custom data before returning it.

      :return: A dictionary containing the data needed to reproduce the
          experiment.


   .. method:: classes_in_task_range(self, task_start: int, task_end: Optional[int] = None) -> List[int]

      Gets a list of classes contained int the given tasks. The tasks are
      defined by range. This means that only the classes in range
      [task_start, task_end) will be included.

      :param task_start: The starting task ID
      :param task_end: The final task ID. Can be None, which means that all
          the remaining tasks will be taken.

      :returns: The classes contained in the required task range.


   .. method:: get_class_split(self, task_id)



.. py:class:: NCTaskInfo(scenario: NCMultiTaskScenario[TrainSetWithTargets, TestSetWithTargets], current_task: int, force_train_transformations: bool = False, force_test_transformations: bool = False, are_transformations_disabled: bool = False)

   Bases: :class:`GenericStepInfo[NCMultiTaskScenario[TrainSetWithTargets, TestSetWithTargets]]`, :class:`Generic[TrainSetWithTargets, TestSetWithTargets]`

   Defines a "New Classes" task. It defines methods to obtain the current,
   previous, cumulative and future training and test sets. It also defines
   fields that can be used to check which classes are in this, previous and
   future batches. Instances of this class are usually created when iterating
   over a :class:`NCMultiTaskScenario` instance.

   It keeps a reference to that :class:`NCMultiTaskScenario`
   instance, which can be used to retrieve additional info about the
   scenario.

   Creates a NCMultiDatasetTaskInfo instance given the root scenario.
   Instances of this class are usually created automatically while
   iterating over an instance of :class:`NCMultiTaskScenario`.

   :param scenario: A reference to the NC scenario
   :param current_task: The task ID
   :param force_train_transformations: If True, train transformations will
       be applied to the test set too. The ``force_test_transformations``
       parameter can't be True at the same time. Defaults to False.
   :param force_test_transformations: If True, test transformations will be
       applied to the training set too. The ``force_train_transformations``
       parameter can't be True at the same time. Defaults to False.
   :param are_transformations_disabled: If True, transformations are
       disabled. That is, patterns and targets will be returned as
       outputted by  the original training and test Datasets. Overrides
       ``force_train_transformations`` and ``force_test_transformations``.
       Defaults to False.

   .. method:: _make_subset(self, is_train: bool, step: int, **kwargs) -> MTSingleSet


   .. method:: _go_to_task(self)



.. py:class:: NCSingleTaskScenario(nc_generic_scenario: NCGenericScenario[TrainSetWithTargets, TestSetWithTargets])

   Bases: :class:`GenericCLScenario[TrainSetWithTargets, TestSetWithTargets, 'NCBatchInfo']`, :class:`Generic[TrainSetWithTargets, TestSetWithTargets]`

   This class defines a "New Classes" Single Incremental Task scenario based
   on a :class:`NCGenericScenario` instance. Once created, an instance of this
   class can be iterated in order to obtain the batch sequence under
   the form of instances of :class:`NCBatchInfo`.

   Instances of this class can be created using the constructor directly.
   However, we recommend using facilities like:
   :func:`.scenario_creation.create_nc_single_dataset_sit_scenario`,
   :func:`.scenario_creation.create_nc_single_dataset_multi_task_scenario`,
   :func:`.scenario_creation.create_nc_multi_dataset_sit_scenario` and
   :func:`.scenario_creation.create_nc_multi_dataset_multi_task_scenario`.

   This class acts as a wrapper for :class:`NCGenericScenario`, adding the
   task label (always "0") as the output to training/test set related functions
   (see: :class:`NCBatchInfo`).

   Creates a NC Single Incremental Task scenario given a
   :class:`NCGenericScenario` instance. That instance will be used as the
   batches factory.

   :param nc_generic_scenario: The :class:`NCGenericScenario` instance
       used to populate this scenario.

   .. method:: get_reproducibility_data(self) -> Dict[str, Any]

      Gets the data needed to reproduce this experiment.

      This data can be stored using the pickle module or some other mechanism.
      It can then be loaded by passing it as the ``reproducibility_data``
      parameter in the constructor.

      Child classes should get the reproducibility dictionary from super class
      and then merge their custom data before returning it.

      :return: A dictionary containing the data needed to reproduce the
          experiment.



.. py:class:: NCBatchInfo(scenario: NCSingleTaskScenario[TrainSetWithTargets, TestSetWithTargets], current_batch: int, force_train_transformations: bool = False, force_test_transformations: bool = False, are_transformations_disabled: bool = False)

   Bases: :class:`GenericStepInfo[NCMultiTaskScenario[TrainSetWithTargets, TestSetWithTargets]]`, :class:`Generic[TrainSetWithTargets, TestSetWithTargets]`

   Defines a "New Classes" batch. It defines methods to obtain the current,
   previous, cumulative and future training and test sets. It also defines
   fields that can be used to check which classes are in this, previous and
   future batches. Instances of this class are usually created when iterating
   over a :class:`NCSingleTaskScenario` instance.

   It keeps a reference to that :class:`NCSingleTaskScenario` instance,
   which can be used to retrieve additional info about the scenario.

   Creates a NCBatchInfo instance given the root scenario. 
   Instances of this class are usually created automatically while 
   iterating over an instance of :class:`NCSingleTaskScenario`.

   :param scenario: A reference to the NC scenario
   :param current_batch: The batch ID
   :param force_train_transformations: If True, train transformations will
       be applied to the test set too. The ``force_test_transformations``
       parameter can't be True at the same time. Defaults to False.
   :param force_test_transformations: If True, test transformations will be
       applied to the training set too. The ``force_train_transformations``
       parameter can't be True at the same time. Defaults to False.
   :param are_transformations_disabled: If True, transformations are
       disabled. That is, patterns and targets will be returned as
       outputted by  the original training and test Datasets. Overrides
       ``force_train_transformations`` and ``force_test_transformations``.
       Defaults to False.

   .. method:: _go_to_batch(self)



.. function:: create_nc_single_dataset_sit_scenario(train_dataset: IDatasetWithTargets, test_dataset: IDatasetWithTargets, n_batches: int, shuffle: bool = True, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, per_batch_classes: Optional[Dict[int, int]] = None, remap_class_ids: bool = False, reproducibility_data: Optional[Dict[str, Any]] = None) -> NCSingleTaskScenario

   Creates a "New Classes - Single Incremental Task" scenario given a couple
   of train and test datasets.

   :param train_dataset: The training dataset.
   :param test_dataset: A list of test dataset.
   :param n_batches: The number of batches.
   :param shuffle: If True, class order will be shuffled.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param fixed_class_order: A list of class IDs used to define the class
       order. If None, values of ``shuffle`` and ``seed`` will be used to
       define the class order. If non-None, ``shuffle`` and ``seed`` parameters
       will be ignored. Defaults to None.
   :param per_batch_classes: Is not None, a dictionary whose keys are
       (0-indexed) batch IDs and their values are the number of classes
       to include in the respective batches. The dictionary doesn't
       have to contain a key for each batch! All the remaining batches
       will contain an equal amount of the remaining classes. The
       remaining number of classes must be divisible without remainder
       by the remaining number of batches. For instance,
       if you want to include 50 classes in the first batch while equally
       distributing remaining classes across remaining batches,
       just pass the "{0: 50}" dictionary as the ``per_batch_classes``
       parameter. Defaults to None.
   :param remap_class_ids: If True, original class IDs will be
       remapped so that they will appear as having an ascending order.
       For instance, if the resulting class order after shuffling
       (or defined by fixed_class_order) is [23, 34, 11, 7, 6, ...] and
       remap_class_indexes is True, then all the patterns belonging to
       class 23 will appear as belonging to class "0", class "34" will
       be mapped to "1", class "11" to "2" and so on. This is very
       useful when drawing confusion matrices and when dealing with
       algorithms with dynamic head expansion. Defaults to False.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options. This is usually a dictionary containing
       data used to reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   :returns: A :class:`NCMultiTaskScenario` instance initialized for the the
       SIT scenario.


.. function:: create_nc_single_dataset_multi_task_scenario(train_dataset: IDatasetWithTargets, test_dataset: IDatasetWithTargets, n_tasks: int, shuffle: bool = True, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, per_task_classes: Optional[Dict[int, int]] = None, classes_ids_from_zero_in_each_task: bool = True, reproducibility_data: Optional[Dict[str, Any]] = None) -> NCMultiTaskScenario

   Creates a "New Classes - Multi Task" scenario given a couple
   of train and test datasets.

   :param train_dataset: The training dataset.
   :param test_dataset: A list of test dataset.
   :param n_tasks: The number of batches.
   :param shuffle: If True, class order will be shuffled.
   :param seed: A valid int used to initialize the random number generator. Can
       be None.
   :param fixed_class_order: A list of class IDs used to define the class
       order. If None, values of shuffle and seed will be used to define the
       class order. If non-None, shuffle and seed parameters will be ignored.
       Defaults to None.
   :param per_task_classes: Is not None, a dictionary whose keys are
       (0-indexed) task IDs and their values are the number of classes
       to include in the respective batches. The dictionary doesn't
       have to contain a key for each task! All the remaining batches
       will contain an equal amount of the remaining classes. The
       remaining number of classes must be divisible without remainder
       by the remaining number of batches. For instance,
       if you want to include 50 classes in the first task while equally
       distributing remaining classes across remaining batches,
       just pass the "{0: 50}" dictionary as the per_task_classes
       parameter. Defaults to None.
   :param classes_ids_from_zero_in_each_task: If True, original class IDs will
       be mapped to range [0, n_classes_in_task) for each task. If False,
       each class will keep its original ID as defined in the input
       datasets. Defaults to True.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options. This is usually a dictionary containing
       data used to reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   :returns: A :class:`NCMultiTaskScenario` instance.


.. function:: create_nc_multi_dataset_sit_scenario(train_dataset_list: Sequence[IDatasetWithTargets], test_dataset_list: Sequence[IDatasetWithTargets], n_batches: int, shuffle: bool = True, seed: Optional[int] = None, per_batch_classes: Optional[Dict[int, int]] = None, one_dataset_per_batch: bool = False, reproducibility_data: Optional[Dict[str, Any]] = None) -> NCSingleTaskScenario

   Creates a "New Classes - Single Incremental Task" scenario given a list of
   datasets and the number of batches. The datasets will be merged together.

   Note: train_dataset_list and test_dataset_list must have the same number of
   datasets.

   :param train_dataset_list: A list of training datasets.
   :param test_dataset_list: A list of test datasets.
   :param n_batches: The number of batches.
   :param shuffle: If True and one_dataset_per_batch is False, class order
       will be shuffled. If True and one_dataset_per_batch is True,
       batch order will be shuffled.
   :param seed: A valid int used to initialize the random number generator. Can
       be None.
   :param per_batch_classes: Is not None, a dictionary whose keys are
       (0-indexed) batch IDs and their values are the number of classes
       to include in the respective batches. The dictionary doesn't
       have to contain a key for each batch! All the remaining batches
       will contain an equal amount of the remaining classes. The
       remaining number of classes must be divisible without remainder
       by the remaining number of batches. Defaults to None. This
       parameter is mutually exclusive with one_dataset_per_batch.
   :param one_dataset_per_batch: If True, each dataset will be treated as a
       batch. Mutually exclusive with the per_task_classes parameter.
       Overrides the n_batches parameter.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options. This is usually a dictionary containing
       data used to reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train
       dataset, test dataset and ``one_dataset_per_batch`` parameter must be
       used. Defaults to None.

   :returns: A :class:`NCMultiTaskScenario` instance initialized for the
       the SIT scenario.


.. function:: create_nc_multi_dataset_multi_task_scenario(train_dataset_list: Sequence[IDatasetWithTargets], test_dataset_list: Sequence[IDatasetWithTargets], shuffle: bool = True, seed: Optional[int] = None, classes_ids_from_zero_in_each_task: bool = True, reproducibility_data: Optional[Dict[str, Any]] = None) -> NCMultiTaskScenario

   Creates a "New Classes - Multi Task" scenario given a list of
   datasets and the number of batches. Each dataset will be treated as a task.
   This means that the overall number of batches will be
   len(train_dataset_list).

   Note: train_dataset_list and test_dataset_list must have the same number of
   datasets.

   :param train_dataset_list: A list of training datasets
   :param test_dataset_list: A list of test datasets
   :param shuffle: If True, task order will be shuffled. Defaults to True.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param classes_ids_from_zero_in_each_task: If True, original class IDs will
       be kept as is, that is, in range [0, n_classes_in_task) for each task.
       If False, each class ID will be remapped so that each class ID will
       appear once across all batches. Defaults to True.
       For instance, if the resulting dataset (task) order after shuffling
       is [dataset2, dataset3, dataset0, dataset1] and
       classes_ids_from_zero_in_each_task is False, then all the classes
       belonging to dataset2 will appear as having IDs in range
       [0, n_classes_in_dataset2) while classes in dataset3 will appear
       as having IDs in range [n_classes_in_dataset2,
       n_classes_in_dataset2+n_classes_in_dataset3) and so on.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options. This is usually a dictionary containing
       data used to reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   :return: A :class:`NCMultiTaskScenario` instance.


.. py:class:: NIScenario(train_dataset: TrainSetWithTargets, test_dataset: TestSetWithTargets, n_batches: int, shuffle: bool = True, seed: Optional[int] = None, balance_batches: bool = False, min_class_patterns_in_batch: int = 0, fixed_batch_assignment: Optional[Sequence[Sequence[int]]] = None, reproducibility_data: Optional[Dict[str, Any]] = None)

   Bases: :class:`GenericCLScenario[TrainSetWithTargets, TestSetWithTargets, 'NIBatchInfo']`, :class:`Generic[TrainSetWithTargets, TestSetWithTargets]`

   This class defines a "New Instance" Single Incremental Task scenario.
   Once created, an instance of this class can be iterated in order to obtain
   the batch sequence under the form of instances of :class:`NIBatchInfo`.

   Instances of this class can be created using the constructor directly.
   However, we recommend using facilities like:
   :func:`.scenario_creation.create_ni_single_dataset_sit_scenario` and
   :func:`.scenario_creation.create_ni_multi_dataset_sit_scenario`.

   Being a Single Incremental Task scenario, the task label will always be "0".
   Also, consider that every method from :class:`NIBatchInfo` used to retrieve
   parts of the test set (past, current, future, cumulative) always return the
   complete test set. That is, they behave as the getter for the complete test
   set. These methods are left for compatibility with the ones found in the
   :class:`avalanche.benchmarks.scenarios.new_classes.NCBatchInfo` scenario.

   Creates a NIScenario instance given the training and test Datasets and
   the number of batches.

   :param train_dataset: The training dataset. The dataset must contain a
       "targets" field. For instance, one can safely use the datasets from
       the torchvision package.
   :param test_dataset: The test dataset. The dataset must contain a
       "targets" field. For instance, one can safely use the datasets from
       the torchvision package.
   :param n_batches: The number of batches.
   :param shuffle: If True, the patterns order will be shuffled. Defaults
       to True.
   :param seed: If shuffle is True and seed is not None, the class order
       will be shuffled according to the seed. When None, the current
       PyTorch random number generator state will be used.
       Defaults to None.
   :param balance_batches: If True, pattern of each class will be equally
       spread across all batches. If False, patterns will be assigned to
       batches in a complete random way. Defaults to False.
   :param min_class_patterns_in_batch: The minimum amount of patterns of
       every class that must be assigned to every batch. Compatible with
       the ``balance_batches`` parameter. An exception will be raised if
       this constraint can't be satisfied. Defaults to 0.
   :param fixed_batch_assignment: If not None, the pattern assignment
       to use. It must be a list with an entry for each batch. Each entry
       is a list that contains the indexes of patterns belonging to that
       batch. Overrides the ``shuffle``, ``balance_batches`` and
       ``min_class_patterns_in_batch`` parameters.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options, including ``fixed_batch_assignment``.
       This is usually a dictionary containing data used to
       reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   .. method:: get_reproducibility_data(self) -> Dict[str, Any]

      Gets the data needed to reproduce this experiment.

      This data can be stored using the pickle module or some other mechanism.
      It can then be loaded by passing it as the ``reproducibility_data``
      parameter in the constructor.

      Child classes should get the reproducibility dictionary from super class
      and then merge their custom data before returning it.

      :return: A dictionary containing the data needed to reproduce the
          experiment.



.. py:class:: NIBatchInfo(scenario: NIScenario[TrainSetWithTargets, TestSetWithTargets], current_batch: int, force_train_transformations: bool = False, force_test_transformations: bool = False, are_transformations_disabled: bool = False)

   Bases: :class:`GenericStepInfo[NIScenario[TrainSetWithTargets, TestSetWithTargets]]`, :class:`Generic[TrainSetWithTargets, TestSetWithTargets]`

   Defines a "New Instances" batch. It defines methods to obtain the current,
   previous, cumulative and future training sets. The returned test
   set is always the complete one (methods used to get previous, cumulative and
   future sets simply return the complete one). It also defines fields that can
   be used to check which classes are in this, previous and
   future batches. Instances of this class are usually created when iterating
   over a :class:`NIScenario` instance.


   It keeps a reference to that :class:`NIScenario` instance, which can be
   used to retrieve additional info about the scenario.

   Creates a NCBatchInfo instance given the root scenario.
   Instances of this class are usually created automatically while
   iterating over an instance of :class:`NCSingleTaskScenario`.

   :param scenario: A reference to the NI scenario
   :param current_batch: Defines the current batch ID.
   :param force_train_transformations: If True, train transformations will
       be applied to the test set too. The ``force_test_transformations``
       parameter can't be True at the same time. Defaults to False.
   :param force_test_transformations: If True, test transformations will be
       applied to the training set too. The ``force_train_transformations``
       parameter can't be True at the same time. Defaults to False.
   :param are_transformations_disabled: If True, transformations are
       disabled. That is, patterns and targets will be returned as
       outputted by  the original training and test Datasets. Overrides
       ``force_train_transformations`` and ``force_test_transformations``.
       Defaults to False.

   .. method:: _go_to_batch(self)



.. function:: make_ni_transformation_subset(dataset: IDatasetWithTargets, transform: Any, target_transform: Any, patterns_indexes: Union[None, Sequence[int]], bucket_classes: bool = False, sort_classes: bool = False, sort_indexes: bool = False) -> TransformationSubset

   Creates a subset given the list of patterns to include.

   :param dataset: The original dataset
   :param transform: The transform function for patterns. Can be None.
   :param target_transform: The transform function for targets. Can be None.
   :param patterns_indexes: A list of indexes of patterns to include.
       If None, all patterns will be included.
   :param bucket_classes: If True, the final Dataset will output patterns by
       grouping them by class. Defaults to True.
   :param sort_classes: If ``bucket_classes`` and ``sort_classes`` are both
       True, the final Dataset will output patterns by grouping them by class
       and the class groups will be ordered by class ID (ascending). Ignored
       if ``bucket_classes`` is False. Defaults to False.
   :param sort_indexes: If True, pattern indexes will be sorted (ascending).
       When grouping by class, patterns will be sorted inside their respective
       class buckets. Defaults to False.

   :returns: A :class:`TransformationSubset` that includes only the required
       patterns, in the order controlled by the ``bucket_classes``,
       ``sort_classes`` and ``sort_indexes`` parameters.


.. function:: create_ni_single_dataset_sit_scenario(train_dataset: IDatasetWithTargets, test_dataset: IDatasetWithTargets, n_batches: int, shuffle: bool = True, seed: Optional[int] = None, balance_batches: bool = False, min_class_patterns_in_batch: int = 0, fixed_batch_assignment: Optional[Sequence[Sequence[int]]] = None, reproducibility_data: Optional[Dict[str, Any]] = None) -> NIScenario

   Creates a "New Instances - Single Incremental Task" scenario given a couple
   of train and test datasets.

   :param train_dataset: The training dataset.
   :param test_dataset: A list of test dataset.
   :param n_batches: The number of batches.
   :param shuffle: If True, patterns order will be shuffled.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param balance_batches: If True, pattern of each class will be equally
       spread across all batches. If False, patterns will be assigned to
       batches in a complete random way. Defaults to False.
   :param min_class_patterns_in_batch: The minimum amount of patterns of
       every class that must be assigned to every batch. Compatible with
       the ``balance_batches`` parameter. An exception will be raised if
       this constraint can't be satisfied. Defaults to 0.
   :param fixed_batch_assignment: If not None, the pattern assignment
       to use. It must be a list with an entry for each batch. Each entry
       is a list that contains the indexes of patterns belonging to that
       batch. Overrides the ``shuffle``, ``balance_batches`` and
       ``min_class_patterns_in_batch`` parameters.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options, including ``fixed_batch_assignment``.
       This is usually a dictionary containing data used to
       reproduce a specific experiment. One can use the scenario's
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   :returns: A :class:`NIScenario` instance.


.. function:: create_ni_multi_dataset_sit_scenario(train_dataset_list: Sequence[IDatasetWithTargets], test_dataset_list: Sequence[IDatasetWithTargets], n_batches: int, shuffle: bool = True, seed: Optional[int] = None, balance_batches: bool = False, min_class_patterns_in_batch: int = 0, reproducibility_data: Optional[Dict[str, Any]] = None) -> NIScenario

   Creates a "New Instances - Single Incremental Task" scenario given a list of
   datasets and the number of batches. The datasets will be merged together.

   Note: train_dataset_list and test_dataset_list must have the same number of
   datasets.

   :param train_dataset_list: A list of training datasets.
   :param test_dataset_list: A list of test datasets.
   :param n_batches: The number of batches.
   :param shuffle: If True, patterns order will be shuffled.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param balance_batches: If True, pattern of each class will be equally
           spread across all batches. If False, patterns will be assigned to
           batches in a complete random way. Defaults to False.
   :param min_class_patterns_in_batch: The minimum amount of patterns of
       every class that must be assigned to every batch. Compatible with
       the ``balance_batches`` parameter. An exception will be raised if
       this constraint can't be satisfied. Defaults to 0.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options, including ``fixed_batch_assignment``.
       This is usually a dictionary containing data used to
       reproduce a specific experiment. One can use the scenario's
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same
       train and test datasets list must be used. Defaults to None.

   :returns: A :class:`NIScenario` instance.


.. py:class:: DatasetPart

   Bases: :class:`enum.Enum`

   An enumeration defining the different dataset parts

   Create and return a new object.  See help(type) for accurate signature.

   .. attribute:: CURRENT
      :annotation: = 1

      

   .. attribute:: CUMULATIVE
      :annotation: = 2

      

   .. attribute:: OLD
      :annotation: = 3

      

   .. attribute:: FUTURE
      :annotation: = 4

      

   .. attribute:: COMPLETE
      :annotation: = 5

      


.. py:class:: DatasetType

   Bases: :class:`enum.Enum`

   An enumeration defining the different dataset types

   Create and return a new object.  See help(type) for accurate signature.

   .. attribute:: TRAIN
      :annotation: = 1

      

   .. attribute:: VALIDATION
      :annotation: = 2

      


.. data:: TrainSetWithTargets
   

   

.. data:: TestSetWithTargets
   

   

.. data:: MTSingleSet
   

   

.. data:: MTMultipleSet
   

   

.. py:class:: IStepInfo

   Bases: :class:`typing.Protocol`

   Definition of a learning step. A learning step contains a set of patterns
   which has become available at a particular time instant. The content and
   size of a Step is defined by the specific benchmark that creates the
   IStepInfo instance.

   For instance, a step of a New Classes scenario will contain all patterns
   belonging to a subset of classes of the original training set. A step of a
   New Instance scenario will contain patterns from previously seen classes.

   Steps of  Single Incremental Task (a.k.a. task-free) scenarios are usually
   called "batches" while in Multi Task scenarios a Step is usually associated
   to a "task". Finally, in a Multi Incremental Task scenario the Step may be
   composed by patterns from different tasks.

   Create and return a new object.  See help(type) for accurate signature.

   .. attribute:: current_step
      :annotation: :int

      

   .. attribute:: n_steps
      :annotation: :int

      

   .. method:: current_training_set(self, bucket_classes=False, sort_classes=False, sort_indexes=False) -> MTSingleSet

      Gets the training set for the current step (batch/task).

      :param bucket_classes: If True, dataset patterns will be grouped by
          class. Defaults to False.
      :param sort_classes: If True (and ``bucket_classes`` is True), class
          groups will be sorted by class ID (ascending). Defaults to False.
      :param sort_indexes: If True patterns will be ordered by their ID
          (ascending). If ``sort_classes`` and ``bucket_classes`` are both
          True, patterns will be sorted inside their groups.
          Defaults to False.

      :returns: The current step training set, as a tuple containing the
          Dataset and the task label. For SIT scenarios, the task label
          will always be 0.


   .. method:: cumulative_training_sets(self, include_current_step: bool = True, bucket_classes=False, sort_classes=False, sort_indexes=False) -> MTMultipleSet

      Gets the list of cumulative training sets.

      :param include_current_step: If True, include the current step
          training set. Defaults to True.
      :param bucket_classes: If True, dataset patterns will be grouped by
          class. Defaults to False.
      :param sort_classes: If True (and ``bucket_classes`` is True), class
          groups will be sorted by class ID (ascending). Defaults to False.
      :param sort_indexes: If True patterns will be ordered by their ID
          (ascending). If ``sort_classes`` and ``bucket_classes`` are both
          True, patterns will be sorted inside their groups.
          Defaults to False.

      :returns: The cumulative training sets, as a list. Each element of the
          list is a tuple containing the Dataset and the task label. For SIT
          scenarios, the task label will always be 0.


   .. method:: complete_training_sets(self, bucket_classes=False, sort_classes=False, sort_indexes=False) -> MTMultipleSet

      Gets the complete list of training sets.

      :param bucket_classes: If True, dataset patterns will be grouped by
          class. Defaults to False.
      :param sort_classes: If True (and ``bucket_classes`` is True), class
          groups will be sorted by class ID (ascending). Defaults to False.
      :param sort_indexes: If True patterns will be ordered by their ID
          (ascending). If ``sort_classes`` and ``bucket_classes`` are both
          True, patterns will be sorted inside their groups.
          Defaults to False.

      :returns: All the training sets, as a list. Each element of the list is
          a tuple containing the Dataset and the task label. For SIT
          scenarios, the task label will always be 0.


   .. method:: future_training_sets(self, bucket_classes=False, sort_classes=False, sort_indexes=False) -> MTMultipleSet

      Gets the "future" training sets. That is, datasets of future steps.

      :param bucket_classes: If True, dataset patterns will be grouped by
          class. Defaults to False.
      :param sort_classes: If True (and ``bucket_classes`` is True), class
          groups will be sorted by class ID (ascending). Defaults to False.
      :param sort_indexes: If True patterns will be ordered by their ID
          (ascending). If ``sort_classes`` and ``bucket_classes`` are both
          True, patterns will be sorted inside their groups.
          Defaults to False.

      :returns: The future training sets, as a list. Each element of the list
          is a tuple containing the Dataset and the task label. For SIT
          scenarios, the task label will always be 0.


   .. method:: step_specific_training_set(self, step_id: int, bucket_classes=False, sort_classes=False, sort_indexes=False) -> MTSingleSet

      Gets the training set of a specific step (batch/task), given its ID.

      :param step_id: The ID of the step.
      :param bucket_classes: If True, dataset patterns will be grouped by
          class. Defaults to False.
      :param sort_classes: If True (and ``bucket_classes`` is True), class
          groups will be sorted by class ID (ascending). Defaults to False.
      :param sort_indexes: If True patterns will be ordered by their ID
          (ascending). If ``sort_classes`` and ``bucket_classes`` are both
          True, patterns will be sorted inside their groups.
          Defaults to False.

      :returns: The required training set, as a tuple containing the Dataset
          and the task label. For SIT scenarios, the task label will always
          be 0.


   .. method:: training_set_part(self, dataset_part: DatasetPart, bucket_classes=False, sort_classes=False, sort_indexes=False) -> MTMultipleSet

      Gets the training subset of a specific part of the scenario.

      :param dataset_part: The part of the scenario.
      :param bucket_classes: If True, dataset patterns will be grouped by
          class. Defaults to False.
      :param sort_classes: If True (and ``bucket_classes`` is True), class
          groups will be sorted by class ID (ascending). Defaults to False.
      :param sort_indexes: If True patterns will be ordered by their ID
          (ascending). If ``sort_classes`` and ``bucket_classes`` are both
          True, patterns will be sorted inside their groups.
          Defaults to False.

      :returns: The training set of the desired part, as a list. Each element
          of the list is a tuple containing the Dataset and the task label.
          For SIT scenarios, the task label will always be 0.


   .. method:: current_test_set(self, bucket_classes=False, sort_classes=False, sort_indexes=False) -> MTSingleSet

      Gets the test set for the current step (batch/task).

      :param bucket_classes: If True, dataset patterns will be grouped by
          class. Defaults to False.
      :param sort_classes: If True (and ``bucket_classes`` is True), class
          groups will be sorted by class ID (ascending). Defaults to False.
      :param sort_indexes: If True patterns will be ordered by their ID
          (ascending). If ``sort_classes`` and ``bucket_classes`` are both
          True, patterns will be sorted inside their groups.
          Defaults to False.

      :returns: The current test set, as a tuple containing the Dataset and
          the task label. For SIT scenarios, the task label will always be 0.


   .. method:: cumulative_test_sets(self, include_current_step: bool = True, bucket_classes=False, sort_classes=False, sort_indexes=False) -> MTMultipleSet

      Gets the list of cumulative test sets (batch/task).

      :param include_current_step: If True, include the current step
          training set. Defaults to True.
      :param bucket_classes: If True, dataset patterns will be grouped by
          class. Defaults to False.
      :param sort_classes: If True (and ``bucket_classes`` is True), class
          groups will be sorted by class ID (ascending). Defaults to False.
      :param sort_indexes: If True patterns will be ordered by their ID
          (ascending). If ``sort_classes`` and ``bucket_classes`` are both
          True, patterns will be sorted inside their groups.
          Defaults to False.

      :returns: The cumulative test sets, as a list. Each element of the
          list is a tuple containing the Dataset and the task label. For SIT
          scenarios, the task label will always be 0.


   .. method:: complete_test_sets(self, bucket_classes=False, sort_classes=False, sort_indexes=False) -> MTMultipleSet

      Gets the complete list of test sets.

      :param bucket_classes: If True, dataset patterns will be grouped by
          class. Defaults to False.
      :param sort_classes: If True (and ``bucket_classes`` is True), class
          groups will be sorted by class ID (ascending). Defaults to False.
      :param sort_indexes: If True patterns will be ordered by their ID
          (ascending). If ``sort_classes`` and ``bucket_classes`` are both
          True, patterns will be sorted inside their groups.
          Defaults to False.

      :returns: All the test sets, as a list. Each element of the list is a
          tuple containing the Dataset and the task label. For SIT scenarios,
          the task label will always be 0.


   .. method:: future_test_sets(self, bucket_classes=False, sort_classes=False, sort_indexes=False) -> MTMultipleSet

      Gets the "future" test sets. That is, datasets of future steps.

      :param bucket_classes: If True, dataset patterns will be grouped by
          class. Defaults to False.
      :param sort_classes: If True (and ``bucket_classes`` is True), class
          groups will be sorted by class ID (ascending). Defaults to False.
      :param sort_indexes: If True patterns will be ordered by their ID
          (ascending). If ``sort_classes`` and ``bucket_classes`` are both
          True, patterns will be sorted inside their groups.
          Defaults to False.

      :returns: The future test sets, as a list. Each element of the list is a
          tuple containing the Dataset and the task label. For SIT scenarios,
          the task label will always be 0.


   .. method:: step_specific_test_set(self, step_id: int, bucket_classes=False, sort_classes=False, sort_indexes=False) -> MTSingleSet

      Gets the test set of a specific step (batch/task), given its ID.

      :param step_id: The ID of the step (batch/task).
      :param bucket_classes: If True, dataset patterns will be grouped by
          class. Defaults to False.
      :param sort_classes: If True (and ``bucket_classes`` is True), class
          groups will be sorted by class ID (ascending). Defaults to False.
      :param sort_indexes: If True patterns will be ordered by their ID
          (ascending). If ``sort_classes`` and ``bucket_classes`` are both
          True, patterns will be sorted inside their groups.
          Defaults to False.

      :returns: The required test set, as a tuple containing the Dataset
          and the task label. For SIT scenarios, the task label will always
          be 0.


   .. method:: test_set_part(self, dataset_part: DatasetPart, bucket_classes=False, sort_classes=False, sort_indexes=False) -> MTMultipleSet

      Gets the test subset of a specific part of the scenario.

      :param dataset_part: The part of the scenario
      :param bucket_classes: If True, dataset patterns will be grouped by
          class. Defaults to False.
      :param sort_classes: If True (and ``bucket_classes`` is True), class
          groups will be sorted by class ID (ascending). Defaults to False.
      :param sort_indexes: If True patterns will be ordered by their ID
          (ascending). If ``sort_classes`` and ``bucket_classes`` are both
          True, patterns will be sorted inside their groups.
          Defaults to False.

      :returns: The test sets of the desired part, as a list. Each element
          of the list is a tuple containing the Dataset and the task label.
          For SIT scenarios, the task label will always be 0.


   .. method:: disable_transformations(self: TStepInfo) -> 'TStepInfo'

      Returns a new step info instance in which transformations are disabled.
      The current instance is not affected. This is useful when there is a
      need to access raw data. Can be used when picking and storing
      rehearsal/replay patterns.

      :returns: A new ``IStepInfo`` in which transformations are disabled.


   .. method:: enable_transformations(self: TStepInfo) -> 'TStepInfo'

      Returns a new step info instance in which transformations are enabled.
      The current instance is not affected. When created the ``IStepInfo``
      instance already has transformations enabled. This method can be used to
      re-enable transformations after a previous call to
      ``disable_transformations()``.

      :returns: A new ``IStepInfo`` in which transformations are enabled.


   .. method:: with_train_transformations(self: TStepInfo) -> 'TStepInfo'

      Returns a new step info instance in which train transformations are
      applied to both training and test sets. The current instance is not
      affected.

      :returns: A new ``IStepInfo`` in which train transformations are applied
          to both training and test sets.


   .. method:: with_test_transformations(self: TStepInfo) -> 'TStepInfo'

      Returns a new step info instance in which test transformations are
      applied to both training and test sets. The current instance is
      not affected. This is useful to get the accuracy on the training set
      without considering the usual training data augmentations.

      :returns: A new ``IStepInfo`` in which test transformations are applied
          to both training and test sets.



.. data:: TStepInfo
   

   

.. function:: create_multi_dataset_generic_scenario(train_dataset_list: Sequence[IDatasetWithTargets], test_dataset_list: Sequence[IDatasetWithTargets], task_labels: Sequence[int], complete_test_set_only: bool = False) -> GenericCLScenario

   Creates a generic scenario given a list of datasets and the respective task
   labels. Each training dataset will be considered as a separate training
   step. Contents of the datasets will not be changed, including the targets.

   When loading the datasets from a set of fixed filelist, consider using
   the :func:`create_generic_scenario_from_filelists` helper method instead.

   In its base form, this function accepts a list of test datsets that must
   contain the same amount of datasets of the training list.
   Those pairs are then used to create the "past", "cumulative"
   (a.k.a. growing) and "future" test sets. However, in certain Continual
   Learning scenarios only the concept of "complete" test set makes sense. In
   that case, the ``complete_test_set_only`` should be set to True (see the
   parameter description for more info).

   Beware that pattern transformations must already be included in the
   datasets (when needed).

   :param train_dataset_list: A list of training datasets.
   :param test_dataset_list: A list of test datasets.
   :param task_labels: A list of task labels. Must contain the same amount of
       elements of the ``train_dataset_list`` parameter. For
       Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
       a list of zeros. For Multi Task scenario, this is usually a list of
       ascending task labels (starting from 0).
   :param complete_test_set_only: If True, only the complete test set will
       be returned by the scenario. This means that the ``test_dataset_list``
       parameter must be list with a single element (the complete test set).
       Defaults to False, which means that ``train_dataset_list`` and
       ``test_dataset_list`` must contain the same amount of datasets.

   :returns: A :class:`GenericCLScenario` instance.


.. function:: create_generic_scenario_from_filelists(root: Union[str, Path], train_file_lists: Sequence[Union[str, Path]], test_file_lists: Union[Union[str, Path], Sequence[Union[str, Path]]], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, test_transform=None, test_target_transform=None) -> GenericCLScenario

   Creates a generic scenario given a list of filelists and the respective task
   labels. A separate dataset will be created for each filelist and each of
   those training datasets will be considered a separate training step.
   Contents of the datasets will not be changed, including the targets.

   In its base form, this function accepts a list of filelists for the test
   datsets that must contain the same amount of elements of the training list.
   Those pairs of datasets are then used to create the "past", "cumulative"
   (a.k.a. growing) and "future" test sets. However, in certain Continual
   Learning scenarios only the concept of "complete" test set makes sense. In
   that case, the ``complete_test_set_only`` should be set to True (see the
   parameter description for more info).

   This helper functions is the best shot when loading Caffe-style dataset
   based on filelists.

   :param root: The root path of the dataset.
   :param train_file_lists: A list of filelists describing the
       paths of the training patterns for each step.
   :param test_file_lists: A list of filelists describing the
       paths of the test patterns for each step.
   :param task_labels: A list of task labels. Must contain the same amount of
       elements of the ``train_file_lists`` parameter. For
       Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
       a list of zeros. For Multi Task scenario, this is usually a list of
       ascending task labels (starting from 0).
   :param complete_test_set_only: If True, only the complete test set will
       be returned by the scenario. This means that the ``test_file_lists``
       parameter must be list with a single element (the complete test set).
       Alternatively, can be a plain string or :class:`Path` object.
       Defaults to False, which means that ``train_file_lists`` and
       ``test_file_lists`` must contain the same amount of filelists paths.
   :param train_transform: The transformation to apply to training patterns.
       Defaults to None.
   :param train_target_transform: The transformation to apply to training
       patterns targets. Defaults to None.
   :param test_transform: The transformation to apply to test patterns.
       Defaults to None.
   :param test_target_transform: The transformation to apply to test
       patterns targets. Defaults to None.

   :returns: A :class:`GenericCLScenario` instance.


.. function:: create_generic_scenario_from_tensors(train_data_x: Sequence[Any], train_data_y: Sequence[Sequence[SupportsInt]], test_data_x: Union[Any, Sequence[Any]], test_data_y: Union[Any, Sequence[Sequence[SupportsInt]]], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, test_transform=None, test_target_transform=None) -> GenericCLScenario

   Creates a generic scenario given lists of Tensors and the respective task
   labels. A separate dataset will be created from each Tensor pair (x + y)
   and each of those training datasets will be considered a separate
   training step. Contents of the datasets will not be changed, including the
   targets. Using this helper function is the lower level way to create a
   Continual Learning scenario. When possible, consider using higher level
   helpers.

   In its base form, the test lists must contain the same amount of elements of
   the training lists. Those pairs of datasets are then used to create the
   "past", "cumulative" (a.k.a. growing) and "future" test sets.
   However, in certain Continual Learning scenarios only the concept of
   "complete" test set makes sense. In that case, the
   ``complete_test_set_only`` should be set to True (see the parameter
   description for more info).

   :param train_data_x: A list of Tensors (one per step) containing the
       patterns of the training sets.
   :param train_data_y: A list of Tensors or int lists containing the
       labels of the patterns of the training sets. Must contain the same
       number of elements of ``train_datasets_x``.
   :param test_data_x: A Tensor or a list of Tensors (one per step) containing
       the patterns of the test sets.
   :param test_data_y: A Tensor or a list of Tensors or int lists containing
       the labels of the patterns of the test sets. Must contain the same
       number of elements of ``test_datasets_x``.
   :param task_labels: A list of task labels. Must contain the same amount of
       elements of the ``train_datasets_x`` parameter. For
       Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
       a list of zeros. For Multi Task scenario, this is usually a list of
       ascending task labels (starting from 0).
   :param complete_test_set_only: If True, only the complete test set will
       be returned by the scenario. This means that the ``test_datasets_x`` and
       ``test_datasets_y`` parameters must be lists with a single element
       (the complete test set). Defaults to False, which means that
       ``train_file_lists`` and ``test_file_lists`` must contain the same
       amount of filelists paths.
   :param train_transform: The transformation to apply to training patterns.
       Defaults to None.
   :param train_target_transform: The transformation to apply to training
       patterns targets. Defaults to None.
   :param test_transform: The transformation to apply to test patterns.
       Defaults to None.
   :param test_target_transform: The transformation to apply to test
       patterns targets. Defaults to None.

   :returns: A :class:`GenericCLScenario` instance.


