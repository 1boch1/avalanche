:mod:`avalanche.benchmarks.scenarios.new_classes.nc_generic_scenario`
=====================================================================

.. py:module:: avalanche.benchmarks.scenarios.new_classes.nc_generic_scenario


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.scenarios.new_classes.nc_generic_scenario.NCGenericScenario



.. py:class:: NCGenericScenario(train_dataset: TrainSetWithTargets, test_dataset: TestSetWithTargets, n_batches: int, shuffle: bool = True, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, per_batch_classes: Optional[Dict[int, int]] = None, remap_class_indexes: bool = False, reproducibility_data: Optional[Dict[str, Any]] = None)

   Bases: :class:`Generic[TrainSetWithTargets, TestSetWithTargets]`

   This class defines a "New Classes" scenario. It is used when creating both
   task-oriented and single-incremental-batches (a.k.a. task-free) as
   it doesn't make any difference between them. Once created, an instance
   of this class can be iterated in order to obtain the batches/batch sequence
   under the form of instances of :class:`NCGenericBatchInfo`.

   This class can be used directly. However, we recommend using facilities like
   :func:`.scenario_creation.create_nc_single_dataset_sit_scenario`,
   :func:`.scenario_creation.create_nc_single_dataset_multi_task_scenario`,
   :func:`.scenario_creation.create_nc_multi_dataset_sit_scenario` and
   :func:`.scenario_creation.create_nc_multi_dataset_multi_task_scenario`.

   Creates a NCGenericScenario instance given the training and test
   Datasets and the number of batches.

   By default, the number of classes will be automatically detected by
   looking at the training Dataset targets field. Classes will be
   uniformly distributed across the "n_batches" unless a per_task_classes
   argument is specified.

   The number of classes must be divisible without remainder by the number
   of batches. This also applies when the per_task_classes argument is not
   None.

   :param train_dataset: The training dataset. The dataset must contain a
       "targets" field. For instance, one can safely use the datasets from
       the torchvision package.
   :param test_dataset: The test dataset. The dataset must contain a
       "targets" field. For instance, one can safely use the datasets from
       the torchvision package.
   :param n_batches: The number of batches.
   :param shuffle: If True, the class order will be shuffled. Defaults to
       True.
   :param seed: If shuffle is True and seed is not None, the class order
       will be shuffled according to the seed. When None, the current
       PyTorch random number generator state will be used.
       Defaults to None.
   :param fixed_class_order: If not None, the class order to use (overrides
       the shuffle argument). Very useful for enhancing
       reproducibility. Defaults to None.
   :param per_batch_classes: Is not None, a dictionary whose keys are
       (0-indexed) batch IDs and their values are the number of classes
       to include in the respective batches. The dictionary doesn't
       have to contain a key for each batch! All the remaining batches
       will contain an equal amount of the remaining classes. The
       remaining number of classes must be divisible without remainder
       by the remaining number of batches. For instance,
       if you want to include 50 classes in the first batch
       while equally distributing remaining classes across remaining
       batches, just pass the "{0: 50}" dictionary as the
       per_batch_classes parameter. Defaults to None.
   :param remap_class_indexes: If True, original class IDs will be
       remapped so that they will appear as having an ascending order.
       For instance, if the resulting class order after shuffling
       (or defined by fixed_class_order) is [23, 34, 11, 7, 6, ...] and
       remap_class_indexes is True, then all the patterns belonging to
       class 23 will appear as belonging to class "0", class "34" will
       be mapped to "1", class "11" to "2" and so on. This is very
       useful when drawing confusion matrices and when dealing with
       algorithms with dynamic head expansion. Defaults to False.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options. This is usually a dictionary containing
       data used to reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   .. method:: get_reproducibility_data(self)


   .. method:: classes_in_batch_range(self, batch_start: int, batch_end: Optional[int] = None) -> List[int]

      Gets a list of classes contained int the given batches. The batches are
      defined by range. This means that only the classes in range
      [batch_start, batch_end) will be included.

      :param batch_start: The starting batch ID
      :param batch_end: The final batch ID. Can be None, which means that all
          the remaining batches will be taken.

      :returns: The classes contained in the required batch range.


   .. method:: get_class_split(self, batch_id: int)



