

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>avalanche.evaluation.metrics &mdash; Avalanche 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/mystyle.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex/" />
    <link rel="search" title="Search" href="../../../../search/" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../" class="icon icon-home"> Avalanche
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Avalanche API:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche</span></code></a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../../benchmarks/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks</span></code></a></li>
<li class="toctree-l4 current"><a class="reference internal" href="../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../evaluation_deprecated/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation_deprecated</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../extras/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.extras</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../training/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../#package-contents">Package Contents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../#avalanche.__version__">__version__</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../">Avalanche</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../" class="icon icon-home"></a> &raquo;</li>
        
      <li><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics</span></code></li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../_sources/autoapi/avalanche/evaluation/metrics/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-avalanche.evaluation.metrics">
<span id="avalanche-evaluation-metrics"></span><h1><a class="reference internal" href="#module-avalanche.evaluation.metrics" title="avalanche.evaluation.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics</span></code></a><a class="headerlink" href="#module-avalanche.evaluation.metrics" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="accuracy/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.accuracy</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="confusion_matrix/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.confusion_matrix</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="forgetting/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.forgetting</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="loss/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.loss</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="mean/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.mean</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="sum/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.sum</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="timing/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.timing</span></code></a></li>
</ul>
</div>
</div>
<div class="section" id="package-contents">
<h2>Package Contents<a class="headerlink" href="#package-contents" title="Permalink to this headline">¶</a></h2>
<div class="section" id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.Accuracy" title="avalanche.evaluation.metrics.Accuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Accuracy</span></code></a></p></td>
<td><p>The accuracy metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MinibatchAccuracy" title="avalanche.evaluation.metrics.MinibatchAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchAccuracy</span></code></a></p></td>
<td><p>The minibatch accuracy metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.EpochAccuracy" title="avalanche.evaluation.metrics.EpochAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochAccuracy</span></code></a></p></td>
<td><p>The average epoch accuracy metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.RunningEpochAccuracy" title="avalanche.evaluation.metrics.RunningEpochAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RunningEpochAccuracy</span></code></a></p></td>
<td><p>The running average accuracy metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.TaskAccuracy" title="avalanche.evaluation.metrics.TaskAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TaskAccuracy</span></code></a></p></td>
<td><p>The task accuracy metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ConfusionMatrix" title="avalanche.evaluation.metrics.ConfusionMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConfusionMatrix</span></code></a></p></td>
<td><p>The confusion matrix metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.TaskConfusionMatrix" title="avalanche.evaluation.metrics.TaskConfusionMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TaskConfusionMatrix</span></code></a></p></td>
<td><p>The Confusion Matrix metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.TaskForgetting" title="avalanche.evaluation.metrics.TaskForgetting"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TaskForgetting</span></code></a></p></td>
<td><p>The TaskForgetting metric, describing the accuracy loss detected for a</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.Loss" title="avalanche.evaluation.metrics.Loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Loss</span></code></a></p></td>
<td><p>The average loss metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MinibatchLoss" title="avalanche.evaluation.metrics.MinibatchLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchLoss</span></code></a></p></td>
<td><p>The minibatch loss metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.EpochLoss" title="avalanche.evaluation.metrics.EpochLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochLoss</span></code></a></p></td>
<td><p>The average epoch loss metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.RunningEpochLoss" title="avalanche.evaluation.metrics.RunningEpochLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RunningEpochLoss</span></code></a></p></td>
<td><p>The running average loss metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.TaskLoss" title="avalanche.evaluation.metrics.TaskLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TaskLoss</span></code></a></p></td>
<td><p>The task loss metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.Mean" title="avalanche.evaluation.metrics.Mean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Mean</span></code></a></p></td>
<td><p>The mean metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.Sum" title="avalanche.evaluation.metrics.Sum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Sum</span></code></a></p></td>
<td><p>The sum metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ElapsedTime" title="avalanche.evaluation.metrics.ElapsedTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ElapsedTime</span></code></a></p></td>
<td><p>The elapsed time metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MinibatchTime" title="avalanche.evaluation.metrics.MinibatchTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchTime</span></code></a></p></td>
<td><p>The minibatch time metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.EpochTime" title="avalanche.evaluation.metrics.EpochTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochTime</span></code></a></p></td>
<td><p>The epoch elapsed time metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.AverageEpochTime" title="avalanche.evaluation.metrics.AverageEpochTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AverageEpochTime</span></code></a></p></td>
<td><p>The average epoch time metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.StepTime" title="avalanche.evaluation.metrics.StepTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StepTime</span></code></a></p></td>
<td><p>The step time metric.</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt id="avalanche.evaluation.metrics.Accuracy">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">Accuracy</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The accuracy metric.</p>
<p>Instances of this metric compute the average accuracy by receiving a pair
of “ground truth” and “prediction” Tensors describing the labels of a
minibatch. Those two tensors can both contain plain labels or
one-hot/logit vectors.</p>
<p>The result is the running accuracy computed as the number of correct
patterns divided by the overall amount of patterns.</p>
<p>The reset method will bring the metric to its initial state. By default
this metric in its initial state will return an accuracy value of 0.</p>
<p>Creates an instance of the accuracy metric.</p>
<p>By default this metric in its initial state will return an accuracy
value of 0. The metric can be updated by using the <cite>update</cite> method
while the running accuracy can be retrieved using the <cite>result</cite> method.</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.Accuracy._mean_accuracy">
<code class="sig-name descname">_mean_accuracy</code><a class="headerlink" href="#avalanche.evaluation.metrics.Accuracy._mean_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>The mean utility that will be used to store the running accuracy.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Accuracy.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">true_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">predicted_y</span><span class="p">:</span> <span class="n">Tensor</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Accuracy.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running accuracy given the true and predicted labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>true_y</strong> – The ground truth. Both labels and one-hot vectors
are supported.</p></li>
<li><p><strong>predicted_y</strong> – The ground truth. Both labels and logit vectors
are supported.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Accuracy.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Accuracy.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the running accuracy.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The running accuracy, as a float value between 0 and 1.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Accuracy.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Accuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">MinibatchAccuracy</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The minibatch accuracy metric.</p>
<p>This metric “logs” the accuracy value after each iteration. Beware that this
metric will not average the accuracy across minibatches!</p>
<p>If a more coarse-grained logging is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.EpochAccuracy" title="avalanche.evaluation.metrics.EpochAccuracy"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochAccuracy</span></code></a> and/or <a class="reference internal" href="#avalanche.evaluation.metrics.TaskAccuracy" title="avalanche.evaluation.metrics.TaskAccuracy"><code class="xref py py-class docutils literal notranslate"><span class="pre">TaskAccuracy</span></code></a> instead.</p>
<p>Creates an instance of the MinibatchAccuracy metric.</p>
<p>The train and test parameters are used to control if this metric should
compute and log values referred to the train phase, test phase or both.
At least one of them must be True!</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy._on_iteration">
<code class="sig-name descname">_on_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy._on_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy._on_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.EpochAccuracy">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">EpochAccuracy</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The average epoch accuracy metric.</p>
<p>The accuracy will be logged after each epoch by computing the accuracy
as the number of correctly predicted patterns divided by the overall
number of patterns encountered in that epoch, which means that having
unbalanced minibatch sizes will not affect the metric.</p>
<p>Creates an instance of the EpochAccuracy metric.</p>
<p>The train and test parameters are used to control if this metric should
compute and log values referred to the train phase, test phase or both.
At least one of them must be True!</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.before_training_epoch">
<code class="sig-name descname">before_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.before_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.before_test_step">
<code class="sig-name descname">before_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.before_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.before_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.after_training_epoch">
<code class="sig-name descname">after_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.after_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">RunningEpochAccuracy</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="accuracy/#avalanche.evaluation.metrics.accuracy.EpochAccuracy" title="avalanche.evaluation.metrics.accuracy.EpochAccuracy"><code class="xref py py-class docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.accuracy.EpochAccuracy</span></code></a></p>
<p>The running average accuracy metric.</p>
<p>This metric behaves like <a class="reference internal" href="#avalanche.evaluation.metrics.EpochAccuracy" title="avalanche.evaluation.metrics.EpochAccuracy"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochAccuracy</span></code></a> but, differently from it,
this metric will log the running accuracy value after each iteration.</p>
<p>Creates an instance of the RunningEpochAccuracy metric.</p>
<p>The train and test parameters are used to control if this metric should
compute and log values referred to the train phase, test phase or both.
At least one of them must be True!</p>
<p>Beware that the test parameter defaults to False because logging
the running test accuracy it’s and uncommon practice.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy.after_training_epoch">
<code class="sig-name descname">after_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy.after_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.TaskAccuracy">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">TaskAccuracy</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[Dict[int,</span> <span class="pre">float]]</span></code></p>
<p>The task accuracy metric.</p>
<p>This is the most common metric used in the evaluation of a Continual
Learning algorithm.</p>
<p>Can be safely used when evaluation task-free scenarios, in which case the
default task label “0” will be used.</p>
<p>The task accuracies will be logged at the end of the test phase. This metric
doesn’t apply to the training phase.</p>
<p>Creates an instance of the TaskAccuracy metric.</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.TaskAccuracy._task_accuracy">
<code class="sig-name descname">_task_accuracy</code><em class="property"> :Dict[int, Accuracy]</em><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy._task_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>A dictionary used to store the accuracy for each task.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskAccuracy.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskAccuracy.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskAccuracy.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">true_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">predicted_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">task_label</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy.update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskAccuracy.before_test">
<code class="sig-name descname">before_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.before_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy.before_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskAccuracy.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskAccuracy.after_test">
<code class="sig-name descname">after_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.after_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy.after_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskAccuracy._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">ConfusionMatrix</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">num_classes</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#ConfusionMatrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[Tensor]</span></code></p>
<p>The confusion matrix metric.</p>
<p>Instances of this metric keep track of the confusion matrix by receiving a
pair of “ground truth” and “prediction” Tensors describing the labels of a
minibatch. Those two tensors can both contain plain labels or
one-hot/logit vectors.</p>
<p>The result is the unnormalized running confusion matrix.</p>
<p>Beware that by default the confusion matrix size will depend on the value of
the maximum label as detected by looking at both the ground truth and
predictions Tensors. When passing one-hot/logit vectors, this
metric will try to infer the number of classes from the vector sizes.
Otherwise, the maximum label value encountered in the truth/prediction
Tensors will be used. It is recommended to set the (initial) number of
classes in the constructor.</p>
<p>The reset method will bring the metric to its initial state. By default
this metric in its initial state will return an empty Tensor.</p>
<p>Creates an instance of the confusion matrix metric.</p>
<p>By default this metric in its initial state will return an empty Tensor.
The metric can be updated by using the <cite>update</cite> method while the running
confusion matrix can be retrieved using the <cite>result</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>num_classes</strong> – The initial number of classes. Defaults to None,
which means that the number of classes will be inferred from
ground truth and prediction Tensors (see class description for more
details).</p>
</dd>
</dl>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix._cm_tensor">
<code class="sig-name descname">_cm_tensor</code><em class="property"> :Optional[Tensor]</em><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix._cm_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>The Tensor where the running confusion matrix is stored.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">true_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">predicted_y</span><span class="p">:</span> <span class="n">Tensor</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#ConfusionMatrix.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running confusion matrix given the true and predicted labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>true_y</strong> – The ground truth. Both labels and one-hot vectors
are supported.</p></li>
<li><p><strong>predicted_y</strong> – The ground truth. Both labels and logit vectors
are supported.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Tensor<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#ConfusionMatrix.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the unnormalized confusion matrix.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The running confusion matrix, as a Tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#ConfusionMatrix.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<p>Calling this method will <em>not</em> reset the default number of classes
optionally defined in the constructor optional parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">TaskConfusionMatrix</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">test</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>int<span class="p">, </span>Mapping<span class="p">[</span>int<span class="p">, </span>int<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="p">:</span> <span class="n">Literal[‘true’, ‘pred’, ‘all’]</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">save_image</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">image_creator</span><span class="p">:</span> <span class="n">Callable<span class="p">[</span><span class="p">[</span>Tensor<span class="p">]</span><span class="p">, </span>Image<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">default_cm_image_creator</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[Tensor]</span></code></p>
<p>The Confusion Matrix metric.</p>
<p>This metric logs the confusion matrix for each task at the end of
each phase. By default this metric computes the matrix on the test phase
(on the test set) only but this behaviour can be changed by passing
<cite>train=True</cite> in the constructor.</p>
<p>The metric will log both a Tensor and PIL Image both representing the
confusion matrices. The Logger will decide which one to use depending on its
internal implementation.</p>
<p>Creates an instance of the Confusion Matrix metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to False.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to True.</p></li>
<li><p><strong>num_classes</strong> – When not None, is used to properly define the
amount of rows/columns in the confusion matrix. When None, the
matrix will have many rows/columns as the maximum value of the
predicted and true pattern labels. Can be either an int, in which
case the same value will be used across all tasks, or a dictionary
defining the amount of classes for each task (key = task label,
value = amount of classes). Defaults to None.</p></li>
<li><p><strong>normalize</strong> – Normalizes confusion matrix over the true (rows),
predicted (columns) conditions or all the population. If None,
confusion matrix will not be normalized. Valid values are: ‘true’,
‘pred’ and ‘all’.</p></li>
<li><p><strong>save_image</strong> – If True, a graphical representation of the confusion
matrix will be logged, too. If False, only the Tensor representation
will be logged. Defaults to True.</p></li>
<li><p><strong>image_creator</strong> – A callable that, given the tensor representation
of the confusion matrix, returns a graphical representation of the
matrix as a PIL Image. Defaults to <cite>default_cm_image_creator</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>int<span class="p">, </span>Tensor<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">true_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">predicted_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">task_label</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.before_training">
<code class="sig-name descname">before_training</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.before_training"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.before_training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.before_test">
<code class="sig-name descname">before_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.before_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.before_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.after_training">
<code class="sig-name descname">after_training</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; ’MetricResult’<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.after_training"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.after_training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.after_test">
<code class="sig-name descname">after_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.after_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.after_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix._class_num_for_task">
<code class="sig-name descname">_class_num_for_task</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">task_label</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>int<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix._class_num_for_task"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix._class_num_for_task" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix._normalize_cm">
<em class="property">static </em><code class="sig-name descname">_normalize_cm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cm</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">normalization</span><span class="p">:</span> <span class="n">Literal[‘true’, ‘pred’, ‘all’]</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix._normalize_cm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix._normalize_cm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.nan_to_num">
<em class="property">static </em><code class="sig-name descname">nan_to_num</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">matrix</span><span class="p">:</span> <span class="n">Tensor</span></em><span class="sig-paren">)</span> &#x2192; Tensor<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.nan_to_num"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.nan_to_num" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.TaskForgetting">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">TaskForgetting</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[Dict[int,</span> <span class="pre">float]]</span></code></p>
<p>The TaskForgetting metric, describing the accuracy loss detected for a
certain task.</p>
<p>This metric, computed separately for each task, is the difference between
the accuracy result obtained after first training on a task and the accuracy
result obtained on the same task at the end of successive steps.</p>
<p>This metric is computed during the test phase only.</p>
<p>Creates an instance of the Catastrophic TaskForgetting metric.</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.TaskForgetting._initial_task_accuracy">
<code class="sig-name descname">_initial_task_accuracy</code><em class="property"> :Dict[int, float]</em><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting._initial_task_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>The initial accuracy of each task.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.TaskForgetting._current_task_accuracy">
<code class="sig-name descname">_current_task_accuracy</code><em class="property"> :Dict[int, Accuracy]</em><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting._current_task_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>The current accuracy of each task.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<p>Beware that this will also reset the initial accuracy of each task!</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting.reset_current_accuracy">
<code class="sig-name descname">reset_current_accuracy</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting.reset_current_accuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting.reset_current_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the current accuracy.</p>
<p>This will preserve the initial accuracy value of each task. To be used
at the beginning of each test step.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">true_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">predicted_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">task_label</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the running accuracy of a task given the ground truth and
predicted labels of a minibatch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>true_y</strong> – The ground truth. Both labels and one-hot vectors
are supported.</p></li>
<li><p><strong>predicted_y</strong> – The ground truth. Both labels and logit vectors
are supported.</p></li>
<li><p><strong>task_label</strong> – The task label.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting.before_test">
<code class="sig-name descname">before_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting.before_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting.before_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting.after_test">
<code class="sig-name descname">after_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting.after_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting.after_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the amount of forgetting for each task.</p>
<p>The forgetting is computed as the accuracy difference between the
initial task accuracy (when first encountered in the training stream)
and the current accuracy. A positive value means that forgetting
occurred. A negative value means that the accuracy on that task
increased.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A dictionary in which keys are task labels and the values are
the forgetting measures (as floats in range [-1, 1]).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">train_task</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.Loss">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">Loss</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#Loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The average loss metric.</p>
<p>Instances of this metric compute the running average loss by receiving a
Tensor describing the loss of a minibatch. This metric then uses that tensor
to computes the average loss per pattern.</p>
<p>The Tensor passed to the <cite>update</cite> method are averaged to obtain a
minibatch average loss. In order to compute the per-pattern running loss,
the users should must pass the number of patterns in that minibatch as the
second parameter of the <cite>update</cite> method. The number of patterns can’t be
usually obtained by analyzing the shape of the loss Tensor, which usually
consists of a single float value.</p>
<p>The result is the running loss computed as the accumulated average loss.</p>
<p>The reset method will bring the metric to its initial state. By default
this metric in its initial state will return an accuracy value of 0.</p>
<p>Creates an instance of the loss metric.</p>
<p>By default this metric in its initial state will return a loss
value of 0. The metric can be updated by using the <cite>update</cite> method
while the running loss can be retrieved using the <cite>result</cite> method.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.Loss.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">loss</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">patterns</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#Loss.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Loss.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running loss given the loss Tensor and the minibatch size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> – The loss Tensor. Different reduction types don’t affect
the result.</p></li>
<li><p><strong>patterns</strong> – The number of patterns in the minibatch.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Loss.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#Loss.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Loss.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the running average loss per pattern.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The running loss, as a float.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Loss.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#Loss.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Loss.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MinibatchLoss">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">MinibatchLoss</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The minibatch loss metric.</p>
<p>The logged loss value is the per-pattern loss obtained by averaging the loss
of patterns contained in the minibatch.</p>
<p>This metric “logs” the loss value after each iteration. Beware that this
metric will not average the loss across minibatches!</p>
<p>If a more coarse-grained logging is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.EpochLoss" title="avalanche.evaluation.metrics.EpochLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochLoss</span></code></a> and/or <a class="reference internal" href="#avalanche.evaluation.metrics.TaskLoss" title="avalanche.evaluation.metrics.TaskLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">TaskLoss</span></code></a> instead.</p>
<p>Creates an instance of the MinibatchLoss metric.</p>
<p>The train and test parameters are used to control if this metric should
compute and log values referred to the train phase, test phase or both.
At least one of them must be True!</p>
<p>Beware that the test parameter defaults to False because logging
the test minibatch loss it’s and uncommon practice.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss._on_iteration">
<code class="sig-name descname">_on_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss._on_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss._on_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.EpochLoss">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">EpochLoss</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The average epoch loss metric.</p>
<p>The logged loss value is the per-pattern loss obtained by averaging the loss
of all patterns encountered in that epoch, which means that having
unbalanced minibatch sizes will not affect the metric.</p>
<p>Creates an instance of the EpochLoss metric.</p>
<p>The train and test parameters are used to control if this metric should
compute and log values referred to the train phase, test phase or both.
At least one of them must be True!</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.before_training_epoch">
<code class="sig-name descname">before_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.before_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.before_test_step">
<code class="sig-name descname">before_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.before_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.before_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.after_training_epoch">
<code class="sig-name descname">after_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.after_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">RunningEpochLoss</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="loss/#avalanche.evaluation.metrics.loss.EpochLoss" title="avalanche.evaluation.metrics.loss.EpochLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.loss.EpochLoss</span></code></a></p>
<p>The running average loss metric.</p>
<p>This metric behaves like <a class="reference internal" href="#avalanche.evaluation.metrics.EpochLoss" title="avalanche.evaluation.metrics.EpochLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochLoss</span></code></a> but, differently from it,
this metric will log the running loss value after each iteration.</p>
<p>Creates an instance of the RunningEpochLoss metric.</p>
<p>The train and test parameters are used to control if this metric should
compute and log values referred to the train phase, test phase or both.
At least one of them must be True!</p>
<p>Beware that the test parameter defaults to False because logging
the running test accuracy it’s and uncommon practice.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss.after_training_epoch">
<code class="sig-name descname">after_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss.after_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.TaskLoss">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">TaskLoss</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[Dict[int,</span> <span class="pre">float]]</span></code></p>
<p>The task loss metric.</p>
<p>The logged loss value is the per-pattern loss obtained by averaging the loss
of all test patterns of a task. This is a common metric used in the
evaluation of a Continual Learning algorithm.</p>
<p>Can be safely used when evaluation task-free scenarios, in which case the
default task label “0” will be used.</p>
<p>The task losses will be logged at the end of the test phase. This metric
doesn’t apply to the training phase.</p>
<p>Creates an instance of the TaskLoss metric.</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.TaskLoss._task_loss">
<code class="sig-name descname">_task_loss</code><em class="property"> :Dict[int, Loss]</em><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss._task_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>A dictionary used to store the loss for each task.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskLoss.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskLoss.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskLoss.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">loss</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">patterns</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">task_label</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss.update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskLoss.before_test">
<code class="sig-name descname">before_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss.before_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss.before_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskLoss.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskLoss.after_test">
<code class="sig-name descname">after_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss.after_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss.after_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskLoss._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.Mean">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">Mean</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Mean"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The mean metric.</p>
<p>This utility metric is a general purpose metric that can be used to keep
track of the mean of a sequence of values.</p>
<p>Creates an instance of the mean metric.</p>
<p>This metric in its initial state will return a mean value of 0.
The metric can be updated by using the <cite>update</cite> method while the mean
can be retrieved using the <cite>result</cite> method.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.Mean.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">value</span><span class="p">:</span> <span class="n">SupportsFloat</span></em>, <em class="sig-param"><span class="n">weight</span><span class="p">:</span> <span class="n">SupportsFloat</span> <span class="o">=</span> <span class="default_value">1.0</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Mean.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Mean.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running mean given the value.</p>
<p>The value can be weighted with a custom value, defined by the <cite>weight</cite>
parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> – The value to be used to update the mean.</p></li>
<li><p><strong>weight</strong> – The weight of the value. Defaults to 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Mean.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Mean.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Mean.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the mean.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The mean, as a float.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Mean.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Mean.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Mean.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.Sum">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">Sum</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/sum/#Sum"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Sum" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The sum metric.</p>
<p>This utility metric is a general purpose metric that can be used to keep
track of the sum of a sequence of values.</p>
<p>Beware that this metric only supports summing numbers and the result is
always a float value, even when <cite>update</cite> is called by passing <a href="#id1"><span class="problematic" id="id2">`</span></a>int`s only.</p>
<p>Creates an instance of the sum metric.</p>
<p>This metric in its initial state will return a sum value of 0.
The metric can be updated by using the <cite>update</cite> method while the sum
can be retrieved using the <cite>result</cite> method.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.Sum.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">value</span><span class="p">:</span> <span class="n">SupportsFloat</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/sum/#Sum.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Sum.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running sum given the value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>value</strong> – The value to be used to update the sum.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Sum.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/sum/#Sum.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Sum.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the sum.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The sum, as a float.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Sum.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/sum/#Sum.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Sum.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ElapsedTime">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">ElapsedTime</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ElapsedTime"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ElapsedTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The elapsed time metric.</p>
<p>Instances of this metric keep track of the time elapsed between calls to the
<cite>update</cite> method. The starting time is set when the <cite>update</cite> method is called
for the first time. That is, the starting time is <em>not</em> taken at the time
the constructor is invoked.</p>
<p>Calling the <cite>update</cite> method more than twice will update the metric to the
elapsed time between the first and the last call to <cite>update</cite>.</p>
<p>The result, obtained using the <cite>result</cite> method, is the time, in seconds,
computed as stated above.</p>
<p>The <cite>reset</cite> method will set the metric to its initial state, thus resetting
the initial time. This metric in its initial state (or if the <cite>update</cite>
method was invoked only once) will return an elapsed time of 0.</p>
<p>Creates an instance of the accuracy metric.</p>
<p>This metric in its initial state (or if the <cite>update</cite> method was invoked
only once) will return an elapsed time of 0. The metric can be updated
by using the <cite>update</cite> method while the running accuracy can be retrieved
using the <cite>result</cite> method.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.ElapsedTime.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ElapsedTime.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ElapsedTime.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the elapsed time.</p>
<p>For more info on how to set the initial time see the class description.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ElapsedTime.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ElapsedTime.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ElapsedTime.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the elapsed time.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The elapsed time, in seconds, as a float value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ElapsedTime.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ElapsedTime.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ElapsedTime.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric, including the initial time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MinibatchTime">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">MinibatchTime</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The minibatch time metric.</p>
<p>This metric “logs” the elapsed time for each iteration. Beware that this
metric will not average the time across minibatches!</p>
<p>If a more coarse-grained logging is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.EpochTime" title="avalanche.evaluation.metrics.EpochTime"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochTime</span></code></a>, <a class="reference internal" href="#avalanche.evaluation.metrics.AverageEpochTime" title="avalanche.evaluation.metrics.AverageEpochTime"><code class="xref py py-class docutils literal notranslate"><span class="pre">AverageEpochTime</span></code></a> or
<a class="reference internal" href="#avalanche.evaluation.metrics.StepTime" title="avalanche.evaluation.metrics.StepTime"><code class="xref py py-class docutils literal notranslate"><span class="pre">StepTime</span></code></a> instead.</p>
<p>Creates an instance of the minibatch time metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.before_training_iteration">
<code class="sig-name descname">before_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.before_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.before_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.before_test_iteration">
<code class="sig-name descname">before_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.before_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.before_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime._on_iteration">
<code class="sig-name descname">_on_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime._on_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime._on_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.EpochTime">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">EpochTime</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The epoch elapsed time metric.</p>
<p>The elapsed time will be logged after each epoch. Beware that this
metric will not average the time across epochs!</p>
<p>If logging the average average across epochs is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.AverageEpochTime" title="avalanche.evaluation.metrics.AverageEpochTime"><code class="xref py py-class docutils literal notranslate"><span class="pre">AverageEpochTime</span></code></a> instead.</p>
<p>Creates an instance of the epoch time metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.before_training_epoch">
<code class="sig-name descname">before_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.before_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.before_test_step">
<code class="sig-name descname">before_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.before_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.before_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.after_training_epoch">
<code class="sig-name descname">after_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.after_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.AverageEpochTime">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">AverageEpochTime</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The average epoch time metric.</p>
<p>The average elapsed time will be logged at the end of the step.</p>
<p>Beware that this metric will average the time across epochs! If logging the
epoch-specific time is needed, consider using <a class="reference internal" href="#avalanche.evaluation.metrics.EpochTime" title="avalanche.evaluation.metrics.EpochTime"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochTime</span></code></a> instead.</p>
<p>Creates an instance of the average epoch time metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochTime.before_training_epoch">
<code class="sig-name descname">before_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime.before_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochTime.before_test_step">
<code class="sig-name descname">before_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime.before_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime.before_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochTime.after_training_epoch">
<code class="sig-name descname">after_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime.after_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochTime.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochTime.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochTime.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochTime._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.StepTime">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">StepTime</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The step time metric.</p>
<p>This metric may seed very similar to <a class="reference internal" href="#avalanche.evaluation.metrics.AverageEpochTime" title="avalanche.evaluation.metrics.AverageEpochTime"><code class="xref py py-class docutils literal notranslate"><span class="pre">AverageEpochTime</span></code></a>. However,
differently from that: 1) obviously, the time is not averaged by dividing
by the number of epochs; 2) most importantly, the time consumed outside the
epoch loop is accounted too (a thing that <a class="reference internal" href="#avalanche.evaluation.metrics.AverageEpochTime" title="avalanche.evaluation.metrics.AverageEpochTime"><code class="xref py py-class docutils literal notranslate"><span class="pre">AverageEpochTime</span></code></a> doesn’t
support). For instance, this metric is more suitable when measuring times
of algorithms involving after-training consolidation, replay pattern
selection and other time consuming mechanisms.</p>
<p>Creates an instance of the EpochAccuracy metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepTime.before_training_step">
<code class="sig-name descname">before_training_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime.before_training_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime.before_training_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepTime.before_test_step">
<code class="sig-name descname">before_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime.before_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime.before_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepTime.after_training_step">
<code class="sig-name descname">after_training_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime.after_training_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime.after_training_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepTime.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepTime.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepTime.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepTime._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, ContinualAI Research.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>