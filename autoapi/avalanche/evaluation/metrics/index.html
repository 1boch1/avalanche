

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>avalanche.evaluation.metrics &mdash; Avalanche 0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../../_static/css/mystyle.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex/" />
    <link rel="search" title="Search" href="../../../../search/" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../" class="icon icon-home"> Avalanche
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Avalanche API:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche</span></code></a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../../benchmarks/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks</span></code></a></li>
<li class="toctree-l4 current"><a class="reference internal" href="../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../extras/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.extras</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../training/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../#package-contents">Package Contents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../#avalanche.__version__">__version__</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../cl_cumulative/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">cl_cumulative</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../cl_cumulative/#module-contents">Module Contents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../cl_cumulative/#classes">Classes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../cl_gdumb/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">cl_gdumb</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../cl_gdumb/#module-contents">Module Contents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../cl_gdumb/#classes">Classes</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../">Avalanche</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../">Docs</a> &raquo;</li>
        
      <li><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics</span></code></li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../../_sources/autoapi/avalanche/evaluation/metrics/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-avalanche.evaluation.metrics">
<span id="avalanche-evaluation-metrics"></span><h1><a class="reference internal" href="#module-avalanche.evaluation.metrics" title="avalanche.evaluation.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics</span></code></a><a class="headerlink" href="#module-avalanche.evaluation.metrics" title="Permalink to this headline">¶</a></h1>
<p>Common metrics for CL.</p>
<div class="section" id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Permalink to this headline">¶</a></h2>
<div class="section" id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MAC" title="avalanche.evaluation.metrics.MAC"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MAC</span></code></a></p></td>
<td><p>Multiply-and-accumulate metric. Provides a lower bound of the</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.GPUUsage" title="avalanche.evaluation.metrics.GPUUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GPUUsage</span></code></a></p></td>
<td><p>GPU usage metric measured as average usage percentage over time.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.CPUUsage" title="avalanche.evaluation.metrics.CPUUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CPUUsage</span></code></a></p></td>
<td><p>CPU usage metric measured in seconds.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ACC" title="avalanche.evaluation.metrics.ACC"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ACC</span></code></a></p></td>
<td><p>Accuracy metrics should be called for each test set</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.CF" title="avalanche.evaluation.metrics.CF"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CF</span></code></a></p></td>
<td><p>Catastrophic Forgetting metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.RAMU" title="avalanche.evaluation.metrics.RAMU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RAMU</span></code></a></p></td>
<td><p>RAM Usage metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.DiskUsage" title="avalanche.evaluation.metrics.DiskUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DiskUsage</span></code></a></p></td>
<td><p><dl class="field-list simple">
<dt class="field-odd">param path_to_monitor (string)</dt>
<dd class="field-odd"><p>a valid path to folder.</p>
</dd>
</dl>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.CM" title="avalanche.evaluation.metrics.CM"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CM</span></code></a></p></td>
<td><p>Confusion Matrix computation</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.TimeUsage" title="avalanche.evaluation.metrics.TimeUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TimeUsage</span></code></a></p></td>
<td><p>Time usage metric measured in seconds.</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt id="avalanche.evaluation.metrics.MAC">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">MAC</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#MAC"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MAC" title="Permalink to this definition">¶</a></dt>
<dd><p>Multiply-and-accumulate metric. Provides a lower bound of the
computational cost of a model in a hardware-independent way by
computing the number of multiplications. Currently supports only
Linear or Conv2d modules. Other operations are ignored.</p>
<p>Initialize self.  See help(type(self)) for accurate signature.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MAC.compute">
<code class="sig-name descname">compute</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">dummy_input</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#MAC.compute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MAC.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the MAC metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – current model.</p></li>
<li><p><strong>dummy_input</strong> – A tensor of the correct size to feed as input
to model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>MAC metric.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MAC.update_compute_cost">
<code class="sig-name descname">update_compute_cost</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">module</span></em>, <em class="sig-param"><span class="n">input</span></em>, <em class="sig-param"><span class="n">output</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#MAC.update_compute_cost"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MAC.update_compute_cost" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MAC.is_recognized_module">
<code class="sig-name descname">is_recognized_module</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">mod</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#MAC.is_recognized_module"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MAC.is_recognized_module" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.GPUUsage">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">GPUUsage</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">gpu_id</span></em>, <em class="sig-param"><span class="n">every</span><span class="o">=</span><span class="default_value">10</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#GPUUsage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GPUUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>GPU usage metric measured as average usage percentage over time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gpu_id</strong> – GPU device ID</p></li>
<li><p><strong>every</strong> – time delay (in seconds) between measurements</p></li>
</ul>
</dd>
</dl>
<p>Initialize self.  See help(type(self)) for accurate signature.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.GPUUsage.compute">
<code class="sig-name descname">compute</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#GPUUsage.compute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GPUUsage.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute CPU usage measured in seconds.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>t</strong> – task id</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>float: average GPU usage</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.GPUUsage.push_lines">
<code class="sig-name descname">push_lines</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#GPUUsage.push_lines"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GPUUsage.push_lines" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.GPUUsage.close">
<code class="sig-name descname">close</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#GPUUsage.close"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GPUUsage.close" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.CPUUsage">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">CPUUsage</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#CPUUsage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.CPUUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>CPU usage metric measured in seconds.</p>
<p>Initialize self.  See help(type(self)) for accurate signature.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.CPUUsage.compute">
<code class="sig-name descname">compute</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#CPUUsage.compute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.CPUUsage.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute CPU usage measured in seconds.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>t</strong> – task id</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tuple (float, float): (user CPU time, system CPU time)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ACC">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">ACC</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">num_class</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#ACC"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ACC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Accuracy metrics should be called for each test set</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>(</strong><strong>int</strong><strong>, </strong><strong>optional</strong><strong>)</strong> (<em>num_class</em>) – number of classes in the test_set
(useful in case the test_set does not cover all the classes
in the train_set).</p>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.ACC.compute">
<code class="sig-name descname">compute</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">y_hat</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#ACC.compute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ACC.compute" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>(</strong><strong>tensor list</strong><strong> or </strong><strong>tensor</strong><strong>)</strong> (<em>y_hat</em>) – true labels for each mini-batch</p></li>
<li><p><strong>(</strong><strong>tensor list</strong><strong> or </strong><strong>tensor</strong><strong>)</strong> – predicted labels for each
mini-batch</p></li>
</ul>
</dd>
<dt class="field-even">Return acc (float)</dt>
<dd class="field-even"><p>average accuracy for the test set</p>
</dd>
<dt class="field-odd">Return accs (float list)</dt>
<dd class="field-odd"><p>accuracy for each class in the training set</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.CF">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">CF</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">num_class</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#CF"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.CF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Catastrophic Forgetting metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.CF.compute">
<code class="sig-name descname">compute</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">y_hat</span></em>, <em class="sig-param"><span class="n">train_t</span></em>, <em class="sig-param"><span class="n">test_t</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#CF.compute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.CF.compute" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>(</strong><strong>tensor list</strong><strong> or </strong><strong>tensor</strong><strong>)</strong> (<em>y_hat</em>) – true labels for each mini-batch</p></li>
<li><p><strong>(</strong><strong>tensor list</strong><strong> or </strong><strong>tensor</strong><strong>)</strong> – predicted labels for each
mini-batch</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.RAMU">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">RAMU</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#RAMU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RAMU" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>RAM Usage metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.RAMU.compute">
<code class="sig-name descname">compute</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#RAMU.compute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RAMU.compute" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.DiskUsage">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">DiskUsage</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">path_to_monitor</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">disk_io</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#DiskUsage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>(</strong><strong>string</strong><strong>)</strong> (<em>path_to_monitor</em>) – a valid path to folder.
If None, the current working directory is used.</p></li>
<li><p><strong>disk_io</strong> – True to enable monitoring of I/O operations on disk.
WARNING: Reports are system-wide, grouping all disks.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.DiskUsage.compute">
<code class="sig-name descname">compute</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#DiskUsage.compute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsage.compute" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>t</strong> – task id</p>
</dd>
<dt class="field-even">Return usage, io (tuple)</dt>
<dd class="field-even"><p>io is None if disk_io is False</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.CM">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">CM</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">num_class</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#CM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.CM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Confusion Matrix computation</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.CM.compute">
<code class="sig-name descname">compute</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">y_hat</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#CM.compute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.CM.compute" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>(</strong><strong>tensor</strong><strong> or </strong><strong>tensors list</strong><strong>)</strong> (<em>y_hat</em>) – true labels for each minibatch</p></li>
<li><p><strong>(</strong><strong>tensor</strong><strong> or </strong><strong>tensors list</strong><strong>)</strong> – predicted labels for each
minibatch</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.TimeUsage">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">TimeUsage</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#TimeUsage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TimeUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Time usage metric measured in seconds.</p>
<p>Initialize self.  See help(type(self)) for accurate signature.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.TimeUsage.compute">
<code class="sig-name descname">compute</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/#TimeUsage.compute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TimeUsage.compute" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, ContinualAI Research

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>