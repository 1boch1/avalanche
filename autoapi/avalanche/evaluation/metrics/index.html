

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>avalanche.evaluation.metrics &mdash; Avalanche 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/mystyle.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex/" />
    <link rel="search" title="Search" href="../../../../search/" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../" class="icon icon-home"> Avalanche
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Avalanche API:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche</span></code></a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../../benchmarks/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks</span></code></a></li>
<li class="toctree-l4 current"><a class="reference internal" href="../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../logging/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.logging</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../models/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.models</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../training/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../#package-contents">Package Contents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../#avalanche.__version__">__version__</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../">Avalanche</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../" class="icon icon-home"></a> &raquo;</li>
        
      <li><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics</span></code></li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../_sources/autoapi/avalanche/evaluation/metrics/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-avalanche.evaluation.metrics">
<span id="avalanche-evaluation-metrics"></span><h1><a class="reference internal" href="#module-avalanche.evaluation.metrics" title="avalanche.evaluation.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics</span></code></a><a class="headerlink" href="#module-avalanche.evaluation.metrics" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="_any_event_metric/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics._any_event_metric</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="accuracy/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.accuracy</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="confusion_matrix/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.confusion_matrix</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu_usage/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.cpu_usage</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="disk_usage/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.disk_usage</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="forgetting/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.forgetting</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu_usage/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.gpu_usage</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="loss/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.loss</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="mac/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.mac</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="mean/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.mean</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="ram_usage/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.ram_usage</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="sum/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.sum</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="timing/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.timing</span></code></a></li>
</ul>
</div>
</div>
<div class="section" id="package-contents">
<h2>Package Contents<a class="headerlink" href="#package-contents" title="Permalink to this headline">¶</a></h2>
<div class="section" id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.Mean" title="avalanche.evaluation.metrics.Mean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Mean</span></code></a></p></td>
<td><p>The mean metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.Sum" title="avalanche.evaluation.metrics.Sum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Sum</span></code></a></p></td>
<td><p>The sum metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.Accuracy" title="avalanche.evaluation.metrics.Accuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Accuracy</span></code></a></p></td>
<td><p>The accuracy metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MinibatchAccuracy" title="avalanche.evaluation.metrics.MinibatchAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchAccuracy</span></code></a></p></td>
<td><p>The minibatch accuracy metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.EpochAccuracy" title="avalanche.evaluation.metrics.EpochAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochAccuracy</span></code></a></p></td>
<td><p>The average epoch accuracy metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.RunningEpochAccuracy" title="avalanche.evaluation.metrics.RunningEpochAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RunningEpochAccuracy</span></code></a></p></td>
<td><p>The running average accuracy metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.TaskAccuracy" title="avalanche.evaluation.metrics.TaskAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TaskAccuracy</span></code></a></p></td>
<td><p>The task accuracy metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ConfusionMatrix" title="avalanche.evaluation.metrics.ConfusionMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConfusionMatrix</span></code></a></p></td>
<td><p>The confusion matrix metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.TaskConfusionMatrix" title="avalanche.evaluation.metrics.TaskConfusionMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TaskConfusionMatrix</span></code></a></p></td>
<td><p>The Confusion Matrix metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.CpuUsage" title="avalanche.evaluation.metrics.CpuUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CpuUsage</span></code></a></p></td>
<td><p>The CPU usage metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MinibatchCpuUsage" title="avalanche.evaluation.metrics.MinibatchCpuUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchCpuUsage</span></code></a></p></td>
<td><p>The minibatch CPU usage metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.EpochCpuUsage" title="avalanche.evaluation.metrics.EpochCpuUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochCpuUsage</span></code></a></p></td>
<td><p>The epoch average CPU usage metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.AverageEpochCpuUsage" title="avalanche.evaluation.metrics.AverageEpochCpuUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AverageEpochCpuUsage</span></code></a></p></td>
<td><p>The average epoch CPU usage metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.StepCpuUsage" title="avalanche.evaluation.metrics.StepCpuUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StepCpuUsage</span></code></a></p></td>
<td><p>The average step CPU usage metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.DiskUsage" title="avalanche.evaluation.metrics.DiskUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DiskUsage</span></code></a></p></td>
<td><p>The disk usage metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.DiskUsageMonitor" title="avalanche.evaluation.metrics.DiskUsageMonitor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DiskUsageMonitor</span></code></a></p></td>
<td><p>The disk usage metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.TaskForgetting" title="avalanche.evaluation.metrics.TaskForgetting"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TaskForgetting</span></code></a></p></td>
<td><p>The TaskForgetting metric, describing the accuracy loss detected for a</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.GpuUsage" title="avalanche.evaluation.metrics.GpuUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GpuUsage</span></code></a></p></td>
<td><p>GPU usage metric measured as average usage percentage over time.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.GpuUsageMonitor" title="avalanche.evaluation.metrics.GpuUsageMonitor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GpuUsageMonitor</span></code></a></p></td>
<td><p>The GPU usage metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.Loss" title="avalanche.evaluation.metrics.Loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Loss</span></code></a></p></td>
<td><p>The average loss metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MinibatchLoss" title="avalanche.evaluation.metrics.MinibatchLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchLoss</span></code></a></p></td>
<td><p>The minibatch loss metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.EpochLoss" title="avalanche.evaluation.metrics.EpochLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochLoss</span></code></a></p></td>
<td><p>The average epoch loss metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.RunningEpochLoss" title="avalanche.evaluation.metrics.RunningEpochLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RunningEpochLoss</span></code></a></p></td>
<td><p>The running average loss metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.TaskLoss" title="avalanche.evaluation.metrics.TaskLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TaskLoss</span></code></a></p></td>
<td><p>The task loss metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MAC" title="avalanche.evaluation.metrics.MAC"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MAC</span></code></a></p></td>
<td><p>Multiply-and-accumulate metric. Provides a lower bound of the</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.RamUsage" title="avalanche.evaluation.metrics.RamUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RamUsage</span></code></a></p></td>
<td><p>The RAM usage metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.RamUsageMonitor" title="avalanche.evaluation.metrics.RamUsageMonitor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RamUsageMonitor</span></code></a></p></td>
<td><p>The RAM usage metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ElapsedTime" title="avalanche.evaluation.metrics.ElapsedTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ElapsedTime</span></code></a></p></td>
<td><p>The elapsed time metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MinibatchTime" title="avalanche.evaluation.metrics.MinibatchTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchTime</span></code></a></p></td>
<td><p>The minibatch time metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.EpochTime" title="avalanche.evaluation.metrics.EpochTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochTime</span></code></a></p></td>
<td><p>The epoch elapsed time metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.AverageEpochTime" title="avalanche.evaluation.metrics.AverageEpochTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AverageEpochTime</span></code></a></p></td>
<td><p>The average epoch time metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.StepTime" title="avalanche.evaluation.metrics.StepTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StepTime</span></code></a></p></td>
<td><p>The step time metric.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.accuracy_metrics" title="avalanche.evaluation.metrics.accuracy_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">accuracy_metrics</span></code></a>(*, minibatch=False, epoch=False, epoch_running=False, task=False, train=None, test=None) → List[PluginMetric]</p></td>
<td><p>Helper method that can be used to obtain the desired set of metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.cpu_usage_metrics" title="avalanche.evaluation.metrics.cpu_usage_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cpu_usage_metrics</span></code></a>(*, minibatch=False, epoch=False, epoch_average=False, step=False, train=None, test=None) → List[PluginMetric]</p></td>
<td><p>Helper method that can be used to obtain the desired set of metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.loss_metrics" title="avalanche.evaluation.metrics.loss_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">loss_metrics</span></code></a>(*, minibatch=False, epoch=False, epoch_running=False, task=False, train=None, test=None) → List[PluginMetric]</p></td>
<td><p>Helper method that can be used to obtain the desired set of metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.timing_metrics" title="avalanche.evaluation.metrics.timing_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">timing_metrics</span></code></a>(*, minibatch=False, epoch=False, epoch_average=False, step=False, train=None, test=None) → List[PluginMetric]</p></td>
<td><p>Helper method that can be used to obtain the desired set of metric.</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt id="avalanche.evaluation.metrics.Mean">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">Mean</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Mean"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The mean metric.</p>
<p>This utility metric is a general purpose metric that can be used to keep
track of the mean of a sequence of values.</p>
<p>Creates an instance of the mean metric.</p>
<p>This metric in its initial state will return a mean value of 0.
The metric can be updated by using the <cite>update</cite> method while the mean
can be retrieved using the <cite>result</cite> method.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.Mean.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">value</span><span class="p">:</span> <span class="n">SupportsFloat</span></em>, <em class="sig-param"><span class="n">weight</span><span class="p">:</span> <span class="n">SupportsFloat</span> <span class="o">=</span> <span class="default_value">1.0</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Mean.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Mean.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running mean given the value.</p>
<p>The value can be weighted with a custom value, defined by the <cite>weight</cite>
parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> – The value to be used to update the mean.</p></li>
<li><p><strong>weight</strong> – The weight of the value. Defaults to 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Mean.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Mean.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Mean.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the mean.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The mean, as a float.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Mean.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Mean.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Mean.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.Sum">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">Sum</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/sum/#Sum"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Sum" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The sum metric.</p>
<p>This utility metric is a general purpose metric that can be used to keep
track of the sum of a sequence of values.</p>
<p>Beware that this metric only supports summing numbers and the result is
always a float value, even when <cite>update</cite> is called by passing <a href="#id1"><span class="problematic" id="id2">`</span></a>int`s only.</p>
<p>Creates an instance of the sum metric.</p>
<p>This metric in its initial state will return a sum value of 0.
The metric can be updated by using the <cite>update</cite> method while the sum
can be retrieved using the <cite>result</cite> method.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.Sum.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">value</span><span class="p">:</span> <span class="n">SupportsFloat</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/sum/#Sum.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Sum.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running sum given the value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>value</strong> – The value to be used to update the sum.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Sum.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/sum/#Sum.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Sum.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the sum.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The sum, as a float.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Sum.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/sum/#Sum.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Sum.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.Accuracy">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">Accuracy</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The accuracy metric.</p>
<p>Instances of this metric compute the average accuracy by receiving a pair
of “ground truth” and “prediction” Tensors describing the labels of a
minibatch. Those two tensors can both contain plain labels or
one-hot/logit vectors.</p>
<p>The result is the running accuracy computed as the number of correct
patterns divided by the overall amount of patterns.</p>
<p>The reset method will bring the metric to its initial state. By default
this metric in its initial state will return an accuracy value of 0.</p>
<p>Creates an instance of the accuracy metric.</p>
<p>By default this metric in its initial state will return an accuracy
value of 0. The metric can be updated by using the <cite>update</cite> method
while the running accuracy can be retrieved using the <cite>result</cite> method.</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.Accuracy._mean_accuracy">
<code class="sig-name descname">_mean_accuracy</code><a class="headerlink" href="#avalanche.evaluation.metrics.Accuracy._mean_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>The mean utility that will be used to store the running accuracy.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Accuracy.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">true_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">predicted_y</span><span class="p">:</span> <span class="n">Tensor</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Accuracy.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running accuracy given the true and predicted labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>true_y</strong> – The ground truth. Both labels and one-hot vectors
are supported.</p></li>
<li><p><strong>predicted_y</strong> – The ground truth. Both labels and logit vectors
are supported.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Accuracy.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Accuracy.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the running accuracy.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The running accuracy, as a float value between 0 and 1.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Accuracy.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Accuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">MinibatchAccuracy</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The minibatch accuracy metric.</p>
<p>This metric “logs” the accuracy value after each iteration. Beware that this
metric will not average the accuracy across minibatches!</p>
<p>If a more coarse-grained logging is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.EpochAccuracy" title="avalanche.evaluation.metrics.EpochAccuracy"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochAccuracy</span></code></a> and/or <a class="reference internal" href="#avalanche.evaluation.metrics.TaskAccuracy" title="avalanche.evaluation.metrics.TaskAccuracy"><code class="xref py py-class docutils literal notranslate"><span class="pre">TaskAccuracy</span></code></a> instead.</p>
<p>Creates an instance of the MinibatchAccuracy metric.</p>
<p>The train and test parameters are used to control if this metric should
compute and log values referred to the train phase, test phase or both.
At least one of them must be True!</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy._on_iteration">
<code class="sig-name descname">_on_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy._on_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy._on_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.EpochAccuracy">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">EpochAccuracy</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The average epoch accuracy metric.</p>
<p>The accuracy will be logged after each epoch by computing the accuracy
as the number of correctly predicted patterns divided by the overall
number of patterns encountered in that epoch, which means that having
unbalanced minibatch sizes will not affect the metric.</p>
<p>Creates an instance of the EpochAccuracy metric.</p>
<p>The train and test parameters are used to control if this metric should
compute and log values referred to the train phase, test phase or both.
At least one of them must be True!</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.before_training_epoch">
<code class="sig-name descname">before_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.before_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.before_test_step">
<code class="sig-name descname">before_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.before_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.before_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.after_training_epoch">
<code class="sig-name descname">after_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.after_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">RunningEpochAccuracy</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="accuracy/#avalanche.evaluation.metrics.accuracy.EpochAccuracy" title="avalanche.evaluation.metrics.accuracy.EpochAccuracy"><code class="xref py py-class docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.accuracy.EpochAccuracy</span></code></a></p>
<p>The running average accuracy metric.</p>
<p>This metric behaves like <a class="reference internal" href="#avalanche.evaluation.metrics.EpochAccuracy" title="avalanche.evaluation.metrics.EpochAccuracy"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochAccuracy</span></code></a> but, differently from it,
this metric will log the running accuracy value after each iteration.</p>
<p>Creates an instance of the RunningEpochAccuracy metric.</p>
<p>The train and test parameters are used to control if this metric should
compute and log values referred to the train phase, test phase or both.
At least one of them must be True!</p>
<p>Beware that the test parameter defaults to False because logging
the running test accuracy it’s and uncommon practice.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy.after_training_epoch">
<code class="sig-name descname">after_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy.after_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.TaskAccuracy">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">TaskAccuracy</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[Dict[int,</span> <span class="pre">float]]</span></code></p>
<p>The task accuracy metric.</p>
<p>This is the most common metric used in the evaluation of a Continual
Learning algorithm.</p>
<p>Can be safely used when evaluation task-free scenarios, in which case the
default task label “0” will be used.</p>
<p>The task accuracies will be logged at the end of the test phase. This metric
doesn’t apply to the training phase.</p>
<p>Creates an instance of the TaskAccuracy metric.</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.TaskAccuracy._task_accuracy">
<code class="sig-name descname">_task_accuracy</code><em class="property"> :Dict[int, Accuracy]</em><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy._task_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>A dictionary used to store the accuracy for each task.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskAccuracy.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskAccuracy.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskAccuracy.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">true_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">predicted_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">task_label</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy.update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskAccuracy.before_test">
<code class="sig-name descname">before_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.before_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy.before_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskAccuracy.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskAccuracy.after_test">
<code class="sig-name descname">after_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.after_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy.after_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskAccuracy._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="avalanche.evaluation.metrics.accuracy_metrics">
<code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">accuracy_metrics</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">minibatch</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">epoch</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">epoch_running</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">task</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>PluginMetric<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#accuracy_metrics"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method that can be used to obtain the desired set of metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>minibatch</strong> – If True, will return a metric able to log the minibatch
accuracy.</p></li>
<li><p><strong>epoch</strong> – If True, will return a metric able to log the epoch accuracy.</p></li>
<li><p><strong>epoch_running</strong> – If True, will return a metric able to log the running
epoch accuracy.</p></li>
<li><p><strong>task</strong> – If True, will return a metric able to log the task accuracy.
This metric applies to the test flow only. If the <cite>test</cite> parameter is
False, an error will be raised.</p></li>
<li><p><strong>train</strong> – If True, metrics will log values for the train flow. Defaults
to None, which means that the per-metric default value will be used.</p></li>
<li><p><strong>test</strong> – If True, metrics will log values for the test flow. Defaults
to None, which means that the per-metric default value will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of plugin metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">ConfusionMatrix</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">num_classes</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#ConfusionMatrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[Tensor]</span></code></p>
<p>The confusion matrix metric.</p>
<p>Instances of this metric keep track of the confusion matrix by receiving a
pair of “ground truth” and “prediction” Tensors describing the labels of a
minibatch. Those two tensors can both contain plain labels or
one-hot/logit vectors.</p>
<p>The result is the unnormalized running confusion matrix.</p>
<p>Beware that by default the confusion matrix size will depend on the value of
the maximum label as detected by looking at both the ground truth and
predictions Tensors. When passing one-hot/logit vectors, this
metric will try to infer the number of classes from the vector sizes.
Otherwise, the maximum label value encountered in the truth/prediction
Tensors will be used. It is recommended to set the (initial) number of
classes in the constructor.</p>
<p>The reset method will bring the metric to its initial state. By default
this metric in its initial state will return an empty Tensor.</p>
<p>Creates an instance of the confusion matrix metric.</p>
<p>By default this metric in its initial state will return an empty Tensor.
The metric can be updated by using the <cite>update</cite> method while the running
confusion matrix can be retrieved using the <cite>result</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>num_classes</strong> – The initial number of classes. Defaults to None,
which means that the number of classes will be inferred from
ground truth and prediction Tensors (see class description for more
details).</p>
</dd>
</dl>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix._cm_tensor">
<code class="sig-name descname">_cm_tensor</code><em class="property"> :Optional[Tensor]</em><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix._cm_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>The Tensor where the running confusion matrix is stored.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">true_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">predicted_y</span><span class="p">:</span> <span class="n">Tensor</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#ConfusionMatrix.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running confusion matrix given the true and predicted labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>true_y</strong> – The ground truth. Both labels and one-hot vectors
are supported.</p></li>
<li><p><strong>predicted_y</strong> – The ground truth. Both labels and logit vectors
are supported.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Tensor<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#ConfusionMatrix.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the unnormalized confusion matrix.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The running confusion matrix, as a Tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#ConfusionMatrix.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<p>Calling this method will <em>not</em> reset the default number of classes
optionally defined in the constructor optional parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">TaskConfusionMatrix</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">test</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>int<span class="p">, </span>Mapping<span class="p">[</span>int<span class="p">, </span>int<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="p">:</span> <span class="n">Literal[‘true’, ‘pred’, ‘all’]</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">save_image</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">image_creator</span><span class="p">:</span> <span class="n">Callable<span class="p">[</span><span class="p">[</span>Tensor<span class="p">]</span><span class="p">, </span>Image<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">default_cm_image_creator</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[Tensor]</span></code></p>
<p>The Confusion Matrix metric.</p>
<p>This metric logs the confusion matrix for each task at the end of
each phase. By default this metric computes the matrix on the test phase
(on the test set) only but this behaviour can be changed by passing
<cite>train=True</cite> in the constructor.</p>
<p>The metric will log both a Tensor and PIL Image both representing the
confusion matrices. The Logger will decide which one to use depending on its
internal implementation.</p>
<p>Creates an instance of the Confusion Matrix metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to False.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to True.</p></li>
<li><p><strong>num_classes</strong> – When not None, is used to properly define the
amount of rows/columns in the confusion matrix. When None, the
matrix will have many rows/columns as the maximum value of the
predicted and true pattern labels. Can be either an int, in which
case the same value will be used across all tasks, or a dictionary
defining the amount of classes for each task (key = task label,
value = amount of classes). Defaults to None.</p></li>
<li><p><strong>normalize</strong> – Normalizes confusion matrix over the true (rows),
predicted (columns) conditions or all the population. If None,
confusion matrix will not be normalized. Valid values are: ‘true’,
‘pred’ and ‘all’.</p></li>
<li><p><strong>save_image</strong> – If True, a graphical representation of the confusion
matrix will be logged, too. If False, only the Tensor representation
will be logged. Defaults to True.</p></li>
<li><p><strong>image_creator</strong> – A callable that, given the tensor representation
of the confusion matrix, returns a graphical representation of the
matrix as a PIL Image. Defaults to <cite>default_cm_image_creator</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>int<span class="p">, </span>Tensor<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">true_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">predicted_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">task_label</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.before_training">
<code class="sig-name descname">before_training</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.before_training"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.before_training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.before_test">
<code class="sig-name descname">before_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.before_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.before_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.after_training">
<code class="sig-name descname">after_training</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; ’MetricResult’<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.after_training"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.after_training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.after_test">
<code class="sig-name descname">after_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.after_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.after_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix._class_num_for_task">
<code class="sig-name descname">_class_num_for_task</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">task_label</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>int<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix._class_num_for_task"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix._class_num_for_task" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix._normalize_cm">
<em class="property">static </em><code class="sig-name descname">_normalize_cm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cm</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">normalization</span><span class="p">:</span> <span class="n">Literal[‘true’, ‘pred’, ‘all’]</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix._normalize_cm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix._normalize_cm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskConfusionMatrix.nan_to_num">
<em class="property">static </em><code class="sig-name descname">nan_to_num</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">matrix</span><span class="p">:</span> <span class="n">Tensor</span></em><span class="sig-paren">)</span> &#x2192; Tensor<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#TaskConfusionMatrix.nan_to_num"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskConfusionMatrix.nan_to_num" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.CpuUsage">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">CpuUsage</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#CpuUsage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.CpuUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The CPU usage metric.</p>
<p>Instances of this metric compute the average CPU usage as a float value.
The metric starts tracking the CPU usage when the <cite>update</cite> method is called
for the first time. That is, the tracking doesn’t start at the time the
constructor is invoked.</p>
<p>Calling the <cite>update</cite> method more than twice will update the metric to the
average usage between the first and the last call to <cite>update</cite>.</p>
<p>The result, obtained using the <cite>result</cite> method, is the usage computed
as stated above.</p>
<p>The reset method will bring the metric to its initial state. By default
this metric in its initial state will return an usage value of 0.</p>
<p>Creates an instance of the CPU usage metric.</p>
<p>By default this metric in its initial state will return a CPU usage
value of 0. The metric can be updated by using the <cite>update</cite> method
while the average CPU usage can be retrieved using the <cite>result</cite> method.</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.CpuUsage._mean_usage">
<code class="sig-name descname">_mean_usage</code><a class="headerlink" href="#avalanche.evaluation.metrics.CpuUsage._mean_usage" title="Permalink to this definition">¶</a></dt>
<dd><p>The mean utility that will be used to store the average usage.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.CpuUsage._process_handle">
<code class="sig-name descname">_process_handle</code><em class="property"> :Optional[Process]</em><a class="headerlink" href="#avalanche.evaluation.metrics.CpuUsage._process_handle" title="Permalink to this definition">¶</a></dt>
<dd><p>The process handle, lazily initialized.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.CpuUsage._first_update">
<code class="sig-name descname">_first_update</code><em class="property"> = True</em><a class="headerlink" href="#avalanche.evaluation.metrics.CpuUsage._first_update" title="Permalink to this definition">¶</a></dt>
<dd><p>An internal flag to keep track of the first call to the <cite>update</cite> method.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.CpuUsage._timer">
<code class="sig-name descname">_timer</code><em class="property"> :Callable[[], float]</em><a class="headerlink" href="#avalanche.evaluation.metrics.CpuUsage._timer" title="Permalink to this definition">¶</a></dt>
<dd><p>The timer implementation (aligned with the one used by psutil).</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.CpuUsage.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#CpuUsage.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.CpuUsage.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running CPU usage.</p>
<p>For more info on how to set the starting moment see the class
description.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.CpuUsage.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#CpuUsage.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.CpuUsage.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the average CPU usage.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The average CPU usage, as a float value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.CpuUsage.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#CpuUsage.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.CpuUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MinibatchCpuUsage">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">MinibatchCpuUsage</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#MinibatchCpuUsage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchCpuUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The minibatch CPU usage metric.</p>
<p>This metric “logs” the CPU usage for each iteration. Beware that this
metric will not average the usage across minibatches!</p>
<p>If a more coarse-grained logging is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.EpochCpuUsage" title="avalanche.evaluation.metrics.EpochCpuUsage"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochCpuUsage</span></code></a>, <a class="reference internal" href="#avalanche.evaluation.metrics.AverageEpochCpuUsage" title="avalanche.evaluation.metrics.AverageEpochCpuUsage"><code class="xref py py-class docutils literal notranslate"><span class="pre">AverageEpochCpuUsage</span></code></a> or
<a class="reference internal" href="#avalanche.evaluation.metrics.StepCpuUsage" title="avalanche.evaluation.metrics.StepCpuUsage"><code class="xref py py-class docutils literal notranslate"><span class="pre">StepCpuUsage</span></code></a> instead.</p>
<p>Creates an instance of the minibatch CPU usage metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchCpuUsage.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#MinibatchCpuUsage.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchCpuUsage.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchCpuUsage.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#MinibatchCpuUsage.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchCpuUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchCpuUsage.before_training_iteration">
<code class="sig-name descname">before_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#MinibatchCpuUsage.before_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchCpuUsage.before_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchCpuUsage.before_test_iteration">
<code class="sig-name descname">before_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#MinibatchCpuUsage.before_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchCpuUsage.before_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchCpuUsage.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#MinibatchCpuUsage.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchCpuUsage.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchCpuUsage.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#MinibatchCpuUsage.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchCpuUsage.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchCpuUsage._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#MinibatchCpuUsage._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchCpuUsage._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.EpochCpuUsage">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">EpochCpuUsage</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#EpochCpuUsage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochCpuUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The epoch average CPU usage metric.</p>
<p>The average usage will be logged after each epoch. Beware that this
metric will not average the CPU usage across epochs!</p>
<p>If logging the average usage across epochs is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.AverageEpochCpuUsage" title="avalanche.evaluation.metrics.AverageEpochCpuUsage"><code class="xref py py-class docutils literal notranslate"><span class="pre">AverageEpochCpuUsage</span></code></a> instead.</p>
<p>Creates an instance of the epoch CPU usage metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochCpuUsage.before_training_epoch">
<code class="sig-name descname">before_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#EpochCpuUsage.before_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochCpuUsage.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochCpuUsage.before_test_step">
<code class="sig-name descname">before_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#EpochCpuUsage.before_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochCpuUsage.before_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochCpuUsage.after_training_epoch">
<code class="sig-name descname">after_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#EpochCpuUsage.after_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochCpuUsage.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochCpuUsage.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#EpochCpuUsage.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochCpuUsage.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochCpuUsage.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#EpochCpuUsage.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochCpuUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochCpuUsage.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#EpochCpuUsage.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochCpuUsage.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochCpuUsage._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#EpochCpuUsage._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochCpuUsage._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.AverageEpochCpuUsage">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">AverageEpochCpuUsage</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#AverageEpochCpuUsage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochCpuUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The average epoch CPU usage metric.</p>
<p>The average usage will be logged at the end of the step.</p>
<p>Beware that this metric will average the usage across epochs! If logging the
epoch-specific usage is needed, consider using <a class="reference internal" href="#avalanche.evaluation.metrics.EpochCpuUsage" title="avalanche.evaluation.metrics.EpochCpuUsage"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochCpuUsage</span></code></a>
instead.</p>
<p>Creates an instance of the average epoch cpu usage metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochCpuUsage.before_training_epoch">
<code class="sig-name descname">before_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#AverageEpochCpuUsage.before_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochCpuUsage.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochCpuUsage.before_test_step">
<code class="sig-name descname">before_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#AverageEpochCpuUsage.before_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochCpuUsage.before_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochCpuUsage.after_training_epoch">
<code class="sig-name descname">after_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#AverageEpochCpuUsage.after_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochCpuUsage.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochCpuUsage.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#AverageEpochCpuUsage.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochCpuUsage.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochCpuUsage.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#AverageEpochCpuUsage.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochCpuUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochCpuUsage.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#AverageEpochCpuUsage.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochCpuUsage.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochCpuUsage._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#AverageEpochCpuUsage._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochCpuUsage._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.StepCpuUsage">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">StepCpuUsage</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#StepCpuUsage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepCpuUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The average step CPU usage metric.</p>
<p>This metric may seem very similar to <a class="reference internal" href="#avalanche.evaluation.metrics.AverageEpochCpuUsage" title="avalanche.evaluation.metrics.AverageEpochCpuUsage"><code class="xref py py-class docutils literal notranslate"><span class="pre">AverageEpochCpuUsage</span></code></a>. However,
differently from that: 1) obviously, the usage is not averaged by dividing
by the number of epochs; 2) most importantly, the usage of code running
outside the epoch loop is accounted too (a thing that
<a class="reference internal" href="#avalanche.evaluation.metrics.AverageEpochCpuUsage" title="avalanche.evaluation.metrics.AverageEpochCpuUsage"><code class="xref py py-class docutils literal notranslate"><span class="pre">AverageEpochCpuUsage</span></code></a> doesn’t support). For instance, this metric is
more suitable when measuring the CPU usage of algorithms involving
after-training consolidation, replay pattern selection and other CPU bound
mechanisms.</p>
<p>Creates an instance of the step CPU usage metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepCpuUsage.before_training_step">
<code class="sig-name descname">before_training_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#StepCpuUsage.before_training_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepCpuUsage.before_training_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepCpuUsage.before_test_step">
<code class="sig-name descname">before_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#StepCpuUsage.before_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepCpuUsage.before_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepCpuUsage.after_training_step">
<code class="sig-name descname">after_training_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#StepCpuUsage.after_training_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepCpuUsage.after_training_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepCpuUsage.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#StepCpuUsage.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepCpuUsage.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepCpuUsage.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#StepCpuUsage.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepCpuUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepCpuUsage.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#StepCpuUsage.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepCpuUsage.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepCpuUsage._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#StepCpuUsage._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepCpuUsage._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="avalanche.evaluation.metrics.cpu_usage_metrics">
<code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">cpu_usage_metrics</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">minibatch</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">epoch</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">epoch_average</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">step</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>PluginMetric<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#cpu_usage_metrics"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.cpu_usage_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method that can be used to obtain the desired set of metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>minibatch</strong> – If True, will return a metric able to log the minibatch
elapsed time.</p></li>
<li><p><strong>epoch</strong> – If True, will return a metric able to log the epoch elapsed
time.</p></li>
<li><p><strong>epoch_average</strong> – If True, will return a metric able to log the average
epoch elapsed time.</p></li>
<li><p><strong>step</strong> – If True, will return a metric able to log the step elapsed
time.</p></li>
<li><p><strong>train</strong> – If True, metrics will log values for the train flow. Defaults
to None, which means that the per-metric default value will be used.</p></li>
<li><p><strong>test</strong> – If True, metrics will log values for the test flow. Defaults
to None, which means that the per-metric default value will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of plugin metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.DiskUsage">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">DiskUsage</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">paths_to_monitor</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>PathAlike<span class="p">, </span>Sequence<span class="p">[</span>PathAlike<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">monitor_disk_io</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#DiskUsage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[DiskUsageResult]</span></code></p>
<p>The disk usage metric.</p>
<p>This metric can be used to monitor the size of a set of directories. This
can be useful to monitor the size of a replay buffer,</p>
<p>This metric can also be used to get info regarding the overall amount of
other system-wide disk stats (see the constructor for more details).</p>
<p>Creates an instance of the disk usage metric.</p>
<p>By default invoking the <cite>result</cite> method will return the sum of the size
of the directories specified as the first parameter. By passing
<cite>monitor_disk_io</cite> as true the <cite>result</cite> method will return a 5 elements
tuple containing 1) the sum of the size of the directories,
the system-wide 2) read count, 3) write count, 4) read bytes and
5) written bytes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>paths_to_monitor</strong> – a path or a list of paths to monitor. If None,
the current working directory is used. Defaults to None.</p></li>
<li><p><strong>monitor_disk_io</strong> – If True enables monitoring of I/O operations on
disk. WARNING: Reports are system-wide, grouping all disks. Defaults
to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.DiskUsage.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#DiskUsage.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsage.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the disk usage statistics.</p>
<p>:return None.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.DiskUsage.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>DiskUsageResult<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#DiskUsage.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsage.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the disk usage as computed during the last call to the
<cite>update</cite> method.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<p>The info returned may vary depending on whether the constructor was
invoked with <cite>monitor_disk_io</cite> to True. See the constructor for more
details.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The disk usage or None if <cite>update</cite> was not invoked yet.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.DiskUsage.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#DiskUsage.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.DiskUsage.get_dir_size">
<em class="property">static </em><code class="sig-name descname">get_dir_size</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">path</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#DiskUsage.get_dir_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsage.get_dir_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.DiskUsageMonitor">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">DiskUsageMonitor</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">paths</span><span class="p">:</span> <span class="n">PathAlike</span></em>, <em class="sig-param"><span class="n">timeout</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">5.0</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#DiskUsageMonitor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsageMonitor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">AnyEventMetric[float]</span></code></p>
<p>The disk usage metric.</p>
<p>This metric logs the disk usage (directory size) of the given list of paths.</p>
<p>The logged value is in MiB.</p>
<p>The metric can be either configured to log after a certain timeout or
at each event.</p>
<p>Disk usage is logged separately for the train and test phases.</p>
<p>Creates an instance of the disk usage metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>paths</strong> – A list of paths to monitor. If no paths are defined,
the current working directory is used.</p></li>
<li><p><strong>timeout</strong> – The timeout between each disk usage check, in seconds.
If None, the disk usage is checked at every possible event (not
recommended). Defaults to 5 seconds.</p></li>
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.DiskUsageMonitor.on_event">
<code class="sig-name descname">on_event</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; ’MetricResult’<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#DiskUsageMonitor.on_event"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsageMonitor.on_event" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.DiskUsageMonitor.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>float<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#DiskUsageMonitor.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsageMonitor.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.DiskUsageMonitor.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#DiskUsageMonitor.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsageMonitor.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.DiskUsageMonitor._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; ’MetricResult’<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#DiskUsageMonitor._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsageMonitor._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.TaskForgetting">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">TaskForgetting</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[Dict[int,</span> <span class="pre">float]]</span></code></p>
<p>The TaskForgetting metric, describing the accuracy loss detected for a
certain task.</p>
<p>This metric, computed separately for each task, is the difference between
the accuracy result obtained after first training on a task and the accuracy
result obtained on the same task at the end of successive steps.</p>
<p>This metric is computed during the test phase only.</p>
<p>Creates an instance of the Catastrophic TaskForgetting metric.</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.TaskForgetting._initial_task_accuracy">
<code class="sig-name descname">_initial_task_accuracy</code><em class="property"> :Dict[int, float]</em><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting._initial_task_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>The initial accuracy of each task.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.TaskForgetting._current_task_accuracy">
<code class="sig-name descname">_current_task_accuracy</code><em class="property"> :Dict[int, Accuracy]</em><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting._current_task_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>The current accuracy of each task.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<p>Beware that this will also reset the initial accuracy of each task!</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting.reset_current_accuracy">
<code class="sig-name descname">reset_current_accuracy</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting.reset_current_accuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting.reset_current_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the current accuracy.</p>
<p>This will preserve the initial accuracy value of each task. To be used
at the beginning of each test step.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">true_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">predicted_y</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">task_label</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the running accuracy of a task given the ground truth and
predicted labels of a minibatch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>true_y</strong> – The ground truth. Both labels and one-hot vectors
are supported.</p></li>
<li><p><strong>predicted_y</strong> – The ground truth. Both labels and logit vectors
are supported.</p></li>
<li><p><strong>task_label</strong> – The task label.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting.before_test">
<code class="sig-name descname">before_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting.before_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting.before_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting.after_test">
<code class="sig-name descname">after_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting.after_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting.after_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the amount of forgetting for each task.</p>
<p>The forgetting is computed as the accuracy difference between the
initial task accuracy (when first encountered in the training stream)
and the current accuracy. A positive value means that forgetting
occurred. A negative value means that the accuracy on that task
increased.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A dictionary in which keys are task labels and the values are
the forgetting measures (as floats in range [-1, 1]).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskForgetting._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">train_task</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#TaskForgetting._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskForgetting._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.GpuUsage">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">GpuUsage</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">gpu_id</span></em>, <em class="sig-param"><span class="n">every</span><span class="o">=</span><span class="default_value">2.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#GpuUsage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>GPU usage metric measured as average usage percentage over time.</p>
<p>This metric will actively poll the system to get the GPU usage over time
starting from the first call to <cite>update</cite>. Subsequent calls to the <cite>update</cite>
method will consolidate the values gathered since the last call.</p>
<p>The <cite>result</cite> method will return <cite>None</cite> until the <cite>update</cite> method is invoked
at least two times.</p>
<p>Invoking the <cite>reset</cite> method will stop the measurement and reset the metric
to its initial state.</p>
<p>Creates an instance of the GPU usage metric.</p>
<p>For more info about the usage see the class description.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gpu_id</strong> – GPU device ID.</p></li>
<li><p><strong>every</strong> – time delay (in seconds) between measurements.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.GpuUsage.MAX_BUFFER">
<code class="sig-name descname">MAX_BUFFER</code><em class="property"> = 10000</em><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsage.MAX_BUFFER" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.GpuUsage.SMI_NOT_FOUND_MSG">
<code class="sig-name descname">SMI_NOT_FOUND_MSG</code><em class="property"> = No GPU available: nvidia-smi command not found. Gpu Usage logging will be disabled.</em><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsage.SMI_NOT_FOUND_MSG" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.GpuUsage.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#GpuUsage.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsage.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Consolidates the values got from the GPU sensor.</p>
<p>This will store the average for retrieval through the <cite>update</cite> method.</p>
<p>The previously consolidated value will be discarded.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.GpuUsage._start_watch">
<code class="sig-name descname">_start_watch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#GpuUsage._start_watch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsage._start_watch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.GpuUsage._push_lines">
<code class="sig-name descname">_push_lines</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#GpuUsage._push_lines"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsage._push_lines" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.GpuUsage.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#GpuUsage.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.GpuUsage.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>float<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#GpuUsage.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsage.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the last consolidated GPU usage value.</p>
<p>For more info about the returned value see the class description.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The percentage GPU usage as a float value in range [0, 1].
Returns None if the <cite>update</cite> method was invoked less than twice.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.GpuUsage.gpu_found">
<code class="sig-name descname">gpu_found</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#GpuUsage.gpu_found"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsage.gpu_found" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks if nvidia-smi could me executed.</p>
<p>This method is experimental. Please use at you own risk.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>True if nvidia-smi could be launched, False otherwise.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.GpuUsageMonitor">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">GpuUsageMonitor</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">gpu_id</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">timeout</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">2</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#GpuUsageMonitor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsageMonitor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">AnyEventMetric[float]</span></code></p>
<p>The GPU usage metric.</p>
<p>This metric logs the percentage GPU usage.</p>
<p>The metric can be either configured to log after a certain timeout or
at each event.</p>
<p>GPU usage is logged separately for the train and test phases.</p>
<p>Creates an instance of the GPU usage metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gpu_id</strong> – The GPU to monitor.</p></li>
<li><p><strong>timeout</strong> – The timeout between each GPU usage log, in seconds.
Defaults to 2 seconds. Must be an int.</p></li>
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.GpuUsageMonitor.on_event">
<code class="sig-name descname">on_event</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; ’MetricResult’<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#GpuUsageMonitor.on_event"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsageMonitor.on_event" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.GpuUsageMonitor.before_training">
<code class="sig-name descname">before_training</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; ’MetricResult’<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#GpuUsageMonitor.before_training"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsageMonitor.before_training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.GpuUsageMonitor.before_test">
<code class="sig-name descname">before_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; ’MetricResult’<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#GpuUsageMonitor.before_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsageMonitor.before_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.GpuUsageMonitor.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>float<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#GpuUsageMonitor.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsageMonitor.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.GpuUsageMonitor.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#GpuUsageMonitor.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsageMonitor.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.GpuUsageMonitor._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; ’MetricResult’<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#GpuUsageMonitor._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.GpuUsageMonitor._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.Loss">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">Loss</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#Loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The average loss metric.</p>
<p>Instances of this metric compute the running average loss by receiving a
Tensor describing the loss of a minibatch. This metric then uses that tensor
to computes the average loss per pattern.</p>
<p>The Tensor passed to the <cite>update</cite> method are averaged to obtain a
minibatch average loss. In order to compute the per-pattern running loss,
the users should must pass the number of patterns in that minibatch as the
second parameter of the <cite>update</cite> method. The number of patterns can’t be
usually obtained by analyzing the shape of the loss Tensor, which usually
consists of a single float value.</p>
<p>The result is the running loss computed as the accumulated average loss.</p>
<p>The reset method will bring the metric to its initial state. By default
this metric in its initial state will return a loss value of 0.</p>
<p>Creates an instance of the loss metric.</p>
<p>By default this metric in its initial state will return a loss
value of 0. The metric can be updated by using the <cite>update</cite> method
while the running loss can be retrieved using the <cite>result</cite> method.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.Loss.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">loss</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">patterns</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#Loss.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Loss.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running loss given the loss Tensor and the minibatch size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> – The loss Tensor. Different reduction types don’t affect
the result.</p></li>
<li><p><strong>patterns</strong> – The number of patterns in the minibatch.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Loss.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#Loss.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Loss.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the running average loss per pattern.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The running loss, as a float.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Loss.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#Loss.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Loss.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MinibatchLoss">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">MinibatchLoss</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The minibatch loss metric.</p>
<p>The logged loss value is the per-pattern loss obtained by averaging the loss
of patterns contained in the minibatch.</p>
<p>This metric “logs” the loss value after each iteration. Beware that this
metric will not average the loss across minibatches!</p>
<p>If a more coarse-grained logging is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.EpochLoss" title="avalanche.evaluation.metrics.EpochLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochLoss</span></code></a> and/or <a class="reference internal" href="#avalanche.evaluation.metrics.TaskLoss" title="avalanche.evaluation.metrics.TaskLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">TaskLoss</span></code></a> instead.</p>
<p>Creates an instance of the MinibatchLoss metric.</p>
<p>The train and test parameters are used to control if this metric should
compute and log values referred to the train phase, test phase or both.
At least one of them must be True!</p>
<p>Beware that the test parameter defaults to False because logging
the test minibatch loss it’s and uncommon practice.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss._on_iteration">
<code class="sig-name descname">_on_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss._on_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss._on_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.EpochLoss">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">EpochLoss</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The average epoch loss metric.</p>
<p>The logged loss value is the per-pattern loss obtained by averaging the loss
of all patterns encountered in that epoch, which means that having
unbalanced minibatch sizes will not affect the metric.</p>
<p>Creates an instance of the EpochLoss metric.</p>
<p>The train and test parameters are used to control if this metric should
compute and log values referred to the train phase, test phase or both.
At least one of them must be True!</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.before_training_epoch">
<code class="sig-name descname">before_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.before_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.before_test_step">
<code class="sig-name descname">before_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.before_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.before_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.after_training_epoch">
<code class="sig-name descname">after_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.after_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">RunningEpochLoss</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="loss/#avalanche.evaluation.metrics.loss.EpochLoss" title="avalanche.evaluation.metrics.loss.EpochLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.loss.EpochLoss</span></code></a></p>
<p>The running average loss metric.</p>
<p>This metric behaves like <a class="reference internal" href="#avalanche.evaluation.metrics.EpochLoss" title="avalanche.evaluation.metrics.EpochLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochLoss</span></code></a> but, differently from it,
this metric will log the running loss value after each iteration.</p>
<p>Creates an instance of the RunningEpochLoss metric.</p>
<p>The train and test parameters are used to control if this metric should
compute and log values referred to the train phase, test phase or both.
At least one of them must be True!</p>
<p>Beware that the test parameter defaults to False because logging
the running test loss it’s and uncommon practice.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss.after_training_epoch">
<code class="sig-name descname">after_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss.after_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.TaskLoss">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">TaskLoss</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[Dict[int,</span> <span class="pre">float]]</span></code></p>
<p>The task loss metric.</p>
<p>The logged loss value is the per-pattern loss obtained by averaging the loss
of all test patterns of a task. This is a common metric used in the
evaluation of a Continual Learning algorithm.</p>
<p>Can be safely used when evaluation task-free scenarios, in which case the
default task label “0” will be used.</p>
<p>The task losses will be logged at the end of the test phase. This metric
doesn’t apply to the training phase.</p>
<p>Creates an instance of the TaskLoss metric.</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.TaskLoss._task_loss">
<code class="sig-name descname">_task_loss</code><em class="property"> :Dict[int, Loss]</em><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss._task_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>A dictionary used to store the loss for each task.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskLoss.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskLoss.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskLoss.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">loss</span><span class="p">:</span> <span class="n">Tensor</span></em>, <em class="sig-param"><span class="n">patterns</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">task_label</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss.update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskLoss.before_test">
<code class="sig-name descname">before_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss.before_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss.before_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskLoss.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskLoss.after_test">
<code class="sig-name descname">after_test</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss.after_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss.after_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.TaskLoss._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#TaskLoss._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.TaskLoss._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="avalanche.evaluation.metrics.loss_metrics">
<code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">loss_metrics</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">minibatch</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">epoch</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">epoch_running</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">task</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>PluginMetric<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#loss_metrics"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.loss_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method that can be used to obtain the desired set of metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>minibatch</strong> – If True, will return a metric able to log the minibatch
loss.</p></li>
<li><p><strong>epoch</strong> – If True, will return a metric able to log the epoch loss.</p></li>
<li><p><strong>epoch_running</strong> – If True, will return a metric able to log the running
epoch loss.</p></li>
<li><p><strong>task</strong> – If True, will return a metric able to log the task loss. This
metric applies to the test flow only. If the <cite>test</cite> parameter is False,
an error will be raised.</p></li>
<li><p><strong>train</strong> – If True, metrics will log values for the train flow. Defaults
to None, which means that the per-metric default value will be used.</p></li>
<li><p><strong>test</strong> – If True, metrics will log values for the test flow. Defaults
to None, which means that the per-metric default value will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of plugin metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MAC">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">MAC</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MAC"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MAC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[int]</span></code></p>
<p>Multiply-and-accumulate metric. Provides a lower bound of the
computational cost of a model in a hardware-independent way by
computing the number of multiplications. Currently supports only
Linear or Conv2d modules. Other operations are ignored.</p>
<p>Creates an instance of the MAC metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MAC.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">model</span><span class="p">:</span> <span class="n">Module</span></em>, <em class="sig-param"><span class="n">dummy_input</span><span class="p">:</span> <span class="n">Tensor</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MAC.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MAC.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the MAC metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – current model.</p></li>
<li><p><strong>dummy_input</strong> – A tensor of the correct size to feed as input
to model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>MAC metric.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MAC.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>int<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MAC.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MAC.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the number of MAC operations as computed in the previous call
to the <cite>update</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The number of MAC operations or None if <cite>update</cite> has not been
called yet.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MAC.update_compute_cost">
<code class="sig-name descname">update_compute_cost</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">module</span></em>, <em class="sig-param"><span class="n">dummy_input</span></em>, <em class="sig-param"><span class="n">output</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MAC.update_compute_cost"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MAC.update_compute_cost" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MAC.is_recognized_module">
<em class="property">static </em><code class="sig-name descname">is_recognized_module</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mod</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MAC.is_recognized_module"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MAC.is_recognized_module" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.RamUsage">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">RamUsage</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">two_read_average</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#RamUsage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RamUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The RAM usage metric.</p>
<p>Instances of this metric compute the punctual RAM usage as a float value.
The metric updates the value each time the <cite>update</cite> method is called.</p>
<p>The result, obtained using the <cite>result</cite> method, is the usage in bytes.</p>
<p>The reset method will bring the metric to its initial state. By default
this metric in its initial state will return an usage value of <cite>None</cite>.</p>
<p>Creates an instance of the RAM usage metric.</p>
<p>By default this metric in its initial state will return a RAM usage
value of <cite>None</cite>. The metric can be updated by using the <cite>update</cite> method
while the average usage value can be retrieved using the <cite>result</cite>
method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>two_read_average</strong> – If True, the value resulting from calling
<cite>update</cite> more than once will set the result to the average between
the last read and the current RAM usage value.</p>
</dd>
</dl>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.RamUsage._process_handle">
<code class="sig-name descname">_process_handle</code><em class="property"> :Optional[Process]</em><a class="headerlink" href="#avalanche.evaluation.metrics.RamUsage._process_handle" title="Permalink to this definition">¶</a></dt>
<dd><p>The process handle, lazily initialized.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.RamUsage._last_values">
<code class="sig-name descname">_last_values</code><a class="headerlink" href="#avalanche.evaluation.metrics.RamUsage._last_values" title="Permalink to this definition">¶</a></dt>
<dd><p>The last detected RAM usage.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.RamUsage._first_update">
<code class="sig-name descname">_first_update</code><em class="property"> = True</em><a class="headerlink" href="#avalanche.evaluation.metrics.RamUsage._first_update" title="Permalink to this definition">¶</a></dt>
<dd><p>An internal flag to keep track of the first call to the <cite>update</cite> method.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.RamUsage._two_read_average">
<code class="sig-name descname">_two_read_average</code><a class="headerlink" href="#avalanche.evaluation.metrics.RamUsage._two_read_average" title="Permalink to this definition">¶</a></dt>
<dd><p>If True, the value resulting from calling <cite>update</cite> more than once will
set the result to the average between the last read and the current RAM
usage value.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RamUsage.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#RamUsage.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RamUsage.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the RAM usage.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RamUsage.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>float<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#RamUsage.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RamUsage.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the RAM usage.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The average RAM usage in bytes, as a float value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RamUsage.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#RamUsage.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RamUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.RamUsageMonitor">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">RamUsageMonitor</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">timeout</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">5.0</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#RamUsageMonitor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RamUsageMonitor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">AnyEventMetric[float]</span></code></p>
<p>The RAM usage metric.</p>
<p>This metric logs the RAM usage.</p>
<p>The logged value is in MiB.</p>
<p>The metric can be either configured to log after a certain timeout or
at each event.</p>
<p>RAM usage is logged separately for the train and test phases.</p>
<p>Creates an instance of the RAM usage metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>timeout</strong> – The timeout between each RAM usage check, in seconds.
If None, the RAM usage is checked at every possible event (not
recommended). Defaults to 5 seconds.</p></li>
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.RamUsageMonitor.on_event">
<code class="sig-name descname">on_event</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; ’MetricResult’<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#RamUsageMonitor.on_event"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RamUsageMonitor.on_event" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RamUsageMonitor.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; Optional<span class="p">[</span>float<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#RamUsageMonitor.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RamUsageMonitor.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RamUsageMonitor.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#RamUsageMonitor.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RamUsageMonitor.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RamUsageMonitor._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; ’MetricResult’<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#RamUsageMonitor._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RamUsageMonitor._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ElapsedTime">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">ElapsedTime</code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ElapsedTime"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ElapsedTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The elapsed time metric.</p>
<p>Instances of this metric keep track of the time elapsed between calls to the
<cite>update</cite> method. The starting time is set when the <cite>update</cite> method is called
for the first time. That is, the starting time is <em>not</em> taken at the time
the constructor is invoked.</p>
<p>Calling the <cite>update</cite> method more than twice will update the metric to the
elapsed time between the first and the last call to <cite>update</cite>.</p>
<p>The result, obtained using the <cite>result</cite> method, is the time, in seconds,
computed as stated above.</p>
<p>The <cite>reset</cite> method will set the metric to its initial state, thus resetting
the initial time. This metric in its initial state (or if the <cite>update</cite>
method was invoked only once) will return an elapsed time of 0.</p>
<p>Creates an instance of the accuracy metric.</p>
<p>This metric in its initial state (or if the <cite>update</cite> method was invoked
only once) will return an elapsed time of 0. The metric can be updated
by using the <cite>update</cite> method while the running accuracy can be retrieved
using the <cite>result</cite> method.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.ElapsedTime.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ElapsedTime.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ElapsedTime.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the elapsed time.</p>
<p>For more info on how to set the initial time see the class description.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ElapsedTime.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ElapsedTime.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ElapsedTime.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the elapsed time.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The elapsed time, in seconds, as a float value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ElapsedTime.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ElapsedTime.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ElapsedTime.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric, including the initial time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MinibatchTime">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">MinibatchTime</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The minibatch time metric.</p>
<p>This metric “logs” the elapsed time for each iteration. Beware that this
metric will not average the time across minibatches!</p>
<p>If a more coarse-grained logging is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.EpochTime" title="avalanche.evaluation.metrics.EpochTime"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochTime</span></code></a>, <a class="reference internal" href="#avalanche.evaluation.metrics.AverageEpochTime" title="avalanche.evaluation.metrics.AverageEpochTime"><code class="xref py py-class docutils literal notranslate"><span class="pre">AverageEpochTime</span></code></a> or
<a class="reference internal" href="#avalanche.evaluation.metrics.StepTime" title="avalanche.evaluation.metrics.StepTime"><code class="xref py py-class docutils literal notranslate"><span class="pre">StepTime</span></code></a> instead.</p>
<p>Creates an instance of the minibatch time metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.before_training_iteration">
<code class="sig-name descname">before_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.before_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.before_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.before_test_iteration">
<code class="sig-name descname">before_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.before_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.before_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.after_training_iteration">
<code class="sig-name descname">after_training_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.after_training_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.after_test_iteration">
<code class="sig-name descname">after_test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.after_test_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.EpochTime">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">EpochTime</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The epoch elapsed time metric.</p>
<p>The elapsed time will be logged after each epoch. Beware that this
metric will not average the time across epochs!</p>
<p>If logging the average time across epochs is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.AverageEpochTime" title="avalanche.evaluation.metrics.AverageEpochTime"><code class="xref py py-class docutils literal notranslate"><span class="pre">AverageEpochTime</span></code></a> instead.</p>
<p>Creates an instance of the epoch time metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.before_training_epoch">
<code class="sig-name descname">before_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.before_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.before_test_step">
<code class="sig-name descname">before_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.before_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.before_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.after_training_epoch">
<code class="sig-name descname">after_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.after_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.AverageEpochTime">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">AverageEpochTime</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The average epoch time metric.</p>
<p>The average elapsed time will be logged at the end of the step.</p>
<p>Beware that this metric will average the time across epochs! If logging the
epoch-specific time is needed, consider using <a class="reference internal" href="#avalanche.evaluation.metrics.EpochTime" title="avalanche.evaluation.metrics.EpochTime"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochTime</span></code></a> instead.</p>
<p>Creates an instance of the average epoch time metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochTime.before_training_epoch">
<code class="sig-name descname">before_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime.before_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochTime.before_test_step">
<code class="sig-name descname">before_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime.before_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime.before_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochTime.after_training_epoch">
<code class="sig-name descname">after_training_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime.after_training_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochTime.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochTime.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochTime.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.AverageEpochTime._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#AverageEpochTime._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.AverageEpochTime._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.StepTime">
<em class="property">class </em><code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">StepTime</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The step time metric.</p>
<p>This metric may seem very similar to <a class="reference internal" href="#avalanche.evaluation.metrics.AverageEpochTime" title="avalanche.evaluation.metrics.AverageEpochTime"><code class="xref py py-class docutils literal notranslate"><span class="pre">AverageEpochTime</span></code></a>. However,
differently from that: 1) obviously, the time is not averaged by dividing
by the number of epochs; 2) most importantly, the time consumed outside the
epoch loop is accounted too (a thing that <a class="reference internal" href="#avalanche.evaluation.metrics.AverageEpochTime" title="avalanche.evaluation.metrics.AverageEpochTime"><code class="xref py py-class docutils literal notranslate"><span class="pre">AverageEpochTime</span></code></a> doesn’t
support). For instance, this metric is more suitable when measuring times
of algorithms involving after-training consolidation, replay pattern
selection and other time consuming mechanisms.</p>
<p>Creates an instance of the step time metric.</p>
<p>The train and test parameters can be True at the same time. However,
at least one of them must be True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepTime.before_training_step">
<code class="sig-name descname">before_training_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime.before_training_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime.before_training_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepTime.before_test_step">
<code class="sig-name descname">before_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime.before_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime.before_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepTime.after_training_step">
<code class="sig-name descname">after_training_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime.after_training_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime.after_training_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepTime.after_test_step">
<code class="sig-name descname">after_test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime.after_test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepTime.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepTime.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StepTime._package_result">
<code class="sig-name descname">_package_result</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="p">:</span> <span class="n">PluggableStrategy</span></em><span class="sig-paren">)</span> &#x2192; MetricResult<a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StepTime._package_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StepTime._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="avalanche.evaluation.metrics.timing_metrics">
<code class="sig-prename descclassname">avalanche.evaluation.metrics.</code><code class="sig-name descname">timing_metrics</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">minibatch</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">epoch</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">epoch_average</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">step</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">train</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">test</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>PluginMetric<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#timing_metrics"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.evaluation.metrics.timing_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method that can be used to obtain the desired set of metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>minibatch</strong> – If True, will return a metric able to log the minibatch
elapsed time.</p></li>
<li><p><strong>epoch</strong> – If True, will return a metric able to log the epoch elapsed
time.</p></li>
<li><p><strong>epoch_average</strong> – If True, will return a metric able to log the average
epoch elapsed time.</p></li>
<li><p><strong>step</strong> – If True, will return a metric able to log the step elapsed
time.</p></li>
<li><p><strong>train</strong> – If True, metrics will log values for the train flow. Defaults
to None, which means that the per-metric default value will be used.</p></li>
<li><p><strong>test</strong> – If True, metrics will log values for the test flow. Defaults
to None, which means that the per-metric default value will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of plugin metrics.</p>
</dd>
</dl>
</dd></dl>

</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, ContinualAI Research.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>