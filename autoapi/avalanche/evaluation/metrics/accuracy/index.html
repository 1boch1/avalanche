

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>avalanche.evaluation.metrics.accuracy &mdash; Avalanche 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../../_static/css/mystyle.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/graphviz.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../../genindex/" />
    <link rel="search" title="Search" href="../../../../../search/" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../../" class="icon icon-home"> Avalanche
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Avalanche API:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../../">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche</span></code></a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../../#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../../../benchmarks/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks</span></code></a></li>
<li class="toctree-l4 current"><a class="reference internal" href="../../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../logging/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.logging</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../models/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.models</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../training/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../#package-contents">Package Contents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../#avalanche.__version__">__version__</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../">Avalanche</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../../" class="icon icon-home"></a> &raquo;</li>
        
      <li><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.accuracy</span></code></li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../../_sources/autoapi/avalanche/evaluation/metrics/accuracy/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-avalanche.evaluation.metrics.accuracy">
<span id="avalanche-evaluation-metrics-accuracy"></span><h1><a class="reference internal" href="#module-avalanche.evaluation.metrics.accuracy" title="avalanche.evaluation.metrics.accuracy"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.accuracy</span></code></a><a class="headerlink" href="#module-avalanche.evaluation.metrics.accuracy" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Permalink to this headline">¶</a></h2>
<div class="section" id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.accuracy.Accuracy" title="avalanche.evaluation.metrics.accuracy.Accuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Accuracy</span></code></a></p></td>
<td><p>The accuracy metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.accuracy.MinibatchAccuracy" title="avalanche.evaluation.metrics.accuracy.MinibatchAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchAccuracy</span></code></a></p></td>
<td><p>The minibatch accuracy metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.accuracy.EpochAccuracy" title="avalanche.evaluation.metrics.accuracy.EpochAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochAccuracy</span></code></a></p></td>
<td><p>The average epoch accuracy metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.accuracy.RunningEpochAccuracy" title="avalanche.evaluation.metrics.accuracy.RunningEpochAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RunningEpochAccuracy</span></code></a></p></td>
<td><p>The running average accuracy metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.accuracy.TaskAccuracy" title="avalanche.evaluation.metrics.accuracy.TaskAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TaskAccuracy</span></code></a></p></td>
<td><p>The task accuracy metric.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.accuracy.accuracy_metrics" title="avalanche.evaluation.metrics.accuracy.accuracy_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">accuracy_metrics</span></code></a>(*, minibatch=False, epoch=False, epoch_running=False, task=False, train=None, test=None) → List[PluginMetric]</p></td>
<td><p>Helper method that can be used to obtain the desired set of metric.</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt id="avalanche.evaluation.metrics.accuracy.Accuracy">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.accuracy.</span></code><code class="sig-name descname"><span class="pre">Accuracy</span></code><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.Accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The accuracy metric.</p>
<p>Instances of this metric compute the average accuracy by receiving a pair
of “ground truth” and “prediction” Tensors describing the labels of a
minibatch. Those two tensors can both contain plain labels or
one-hot/logit vectors.</p>
<p>The result is the running accuracy computed as the number of correct
patterns divided by the overall amount of patterns.</p>
<p>The reset method will bring the metric to its initial state. By default
this metric in its initial state will return an accuracy value of 0.</p>
<p>Creates an instance of the accuracy metric.</p>
<p>By default this metric in its initial state will return an accuracy
value of 0. The metric can be updated by using the <cite>update</cite> method
while the running accuracy can be retrieved using the <cite>result</cite> method.</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.accuracy.Accuracy._mean_accuracy">
<code class="sig-name descname"><span class="pre">_mean_accuracy</span></code><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.Accuracy._mean_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>The mean utility that will be used to store the running accuracy.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.Accuracy.update">
<code class="sig-name descname"><span class="pre">update</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">true_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predicted_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.Accuracy.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running accuracy given the true and predicted labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>true_y</strong> – The ground truth. Both labels and one-hot vectors
are supported.</p></li>
<li><p><strong>predicted_y</strong> – The ground truth. Both labels and logit vectors
are supported.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.Accuracy.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.Accuracy.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the running accuracy.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The running accuracy, as a float value between 0 and 1.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.Accuracy.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.Accuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.accuracy.MinibatchAccuracy">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.accuracy.</span></code><code class="sig-name descname"><span class="pre">MinibatchAccuracy</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.MinibatchAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The minibatch accuracy metric.</p>
<p>This metric “logs” the accuracy value after each iteration. Beware that this
metric will not average the accuracy across minibatches!</p>
<p>If a more coarse-grained logging is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.accuracy.EpochAccuracy" title="avalanche.evaluation.metrics.accuracy.EpochAccuracy"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochAccuracy</span></code></a> and/or <a class="reference internal" href="#avalanche.evaluation.metrics.accuracy.TaskAccuracy" title="avalanche.evaluation.metrics.accuracy.TaskAccuracy"><code class="xref py py-class docutils literal notranslate"><span class="pre">TaskAccuracy</span></code></a> instead.</p>
<p>Creates an instance of the MinibatchAccuracy metric.</p>
<p>The train and test parameters are used to control if this metric should
compute and log values referred to the train phase, test phase or both.
At least one of them must be True!</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.MinibatchAccuracy.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.MinibatchAccuracy.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.MinibatchAccuracy.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.MinibatchAccuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.MinibatchAccuracy.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.MinibatchAccuracy.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.MinibatchAccuracy.after_test_iteration">
<code class="sig-name descname"><span class="pre">after_test_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.after_test_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.MinibatchAccuracy.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.MinibatchAccuracy._on_iteration">
<code class="sig-name descname"><span class="pre">_on_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy._on_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.MinibatchAccuracy._on_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.MinibatchAccuracy._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.MinibatchAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.accuracy.EpochAccuracy">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.accuracy.</span></code><code class="sig-name descname"><span class="pre">EpochAccuracy</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.EpochAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The average epoch accuracy metric.</p>
<p>The accuracy will be logged after each epoch by computing the accuracy
as the number of correctly predicted patterns divided by the overall
number of patterns encountered in that epoch, which means that having
unbalanced minibatch sizes will not affect the metric.</p>
<p>Creates an instance of the EpochAccuracy metric.</p>
<p>The train and test parameters are used to control if this metric should
compute and log values referred to the train phase, test phase or both.
At least one of them must be True!</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.EpochAccuracy.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.EpochAccuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.EpochAccuracy.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.EpochAccuracy.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.EpochAccuracy.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.EpochAccuracy.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.EpochAccuracy.after_test_iteration">
<code class="sig-name descname"><span class="pre">after_test_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.after_test_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.EpochAccuracy.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.EpochAccuracy.before_training_epoch">
<code class="sig-name descname"><span class="pre">before_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.before_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.EpochAccuracy.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.EpochAccuracy.before_test_step">
<code class="sig-name descname"><span class="pre">before_test_step</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.before_test_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.EpochAccuracy.before_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.EpochAccuracy.after_training_epoch">
<code class="sig-name descname"><span class="pre">after_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.after_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.EpochAccuracy.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.EpochAccuracy.after_test_step">
<code class="sig-name descname"><span class="pre">after_test_step</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.after_test_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.EpochAccuracy.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.EpochAccuracy._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.EpochAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.accuracy.RunningEpochAccuracy">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.accuracy.</span></code><code class="sig-name descname"><span class="pre">RunningEpochAccuracy</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.RunningEpochAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#avalanche.evaluation.metrics.accuracy.EpochAccuracy" title="avalanche.evaluation.metrics.accuracy.EpochAccuracy"><code class="xref py py-class docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.accuracy.EpochAccuracy</span></code></a></p>
<p>The running average accuracy metric.</p>
<p>This metric behaves like <a class="reference internal" href="#avalanche.evaluation.metrics.accuracy.EpochAccuracy" title="avalanche.evaluation.metrics.accuracy.EpochAccuracy"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochAccuracy</span></code></a> but, differently from it,
this metric will log the running accuracy value after each iteration.</p>
<p>Creates an instance of the RunningEpochAccuracy metric.</p>
<p>The train and test parameters are used to control if this metric should
compute and log values referred to the train phase, test phase or both.
At least one of them must be True!</p>
<p>Beware that the test parameter defaults to False because logging
the running test accuracy it’s and uncommon practice.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> – When True, the metric will be computed on the training
phase. Defaults to True.</p></li>
<li><p><strong>test</strong> – When True, the metric will be computed on the test
phase. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.RunningEpochAccuracy.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.RunningEpochAccuracy.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.RunningEpochAccuracy.after_test_iteration">
<code class="sig-name descname"><span class="pre">after_test_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy.after_test_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.RunningEpochAccuracy.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.RunningEpochAccuracy.after_training_epoch">
<code class="sig-name descname"><span class="pre">after_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy.after_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.RunningEpochAccuracy.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.RunningEpochAccuracy.after_test_step">
<code class="sig-name descname"><span class="pre">after_test_step</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy.after_test_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.RunningEpochAccuracy.after_test_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.RunningEpochAccuracy._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.RunningEpochAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.accuracy.TaskAccuracy">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.accuracy.</span></code><code class="sig-name descname"><span class="pre">TaskAccuracy</span></code><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.TaskAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[Dict[int,</span> <span class="pre">float]]</span></code></p>
<p>The task accuracy metric.</p>
<p>This is the most common metric used in the evaluation of a Continual
Learning algorithm.</p>
<p>Can be safely used when evaluation task-free scenarios, in which case the
default task label “0” will be used.</p>
<p>The task accuracies will be logged at the end of the test phase. This metric
doesn’t apply to the training phase.</p>
<p>Creates an instance of the TaskAccuracy metric.</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.accuracy.TaskAccuracy._task_accuracy">
<code class="sig-name descname"><span class="pre">_task_accuracy</span></code><em class="property"> <span class="pre">:Dict[int,</span> <span class="pre">Accuracy]</span></em><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.TaskAccuracy._task_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>A dictionary used to store the accuracy for each task.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.TaskAccuracy.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.TaskAccuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.TaskAccuracy.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.TaskAccuracy.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.TaskAccuracy.update">
<code class="sig-name descname"><span class="pre">update</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">true_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predicted_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_label</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.TaskAccuracy.update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.TaskAccuracy.before_test">
<code class="sig-name descname"><span class="pre">before_test</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.before_test"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.TaskAccuracy.before_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.TaskAccuracy.after_test_iteration">
<code class="sig-name descname"><span class="pre">after_test_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluggableStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.after_test_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.TaskAccuracy.after_test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.TaskAccuracy.after_test">
<code class="sig-name descname"><span class="pre">after_test</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy.after_test"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.TaskAccuracy.after_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.accuracy.TaskAccuracy._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#TaskAccuracy._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.TaskAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="avalanche.evaluation.metrics.accuracy.accuracy_metrics">
<code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.accuracy.</span></code><code class="sig-name descname"><span class="pre">accuracy_metrics</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minibatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch_running</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">PluginMetric</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../../_modules/avalanche/evaluation/metrics/accuracy/#accuracy_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy.accuracy_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method that can be used to obtain the desired set of metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>minibatch</strong> – If True, will return a metric able to log the minibatch
accuracy.</p></li>
<li><p><strong>epoch</strong> – If True, will return a metric able to log the epoch accuracy.</p></li>
<li><p><strong>epoch_running</strong> – If True, will return a metric able to log the running
epoch accuracy.</p></li>
<li><p><strong>task</strong> – If True, will return a metric able to log the task accuracy.
This metric applies to the test flow only. If the <cite>test</cite> parameter is
False, an error will be raised.</p></li>
<li><p><strong>train</strong> – If True, metrics will log values for the train flow. Defaults
to None, which means that the per-metric default value will be used.</p></li>
<li><p><strong>test</strong> – If True, metrics will log values for the test flow. Defaults
to None, which means that the per-metric default value will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of plugin metrics.</p>
</dd>
</dl>
</dd></dl>

</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, ContinualAI Research.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>