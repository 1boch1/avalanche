

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>avalanche.benchmarks.generators &mdash; Avalanche 0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../../_static/css/mystyle.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex/" />
    <link rel="search" title="Search" href="../../../../search/" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../" class="icon icon-home"> Avalanche
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Avalanche API:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche</span></code></a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../evaluation/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../extras/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.extras</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../training/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../#submodules">Submodules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../constants/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.constants</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../#package-contents">Package Contents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../#avalanche.__version__">__version__</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../">Avalanche</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../">Docs</a> &raquo;</li>
        
      <li><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.generators</span></code></li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../../_sources/autoapi/avalanche/benchmarks/generators/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-avalanche.benchmarks.generators">
<span id="avalanche-benchmarks-generators"></span><h1><a class="reference internal" href="#module-avalanche.benchmarks.generators" title="avalanche.benchmarks.generators"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.generators</span></code></a><a class="headerlink" href="#module-avalanche.benchmarks.generators" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="generators_api/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.generators.generators_api</span></code></a></li>
</ul>
</div>
</div>
<div class="section" id="package-contents">
<h2>Package Contents<a class="headerlink" href="#package-contents" title="Permalink to this headline">¶</a></h2>
<div class="section" id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.generators.NCScenario" title="avalanche.benchmarks.generators.NCScenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NCScenario</span></code></a>(train_dataset: Union[Sequence[IDatasetWithTargets], IDatasetWithTargets], test_dataset: Union[Sequence[IDatasetWithTargets], IDatasetWithTargets], n_steps: int, multi_task: bool = True, shuffle: bool = True, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, per_step_classes: Optional[Dict[int, int]] = None, classes_ids_from_zero: bool = True, remap_class_ids: bool = False, one_dataset_per_batch: bool = False, reproducibility_data: Optional[Dict[str, Any]] = None) → Union[NCMultiTaskScenario, NCSingleTaskScenario]</p></td>
<td><p>This method is the high-level specific scenario generator for the</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.generators.NIScenario" title="avalanche.benchmarks.generators.NIScenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NIScenario</span></code></a>(train_dataset: Union[Sequence[IDatasetWithTargets], IDatasetWithTargets], test_dataset: Union[Sequence[IDatasetWithTargets], IDatasetWithTargets], n_batches: int, shuffle: bool = True, seed: Optional[int] = None, balance_batches: bool = False, min_class_patterns_in_batch: int = 0, fixed_batch_assignment: Optional[Sequence[Sequence[int]]] = None, reproducibility_data: Optional[Dict[str, Any]] = None) → NIScenario</p></td>
<td><p>This method is the high-level specific scenario generator for the</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.generators.DatasetScenario" title="avalanche.benchmarks.generators.DatasetScenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DatasetScenario</span></code></a>(train_dataset_list: Sequence[IDatasetWithTargets], test_dataset_list: Sequence[IDatasetWithTargets], task_labels: Sequence[int], complete_test_set_only: bool = False) → GenericCLScenario</p></td>
<td><p>Creates a generic scenario given a list of datasets and the respective task</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.generators.FilelistScenario" title="avalanche.benchmarks.generators.FilelistScenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FilelistScenario</span></code></a>(root: Union[str, Path], train_file_lists: Sequence[Union[str, Path]], test_file_lists: Union[Union[str, Path], Sequence[Union[str, Path]]], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, test_transform=None, test_target_transform=None) → GenericCLScenario</p></td>
<td><p>Creates a generic scenario given a list of filelists and the respective task</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.generators.TensorScenario" title="avalanche.benchmarks.generators.TensorScenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorScenario</span></code></a>(train_data_x: Sequence[Any], train_data_y: Sequence[Sequence[SupportsInt]], test_data_x: Union[Any, Sequence[Any]], test_data_y: Union[Any, Sequence[Sequence[SupportsInt]]], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, test_transform=None, test_target_transform=None) → GenericCLScenario</p></td>
<td><p>Creates a generic scenario given lists of Tensors and the respective task</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt id="avalanche.benchmarks.generators.NCScenario">
<code class="sig-prename descclassname">avalanche.benchmarks.generators.</code><code class="sig-name descname">NCScenario</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">train_dataset</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>Sequence<span class="p">[</span>IDatasetWithTargets<span class="p">]</span><span class="p">, </span>IDatasetWithTargets<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">test_dataset</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>Sequence<span class="p">[</span>IDatasetWithTargets<span class="p">]</span><span class="p">, </span>IDatasetWithTargets<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">n_steps</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">multi_task</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">shuffle</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">seed</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fixed_class_order</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Sequence<span class="p">[</span>int<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">per_step_classes</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Dict<span class="p">[</span>int<span class="p">, </span>int<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">classes_ids_from_zero</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">remap_class_ids</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">one_dataset_per_batch</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">reproducibility_data</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; Union<span class="p">[</span>NCMultiTaskScenario<span class="p">, </span>NCSingleTaskScenario<span class="p">]</span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/generators/generators_api/#NCScenario"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.benchmarks.generators.NCScenario" title="Permalink to this definition">¶</a></dt>
<dd><p>This method is the high-level specific scenario generator for the
“New Classes” (NC) case. Given a sequence of train and test datasets creates
the continual stream of data as a series of steps (task or batches),
highly tunable through its parameters.</p>
<p>The main parameter <code class="docutils literal notranslate"><span class="pre">multi_task</span></code> determines if the scenario is a
Single-Incremental-Task scenario o a Multi-task one. This in turn enable
other important options specifying the behavious of each of those.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> – A list of training datasets, or a single dataset.</p></li>
<li><p><strong>test_dataset</strong> – A list of test datasets, or a single test dataset.</p></li>
<li><p><strong>n_steps</strong> – The number of batches or tasks. This is not used in the
case of multiple train/test datasets and when <code class="docutils literal notranslate"><span class="pre">multi_task</span></code> is set to
True.</p></li>
<li><p><strong>multi_task</strong> – True if the scenario is Multi-Task, False if it is a
Single-Incremental-Task scenario.</p></li>
<li><p><strong>shuffle</strong> – If True, class order will be shuffled.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>fixed_class_order</strong> – This parameter is valid only if a single
train-test dataset is provided. A list of class IDs used to define the
classorder. If None, values of shuffle and seed will be used to define
the class order. If non-None, shuffle and seed parameters will be
ignored. Defaults to None.</p></li>
<li><p><strong>per_step_classes</strong> – not available with multiple train-test
datasets and <code class="docutils literal notranslate"><span class="pre">multi_task</span></code> is set to True. Is not None, a dictionary
whose keys are (0-indexed) task IDs and their values are the number
of classes to include in the respective batches. The dictionary doesn’t
have to contain a key for each task! All the remaining batches
will contain an equal amount of the remaining classes. The
remaining number of classes must be divisible without remainder
by the remaining number of steps. For instance,
if you want to include 50 classes in the first task while equally
distributing remaining classes across remaining batches,
just pass the “{0: 50}” dictionary as the per_task_classes
parameter. Defaults to None.</p></li>
<li><p><strong>classes_ids_from_zero</strong> – This parametes is valid
only when <code class="docutils literal notranslate"><span class="pre">multi_task</span></code> is set to True. If True, original class IDs
will be mapped to range [0, n_classes_in_task) for each step. If False,
each class will keep its original ID as defined in the input
datasets. Defaults to True.</p></li>
<li><p><strong>remap_class_ids</strong> – This parameter is only valid when a single
train/test is given and <code class="docutils literal notranslate"><span class="pre">multi_task</span></code> is set to False.
If True, original class IDs will be remapped so that they will appear
as having an ascending order. For instance, if the resulting class
order after shuffling (or defined by fixed_class_order) is [23, 34,
11, 7, 6, …] and remap_class_indexes is True, then all the patterns
belonging to class 23 will appear as belonging to class “0”,
class “34” will be mapped to “1”, class “11” to “2” and so on. This
is very useful when drawing confusion matrices and when dealing with
algorithms with dynamic head expansion. Defaults to False.</p></li>
<li><p><strong>one_dataset_per_batch</strong> – available only when multile train-test
datasets are provided and <code class="docutils literal notranslate"><span class="pre">multi_task</span></code> is set to False. If True, each
dataset will be treated as a batch. Mutually exclusive with the
per_task_classes parameter. Overrides the n_batches parameter.</p></li>
<li><p><strong>reproducibility_data</strong> – If not None, overrides all the other
scenario definition options. This is usually a dictionary containing
data used to reproduce a specific experiment. One can use the
<code class="docutils literal notranslate"><span class="pre">get_reproducibility_data</span></code> method to get (and even distribute)
the experiment setup so that it can be loaded by passing it as this
parameter. In this way one can be sure that the same specific
experimental setup is being used (for reproducibility purposes).
Beware that, in order to reproduce an experiment, the same train and
test datasets must be used. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">NCMultiTaskScenario</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">NCSingleTaskScenario</span></code>
instance initialized for the the SIT or MT scenario.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.generators.NIScenario">
<code class="sig-prename descclassname">avalanche.benchmarks.generators.</code><code class="sig-name descname">NIScenario</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">train_dataset</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>Sequence<span class="p">[</span>IDatasetWithTargets<span class="p">]</span><span class="p">, </span>IDatasetWithTargets<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">test_dataset</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>Sequence<span class="p">[</span>IDatasetWithTargets<span class="p">]</span><span class="p">, </span>IDatasetWithTargets<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">n_batches</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">shuffle</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">seed</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">balance_batches</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">min_class_patterns_in_batch</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">0</span></em>, <em class="sig-param"><span class="n">fixed_batch_assignment</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Sequence<span class="p">[</span>Sequence<span class="p">[</span>int<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">reproducibility_data</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.generators.NIScenario" title="avalanche.benchmarks.generators.NIScenario">NIScenario</a><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/generators/generators_api/#NIScenario"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.benchmarks.generators.NIScenario" title="Permalink to this definition">¶</a></dt>
<dd><p>This method is the high-level specific scenario generator for the
“New Instances” (NI) case. Given a sequence of train and test datasets
creates the continual stream of data as a series of steps (task or batches),
highly tunable through its parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> – A list of training datasets, or a single dataset.</p></li>
<li><p><strong>test_dataset</strong> – A list of test datasets, or a single test dataset.</p></li>
<li><p><strong>n_batches</strong> – The number of batches.</p></li>
<li><p><strong>shuffle</strong> – If True, patterns order will be shuffled.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>balance_batches</strong> – If True, pattern of each class will be equally
spread across all batches. If False, patterns will be assigned to
batches in a complete random way. Defaults to False.</p></li>
<li><p><strong>min_class_patterns_in_batch</strong> – The minimum amount of patterns of
every class that must be assigned to every batch. Compatible with
the <code class="docutils literal notranslate"><span class="pre">balance_batches</span></code> parameter. An exception will be raised if
this constraint can’t be satisfied. Defaults to 0.</p></li>
<li><p><strong>fixed_batch_assignment</strong> – only available when a single train-test
dataset is given. If not None, the pattern assignment
to use. It must be a list with an entry for each batch. Each entry
is a list that contains the indexes of patterns belonging to that
batch. Overrides the <code class="docutils literal notranslate"><span class="pre">shuffle</span></code>, <code class="docutils literal notranslate"><span class="pre">balance_batches</span></code> and
<code class="docutils literal notranslate"><span class="pre">min_class_patterns_in_batch</span></code> parameters.</p></li>
<li><p><strong>reproducibility_data</strong> – If not None, overrides all the other
scenario definition options, including <code class="docutils literal notranslate"><span class="pre">fixed_batch_assignment</span></code>.
This is usually a dictionary containing data used to
reproduce a specific experiment. One can use the scenario’s
<code class="docutils literal notranslate"><span class="pre">get_reproducibility_data</span></code> method to get (and even distribute)
the experiment setup so that it can be loaded by passing it as this
parameter. In this way one can be sure that the same specific
experimental setup is being used (for reproducibility purposes).
Beware that, in order to reproduce an experiment, the same train and
test datasets must be used. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="#avalanche.benchmarks.generators.NIScenario" title="avalanche.benchmarks.generators.NIScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NIScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.generators.DatasetScenario">
<code class="sig-prename descclassname">avalanche.benchmarks.generators.</code><code class="sig-name descname">DatasetScenario</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">train_dataset_list</span><span class="p">:</span> <span class="n">Sequence<span class="p">[</span>IDatasetWithTargets<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">test_dataset_list</span><span class="p">:</span> <span class="n">Sequence<span class="p">[</span>IDatasetWithTargets<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">task_labels</span><span class="p">:</span> <span class="n">Sequence<span class="p">[</span>int<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">complete_test_set_only</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span> &#x2192; GenericCLScenario<a class="reference internal" href="../../../../_modules/avalanche/benchmarks/generators/generators_api/#DatasetScenario"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.benchmarks.generators.DatasetScenario" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a generic scenario given a list of datasets and the respective task
labels. Each training dataset will be considered as a separate training
step. Contents of the datasets will not be changed, including the targets.</p>
<p>When loading the datasets from a set of fixed filelist, consider using
the <code class="xref py py-func docutils literal notranslate"><span class="pre">create_generic_scenario_from_filelists()</span></code> helper method instead.</p>
<p>In its base form, this function accepts a list of test datsets that must
contain the same amount of datasets of the training list.
Those pairs are then used to create the “past”, “cumulative”
(a.k.a. growing) and “future” test sets. However, in certain Continual
Learning scenarios only the concept of “complete” test set makes sense. In
that case, the <code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> should be set to True (see the
parameter description for more info).</p>
<p>Beware that pattern transformations must already be included in the
datasets (when needed).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset_list</strong> – A list of training datasets.</p></li>
<li><p><strong>test_dataset_list</strong> – A list of test datasets.</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain the same amount of
elements of the <code class="docutils literal notranslate"><span class="pre">train_dataset_list</span></code> parameter. For
Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
a list of zeros. For Multi Task scenario, this is usually a list of
ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that the <code class="docutils literal notranslate"><span class="pre">test_dataset_list</span></code>
parameter must be list with a single element (the complete test set).
Defaults to False, which means that <code class="docutils literal notranslate"><span class="pre">train_dataset_list</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_dataset_list</span></code> must contain the same amount of datasets.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.generators.FilelistScenario">
<code class="sig-prename descclassname">avalanche.benchmarks.generators.</code><code class="sig-name descname">FilelistScenario</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">root</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>str<span class="p">, </span>Path<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">train_file_lists</span><span class="p">:</span> <span class="n">Sequence<span class="p">[</span>Union<span class="p">[</span>str<span class="p">, </span>Path<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">test_file_lists</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>Union<span class="p">[</span>str<span class="p">, </span>Path<span class="p">]</span><span class="p">, </span>Sequence<span class="p">[</span>Union<span class="p">[</span>str<span class="p">, </span>Path<span class="p">]</span><span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">task_labels</span><span class="p">:</span> <span class="n">Sequence<span class="p">[</span>int<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">complete_test_set_only</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">train_transform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">train_target_transform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">test_transform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">test_target_transform</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; GenericCLScenario<a class="reference internal" href="../../../../_modules/avalanche/benchmarks/generators/generators_api/#FilelistScenario"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.benchmarks.generators.FilelistScenario" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a generic scenario given a list of filelists and the respective task
labels. A separate dataset will be created for each filelist and each of
those training datasets will be considered a separate training step.
Contents of the datasets will not be changed, including the targets.</p>
<p>In its base form, this function accepts a list of filelists for the test
datsets that must contain the same amount of elements of the training list.
Those pairs of datasets are then used to create the “past”, “cumulative”
(a.k.a. growing) and “future” test sets. However, in certain Continual
Learning scenarios only the concept of “complete” test set makes sense. In
that case, the <code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> should be set to True (see the
parameter description for more info).</p>
<p>This helper functions is the best shot when loading Caffe-style dataset
based on filelists.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – The root path of the dataset.</p></li>
<li><p><strong>train_file_lists</strong> – A list of filelists describing the
paths of the training patterns for each step.</p></li>
<li><p><strong>test_file_lists</strong> – A list of filelists describing the
paths of the test patterns for each step.</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain the same amount of
elements of the <code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> parameter. For
Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
a list of zeros. For Multi Task scenario, this is usually a list of
ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that the <code class="docutils literal notranslate"><span class="pre">test_file_lists</span></code>
parameter must be list with a single element (the complete test set).
Alternatively, can be a plain string or <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code> object.
Defaults to False, which means that <code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_file_lists</span></code> must contain the same amount of filelists paths.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to training patterns.
Defaults to None.</p></li>
<li><p><strong>train_target_transform</strong> – The transformation to apply to training
patterns targets. Defaults to None.</p></li>
<li><p><strong>test_transform</strong> – The transformation to apply to test patterns.
Defaults to None.</p></li>
<li><p><strong>test_target_transform</strong> – The transformation to apply to test
patterns targets. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.generators.TensorScenario">
<code class="sig-prename descclassname">avalanche.benchmarks.generators.</code><code class="sig-name descname">TensorScenario</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">train_data_x</span><span class="p">:</span> <span class="n">Sequence<span class="p">[</span>Any<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">train_data_y</span><span class="p">:</span> <span class="n">Sequence<span class="p">[</span>Sequence<span class="p">[</span>SupportsInt<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">test_data_x</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>Any<span class="p">, </span>Sequence<span class="p">[</span>Any<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">test_data_y</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>Any<span class="p">, </span>Sequence<span class="p">[</span>Sequence<span class="p">[</span>SupportsInt<span class="p">]</span><span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">task_labels</span><span class="p">:</span> <span class="n">Sequence<span class="p">[</span>int<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">complete_test_set_only</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">train_transform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">train_target_transform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">test_transform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">test_target_transform</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; GenericCLScenario<a class="reference internal" href="../../../../_modules/avalanche/benchmarks/generators/generators_api/#TensorScenario"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#avalanche.benchmarks.generators.TensorScenario" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a generic scenario given lists of Tensors and the respective task
labels. A separate dataset will be created from each Tensor pair (x + y)
and each of those training datasets will be considered a separate
training step. Contents of the datasets will not be changed, including the
targets. Using this helper function is the lower level way to create a
Continual Learning scenario. When possible, consider using higher level
helpers.</p>
<p>In its base form, the test lists must contain the same amount of elements of
the training lists. Those pairs of datasets are then used to create the
“past”, “cumulative” (a.k.a. growing) and “future” test sets.
However, in certain Continual Learning scenarios only the concept of
“complete” test set makes sense. In that case, the
<code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> should be set to True (see the parameter
description for more info).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_data_x</strong> – A list of Tensors (one per step) containing the
patterns of the training sets.</p></li>
<li><p><strong>train_data_y</strong> – A list of Tensors or int lists containing the
labels of the patterns of the training sets. Must contain the same
number of elements of <code class="docutils literal notranslate"><span class="pre">train_datasets_x</span></code>.</p></li>
<li><p><strong>test_data_x</strong> – A Tensor or a list of Tensors (one per step) containing
the patterns of the test sets.</p></li>
<li><p><strong>test_data_y</strong> – A Tensor or a list of Tensors or int lists containing
the labels of the patterns of the test sets. Must contain the same
number of elements of <code class="docutils literal notranslate"><span class="pre">test_datasets_x</span></code>.</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain the same amount of
elements of the <code class="docutils literal notranslate"><span class="pre">train_datasets_x</span></code> parameter. For
Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
a list of zeros. For Multi Task scenario, this is usually a list of
ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that the <code class="docutils literal notranslate"><span class="pre">test_datasets_x</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_datasets_y</span></code> parameters must be lists with a single element
(the complete test set). Defaults to False, which means that
<code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> and <code class="docutils literal notranslate"><span class="pre">test_file_lists</span></code> must contain the same
amount of filelists paths.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to training patterns.
Defaults to None.</p></li>
<li><p><strong>train_target_transform</strong> – The transformation to apply to training
patterns targets. Defaults to None.</p></li>
<li><p><strong>test_transform</strong> – The transformation to apply to test patterns.
Defaults to None.</p></li>
<li><p><strong>test_target_transform</strong> – The transformation to apply to test
patterns targets. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code> instance.</p>
</dd>
</dl>
</dd></dl>

</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, ContinualAI Research

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>